{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence example\n",
    "\n",
    ">https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tfrecords_filename= 'sequence_examples.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\x11\\n\\x0f\\n\\x06length\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\x12B\\n\\x1f\\n\\x06tokens\\x12\\x15\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x1f\\n\\x06labels\\x12\\x15\\n\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      "b'\\n\\x11\\n\\x0f\\n\\x06length\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\x12B\\n\\x1f\\n\\x06tokens\\x12\\x15\\n\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x05\\x1a\\x03\\n\\x01\\x05\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x1f\\n\\x06labels\\x12\\x15\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      "b'\\n\\x11\\n\\x0f\\n\\x06length\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\x124\\n\\x18\\n\\x06tokens\\x12\\x0e\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x18\\n\\x06labels\\x12\\x0e\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      "Wrote to sequence_examples.tfrecords\n"
     ]
    }
   ],
   "source": [
    "sequences= [[1,2,3], [4,5,1], [1,2]]\n",
    "label_sequences= [[0,1,0], [1,0,0], [1,1]]\n",
    "\n",
    "def make_example(sequences, labels):\n",
    "    # The object we return\n",
    "    ex= tf.train.SequenceExample() \n",
    "    # A non-sequential feature of our example\n",
    "    sequence_length=len(sequences)\n",
    "    ex.context.feature['length'].int64_list.value.append(sequence_length)\n",
    "    #Feature lists for the two sequential feature of our example\n",
    "    f1_tokens= ex.feature_lists.feature_list['tokens']\n",
    "    f1_labels= ex.feature_lists.feature_list['labels']\n",
    "    for token, label in zip(sequence, labels):\n",
    "        f1_tokens.feature.add().int64_list.value.append(token)\n",
    "        f1_labels.feature.add().int64_list.value.append(label)\n",
    "    return ex\n",
    "\n",
    "#Write all examples into a TFRecords file\n",
    "with open(tfrecords_filename) as f:\n",
    "    writer= tf.python_io.TFRecordWriter(f.name)\n",
    "    for sequence, label_sequence in zip(sequences, label_sequences):\n",
    "        ex= make_example(sequence, label_sequence)\n",
    "        print(ex.SerializeToString())\n",
    "        writer.write(ex.SerializeToString())        \n",
    "    writer.close()\n",
    "    print('Wrote to {}'.format(f.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#reading back\n",
    "record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "\n",
    "for string_record in record_iterator:\n",
    "    ex = tf.train.SequenceExample()\n",
    "    ex.ParseFromString(string_record)\n",
    "#     print(ex)\n",
    "    #Length of the sequence\n",
    "    print(ex.context.feature['length'].int64_list.value[0])\n",
    "    #First element of every label\n",
    "    print(ex.feature_lists.feature_list['labels'].feature[0].int64_list.value[0])\n",
    "    #Last element of every token\n",
    "    print(ex.feature_lists.feature_list['tokens'].feature[0].int64_list.value[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-31e038e549f9>:22: run_n (from tensorflow.contrib.learn.python.learn.graph_actions) is deprecated and will be removed after 2017-02-15.\n",
      "Instructions for updating:\n",
      "graph_actions.py will be deleted. Use tf.train.* utilities instead. You can use learn/estimators/estimator.py as an example.\n",
      "WARNING:tensorflow:From /Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py:644: run_feeds (from tensorflow.contrib.learn.python.learn.graph_actions) is deprecated and will be removed after 2017-02-15.\n",
      "Instructions for updating:\n",
      "graph_actions.py will be deleted. Use tf.train.* utilities instead. You can use learn/estimators/estimator.py as an example.\n",
      "WARNING:tensorflow:From /Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py:702: run_feeds_iter (from tensorflow.contrib.learn.python.learn.graph_actions) is deprecated and will be removed after 2017-02-15.\n",
      "Instructions for updating:\n",
      "graph_actions.py will be deleted. Use tf.train.* utilities instead. You can use learn/estimators/estimator.py as an example.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# A single serialized example\n",
    "#(You can read this from a file using TFRecordReader)\n",
    "ex= make_example([1, 2, 3], [0, 1, 0]).SerializeToString() \n",
    "\n",
    "#Define how to parse the example\n",
    "context_features= {\n",
    "    'length': tf.FixedLenFeature([], dtype=tf.int64)\n",
    "}\n",
    "sequence_features= {\n",
    "    'tokens': tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "    'labels': tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "#Parse the example (returns a dictionary of tensors)\n",
    "context_parsed, sequence_parsed= tf.parse_single_sequence_example(\n",
    "    serialized=ex,\n",
    "    context_features=context_features,\n",
    "    sequence_features=sequence_features\n",
    ")\n",
    "context= tf.contrib.learn.run_n(context_parsed, n=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'length': <tf.Tensor 'ParseSingleSequenceExample_8/ParseSingleSequenceExample:0' shape=() dtype=int64>}\n",
      "{'labels': <tf.Tensor 'ParseSingleSequenceExample_8/ParseSingleSequenceExample:1' shape=(?,) dtype=int64>, 'tokens': <tf.Tensor 'ParseSingleSequenceExample_8/ParseSingleSequenceExample:2' shape=(?,) dtype=int64>}\n",
      "{'length': <tf.Tensor 'ParseSingleSequenceExample_9/ParseSingleSequenceExample:0' shape=() dtype=int64>}\n",
      "{'labels': <tf.Tensor 'ParseSingleSequenceExample_9/ParseSingleSequenceExample:1' shape=(?,) dtype=int64>, 'tokens': <tf.Tensor 'ParseSingleSequenceExample_9/ParseSingleSequenceExample:2' shape=(?,) dtype=int64>}\n",
      "{'length': <tf.Tensor 'ParseSingleSequenceExample_10/ParseSingleSequenceExample:0' shape=() dtype=int64>}\n",
      "{'labels': <tf.Tensor 'ParseSingleSequenceExample_10/ParseSingleSequenceExample:1' shape=(?,) dtype=int64>, 'tokens': <tf.Tensor 'ParseSingleSequenceExample_10/ParseSingleSequenceExample:2' shape=(?,) dtype=int64>}\n"
     ]
    }
   ],
   "source": [
    "#reading back\n",
    "record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "\n",
    "#Define how to parse the example\n",
    "context_features= {\n",
    "    'length': tf.FixedLenFeature([], dtype=tf.int64)\n",
    "}\n",
    "sequence_features= {\n",
    "    'tokens': tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "    'labels': tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "for string_record in record_iterator:\n",
    "#     ex= tf.train.SequenceExample()\n",
    "#     ex.ParseFromString(string_record)\n",
    "    \n",
    "    #Parse the example (returns a dictionary of tensors)\n",
    "    context_parsed, sequence_parsed= tf.parse_single_sequence_example(\n",
    "        serialized=string_record,\n",
    "        context_features=context_features,\n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "#     import code; code.interact(local=dict(globals(), **locals()))\n",
    "    print(context_parsed)\n",
    "    print(sequence_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
