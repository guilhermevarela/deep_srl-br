{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence example\n",
    "\n",
    ">https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tfrecords_filename= 'sequence_examples.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\x11\\n\\x0f\\n\\x06length\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\x12B\\n\\x1f\\n\\x06tokens\\x12\\x15\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x1f\\n\\x06labels\\x12\\x15\\n\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      "b'\\n\\x11\\n\\x0f\\n\\x06length\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\x12B\\n\\x1f\\n\\x06tokens\\x12\\x15\\n\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x05\\x1a\\x03\\n\\x01\\x05\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x1f\\n\\x06labels\\x12\\x15\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      "b'\\n\\x11\\n\\x0f\\n\\x06length\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\x124\\n\\x18\\n\\x06tokens\\x12\\x0e\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x18\\n\\x06labels\\x12\\x0e\\n\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x05\\x1a\\x03\\n\\x01\\x01'\n",
      "Wrote to sequence_examples.tfrecords\n"
     ]
    }
   ],
   "source": [
    "sequences= [[1,2,3], [4,5,1], [1,2]]\n",
    "label_sequences= [[0,1,0], [1,0,0], [1,1]]\n",
    "\n",
    "def make_example(sequences, labels):\n",
    "    # The object we return\n",
    "    ex= tf.train.SequenceExample() \n",
    "    # A non-sequential feature of our example\n",
    "    sequence_length=len(sequences)\n",
    "    ex.context.feature['length'].int64_list.value.append(sequence_length)\n",
    "    #Feature lists for the two sequential feature of our example\n",
    "    f1_tokens= ex.feature_lists.feature_list['tokens']\n",
    "    f1_labels= ex.feature_lists.feature_list['labels']\n",
    "    for token, label in zip(sequence, labels):\n",
    "        f1_tokens.feature.add().int64_list.value.append(token)\n",
    "        f1_labels.feature.add().int64_list.value.append(label)\n",
    "    return ex\n",
    "\n",
    "#Write all examples into a TFRecords file\n",
    "with open(tfrecords_filename) as f:\n",
    "    writer= tf.python_io.TFRecordWriter(f.name)\n",
    "    for sequence, label_sequence in zip(sequences, label_sequences):\n",
    "        ex= make_example(sequence, label_sequence)\n",
    "        print(ex.SerializeToString())\n",
    "        writer.write(ex.SerializeToString())        \n",
    "    writer.close()\n",
    "    print('Wrote to {}'.format(f.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#reading back\n",
    "record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "\n",
    "for string_record in record_iterator:\n",
    "    ex = tf.train.SequenceExample()\n",
    "    ex.ParseFromString(string_record)\n",
    "#     print(ex)\n",
    "    #Length of the sequence\n",
    "    print(ex.context.feature['length'].int64_list.value[0])\n",
    "    #First element of every label\n",
    "    print(ex.feature_lists.feature_list['labels'].feature[0].int64_list.value[0])\n",
    "    #Last element of every token\n",
    "    print(ex.feature_lists.feature_list['tokens'].feature[0].int64_list.value[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-31e038e549f9>:22: run_n (from tensorflow.contrib.learn.python.learn.graph_actions) is deprecated and will be removed after 2017-02-15.\n",
      "Instructions for updating:\n",
      "graph_actions.py will be deleted. Use tf.train.* utilities instead. You can use learn/estimators/estimator.py as an example.\n",
      "WARNING:tensorflow:From /Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py:644: run_feeds (from tensorflow.contrib.learn.python.learn.graph_actions) is deprecated and will be removed after 2017-02-15.\n",
      "Instructions for updating:\n",
      "graph_actions.py will be deleted. Use tf.train.* utilities instead. You can use learn/estimators/estimator.py as an example.\n",
      "WARNING:tensorflow:From /Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py:702: run_feeds_iter (from tensorflow.contrib.learn.python.learn.graph_actions) is deprecated and will be removed after 2017-02-15.\n",
      "Instructions for updating:\n",
      "graph_actions.py will be deleted. Use tf.train.* utilities instead. You can use learn/estimators/estimator.py as an example.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# A single serialized example\n",
    "#(You can read this from a file using TFRecordReader)\n",
    "ex= make_example([1, 2, 3], [0, 1, 0]).SerializeToString() \n",
    "\n",
    "#Define how to parse the example\n",
    "context_features= {\n",
    "    'length': tf.FixedLenFeature([], dtype=tf.int64)\n",
    "}\n",
    "sequence_features= {\n",
    "    'tokens': tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "    'labels': tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "#Parse the example (returns a dictionary of tensors)\n",
    "context_parsed, sequence_parsed= tf.parse_single_sequence_example(\n",
    "    serialized=ex,\n",
    "    context_features=context_features,\n",
    "    sequence_features=sequence_features\n",
    ")\n",
    "context= tf.contrib.learn.run_n(context_parsed, n=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected string passed to parameter 'serialized' of op 'ParseSingleSequenceExample', got context {\n  feature {\n    key: \"length\"\n    value {\n      int64_list {\n        value: 3\n      }\n    }\n  }\n}\nfeature_lists {\n  feature_list {\n    key: \"labels\"\n    value {\n      feature {\n        int64_list {\n          value: 0\n        }\n      }\n      feature {\n        int64_list {\n          value: 1\n        }\n      }\n      feature {\n        int64_list {\n          value: 0\n        }\n      }\n    }\n  }\n  feature_list {\n    key: \"tokens\"\n    value {\n      feature {\n        int64_list {\n          value: 1\n        }\n      }\n      feature {\n        int64_list {\n          value: 2\n        }\n      }\n      feature {\n        int64_list {\n          value: 3\n        }\n      }\n    }\n  }\n}\n of type 'SequenceExample' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    302\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 303\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected string, got context {\n  feature {\n    key: \"length\"\n    value {\n      int64_list {\n        value: 3\n      }\n    }\n  }\n}\nfeature_lists {\n  feature_list {\n    key: \"labels\"\n    value {\n      feature {\n        int64_list {\n          value: 0\n        }\n      }\n      feature {\n        int64_list {\n          value: 1\n        }\n      }\n      feature {\n        int64_list {\n          value: 0\n        }\n      }\n    }\n  }\n  feature_list {\n    key: \"tokens\"\n    value {\n      feature {\n        int64_list {\n          value: 1\n        }\n      }\n      feature {\n        int64_list {\n          value: 2\n        }\n      }\n      feature {\n        int64_list {\n          value: 3\n        }\n      }\n    }\n  }\n}\n of type 'SequenceExample' instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a5a51dd8b581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mserialized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcontext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msequence_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_sequence_example\u001b[0;34m(serialized, context_features, sequence_features, example_name, name)\u001b[0m\n\u001b[1;32m    942\u001b[0m       \u001b[0mfeature_list_sparse_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list_dense_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m       \u001b[0mfeature_list_dense_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list_dense_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m       feature_list_dense_defaults, example_name, name)\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36m_parse_single_sequence_example_raw\u001b[0;34m(serialized, context_sparse_keys, context_sparse_types, context_dense_keys, context_dense_types, context_dense_defaults, context_dense_shapes, feature_list_sparse_keys, feature_list_sparse_types, feature_list_dense_keys, feature_list_dense_types, feature_list_dense_shapes, feature_list_dense_defaults, debug_name, name)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         feature_list_dense_missing_assumed_empty=(\n\u001b[1;32m   1140\u001b[0m             feature_list_dense_missing_assumed_empty),\n\u001b[0;32m-> 1141\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1142\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_parsing_ops.py\u001b[0m in \u001b[0;36m_parse_single_sequence_example\u001b[0;34m(serialized, feature_list_dense_missing_assumed_empty, context_sparse_keys, context_dense_keys, feature_list_sparse_keys, feature_list_dense_keys, context_dense_defaults, debug_name, context_sparse_types, feature_list_dense_types, context_dense_shapes, feature_list_sparse_types, feature_list_dense_shapes, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mcontext_dense_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_dense_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mfeature_list_sparse_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_list_sparse_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         feature_list_dense_shapes=feature_list_dense_shapes, name=name)\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    517\u001b[0m                   \u001b[0;34m\"type '%s' instead.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                   (dtypes.as_dtype(dtype).name, input_arg.name, op_type_name,\n\u001b[0;32m--> 519\u001b[0;31m                    repr(values), type(values).__name__))\n\u001b[0m\u001b[1;32m    520\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;31m# What type does convert_to_tensor think it has?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected string passed to parameter 'serialized' of op 'ParseSingleSequenceExample', got context {\n  feature {\n    key: \"length\"\n    value {\n      int64_list {\n        value: 3\n      }\n    }\n  }\n}\nfeature_lists {\n  feature_list {\n    key: \"labels\"\n    value {\n      feature {\n        int64_list {\n          value: 0\n        }\n      }\n      feature {\n        int64_list {\n          value: 1\n        }\n      }\n      feature {\n        int64_list {\n          value: 0\n        }\n      }\n    }\n  }\n  feature_list {\n    key: \"tokens\"\n    value {\n      feature {\n        int64_list {\n          value: 1\n        }\n      }\n      feature {\n        int64_list {\n          value: 2\n        }\n      }\n      feature {\n        int64_list {\n          value: 3\n        }\n      }\n    }\n  }\n}\n of type 'SequenceExample' instead."
     ]
    }
   ],
   "source": [
    "#reading back\n",
    "record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "\n",
    "#Define how to parse the example\n",
    "context_features= {\n",
    "    'length': tf.FixedLenFeature([], dtype=tf.int64)\n",
    "}\n",
    "sequence_features= {\n",
    "    'tokens': tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "    'labels': tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "for string_record in record_iterator:\n",
    "    ex= tf.train.SequenceExample()\n",
    "    ex.ParseFromString(string_record)\n",
    "    \n",
    "    #Parse the example (returns a dictionary of tensors)\n",
    "    context_parsed, sequence_parsed= tf.parse_single_sequence_example(\n",
    "        serialized=ex,\n",
    "        context_features=context_features,\n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "#     import code; code.interact(local=dict(globals(), **locals()))\n",
    "#     print(str(context_parsed))\n",
    "#     print(sequence_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
