{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loads Gold Standard and Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../datasets')\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import glob \n",
    "import re\n",
    "import math\n",
    "from gensim.models import KeyedVectors\n",
    "from data_propbankbr import propbankbr_arg2t\n",
    "\n",
    "DATASETS_DIR = '../datasets/csvs/'\n",
    "SCHEMAS_DIR = '../datasets/schemas/'\n",
    "SVM_DIR = '../datasets/svms/'\n",
    "EMBEDDINGS_DIR = '../datasets/txts/embeddings/'\n",
    "\n",
    "GS_PATH = '{:}{:}'.format(DATASETS_DIR, 'gs.csv')\n",
    "GS_SCHEMA_PATH = '{:}{:}'.format(SCHEMAS_DIR, 'gs.yaml')\n",
    "\n",
    "GLOVE_S50_PATH = '{:}glove_s50.txt'.format(EMBEDDINGS_DIR)\n",
    "WANG_S100_PATH = '{:}wang2vec_s100.txt'.format(EMBEDDINGS_DIR)\n",
    "\n",
    "\n",
    "\n",
    "DATASET_SIZE= 5931\n",
    "DATASET_TRAIN_SIZE= 5099\n",
    "DATASET_VALID_SIZE= 569\n",
    "DATASET_TEST_SIZE=  263\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARG', 'CTREE', 'DTREE', 'FORM', 'FUNC', 'GPOS', 'ID', 'INDEX', 'LEMMA', 'MORF', 'P', 'PRED', 'P_S', 'S']\n"
     ]
    }
   ],
   "source": [
    "with open(GS_SCHEMA_PATH, mode='r') as f:\n",
    "    dictschema = yaml.load(f)\n",
    "\n",
    "print([ i\n",
    "    for i in dictschema])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC',\n",
      "       'CTREE', 'PRED', 'ARG'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(GS_PATH, sep=',', encoding='utf-8', index_col=0)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loads gs_column_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC',\n",
      "       'CTREE', 'PRED', 'ARG', 'FORM+1', 'FORM+2', 'FORM+3', 'FORM-1',\n",
      "       'FORM-2', 'FORM-3', 'FUNC+1', 'FUNC+2', 'FUNC+3', 'FUNC-1', 'FUNC-2',\n",
      "       'FUNC-3', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3', 'LEMMA-1', 'LEMMA-2',\n",
      "       'LEMMA-3', 'GPOS+1', 'GPOS+2', 'GPOS+3', 'GPOS-1', 'GPOS-2', 'GPOS-3',\n",
      "       'LEMMA_CTX_P+0', 'LEMMA_CTX_P+1', 'LEMMA_CTX_P-1', 'GPOS_CTX_P+0',\n",
      "       'GPOS_CTX_P+1', 'GPOS_CTX_P-1', 'FORM+1', 'FORM+2', 'FORM+3', 'FORM-1',\n",
      "       'FORM-2', 'FORM-3', 'FUNC+1', 'FUNC+2', 'FUNC+3', 'FUNC-1', 'FUNC-2',\n",
      "       'FUNC-3', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3', 'LEMMA-1', 'LEMMA-2',\n",
      "       'LEMMA-3', 'GPOS+1', 'GPOS+2', 'GPOS+3', 'GPOS-1', 'GPOS-2', 'GPOS-3',\n",
      "       'LEMMA_CTX_P+0', 'LEMMA_CTX_P+1', 'LEMMA_CTX_P-1', 'GPOS_CTX_P+0',\n",
      "       'GPOS_CTX_P+1', 'GPOS_CTX_P-1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "gs_column_paths = ('../datasets/csvs/gs_column_shifts/*','../datasets/csvs/gs_column_shifts_ctx_p/*')\n",
    "for gs_column_path in gs_column_paths:\n",
    "    for file_path in glob.glob(gs_column_path):\n",
    "        _df = pd.read_csv(file_path, sep=',', encoding='utf-8', index_col=0)\n",
    "        df = pd.concat((df, _df), axis=1, ignore_index=False)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Features per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 'ID', 'S': 'S', 'P': 'P', 'P_S': 'P_S', 'FORM': 'FORM', 'LEMMA': 'LEMMA', 'GPOS': 'GPOS', 'MORF': 'MORF', 'DTREE': 'DTREE', 'FUNC': 'FUNC', 'CTREE': 'CTREE', 'PRED': 'PRED', 'ARG': 'ARG', 'FORM+1': 'FORM', 'FORM+2': 'FORM', 'FORM+3': 'FORM', 'FORM-1': 'FORM', 'FORM-2': 'FORM', 'FORM-3': 'FORM', 'FUNC+1': 'FUNC', 'FUNC+2': 'FUNC', 'FUNC+3': 'FUNC', 'FUNC-1': 'FUNC', 'FUNC-2': 'FUNC', 'FUNC-3': 'FUNC', 'LEMMA+1': 'LEMMA', 'LEMMA+2': 'LEMMA', 'LEMMA+3': 'LEMMA', 'LEMMA-1': 'LEMMA', 'LEMMA-2': 'LEMMA', 'LEMMA-3': 'LEMMA', 'GPOS+1': 'GPOS', 'GPOS+2': 'GPOS', 'GPOS+3': 'GPOS', 'GPOS-1': 'GPOS', 'GPOS-2': 'GPOS', 'GPOS-3': 'GPOS', 'LEMMA_CTX_P+0': 'LEMMA', 'LEMMA_CTX_P+1': 'LEMMA', 'LEMMA_CTX_P-1': 'LEMMA', 'GPOS_CTX_P+0': 'GPOS', 'GPOS_CTX_P+1': 'GPOS', 'GPOS_CTX_P-1': 'GPOS'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 1, 'S': 1, 'P': 1, 'P_S': 1, 'FORM': 13290, 'LEMMA': 9071, 'GPOS': 25, 'MORF': 25, 'DTREE': 91, 'FUNC': 49, 'CTREE': 49, 'PRED': 1027, 'ARG': 60, 'FORM+1': 13290, 'FORM+2': 13290, 'FORM+3': 13290, 'FORM-1': 13290, 'FORM-2': 13290, 'FORM-3': 13290, 'FUNC+1': 49, 'FUNC+2': 49, 'FUNC+3': 49, 'FUNC-1': 49, 'FUNC-2': 49, 'FUNC-3': 49, 'LEMMA+1': 9071, 'LEMMA+2': 9071, 'LEMMA+3': 9071, 'LEMMA-1': 9071, 'LEMMA-2': 9071, 'LEMMA-3': 9071, 'GPOS+1': 25, 'GPOS+2': 25, 'GPOS+3': 25, 'GPOS-1': 25, 'GPOS-2': 25, 'GPOS-3': 25, 'LEMMA_CTX_P+0': 9071, 'LEMMA_CTX_P+1': 9071, 'LEMMA_CTX_P-1': 9071, 'GPOS_CTX_P+0': 25, 'GPOS_CTX_P+1': 25, 'GPOS_CTX_P-1': 25}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_mapper = {col: re.sub(r'[\\+|\\-|\\d|]|(_CTX_P)', '', col) for col in df.columns.tolist()}\n",
    "\n",
    "dimension_mapper = {colfeat:len(dictschema[colbase].get('domain',[1]))\n",
    "          for colfeat, colbase in columns_mapper.items()}\n",
    "          \n",
    "def bounds_fn(columns, embeddings_size, dimension_mapper, columns_mapper):\n",
    "    bmapper = {}\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        if is_dense(col, columns_mapper):\n",
    "            ub = lb +  embeddings_size        \n",
    "        else:\n",
    "            ub = lb +  dimension_mapper[col]            \n",
    "        bmapper[col] = {'lb': lb, 'ub':ub }\n",
    "        lb = ub + 1\n",
    "    return bmapper\n",
    "\n",
    "def is_dense(col, columns_mapper):\n",
    "    return columns_mapper[col] in ('FORM', 'LEMMA', 'PRED')\n",
    "\n",
    "print(dimension_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ARG', 'CTREE', 'DTREE', 'FORM', 'FUNC', 'GPOS', 'LEMMA', 'MORF', 'PRED'])\n",
      "dict_keys(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED', 'ARG', 'FORM+1', 'FORM+2', 'FORM+3', 'FORM-1', 'FORM-2', 'FORM-3', 'FUNC+1', 'FUNC+2', 'FUNC+3', 'FUNC-1', 'FUNC-2', 'FUNC-3', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3', 'LEMMA-1', 'LEMMA-2', 'LEMMA-3', 'GPOS+1', 'GPOS+2', 'GPOS+3', 'GPOS-1', 'GPOS-2', 'GPOS-3', 'LEMMA_CTX_P+0', 'LEMMA_CTX_P+1', 'LEMMA_CTX_P-1', 'GPOS_CTX_P+0', 'GPOS_CTX_P+1', 'GPOS_CTX_P-1'])\n"
     ]
    }
   ],
   "source": [
    "lexicons = {col : \n",
    "                dict(\n",
    "                     zip(dictschema[col]['domain'], \n",
    "                         range(1, dimension_mapper[col]+1)\n",
    "                        )\n",
    "                    )\n",
    "             for col in dictschema if 'domain' in dictschema[col]}\n",
    "\n",
    "\n",
    "columns = ['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED',\n",
    "          'FORM-3', 'FORM-2', 'FORM-1', 'FORM+1', 'FORM+2', 'FORM+3',\n",
    "          'LEMMA-3', 'LEMMA-2', 'LEMMA-1', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3',\n",
    "          'GPOS-3', 'GPOS-2', 'GPOS-1', 'GPOS+1', 'GPOS+2', 'GPOS+3',\n",
    "          'FUNC-3', 'FUNC-2', 'FUNC-1', 'FUNC+1', 'FUNC+2', 'FUNC+3'\n",
    "          'GPOS_CTX_P-1', 'GPOS_CTX_P+0', 'GPOS_CTX_P+1',\n",
    "          'LEMMA_CTX_P-1', 'LEMMA_CTX_P+0', 'LEMMA_CTX_P+1']\n",
    "\n",
    "\n",
    "d = df.to_dict()\n",
    "\n",
    "print(lexicons.keys())\n",
    "print(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5161: 1,\n",
       " 16801: 1,\n",
       " 22364: 1,\n",
       " 22386: 1,\n",
       " 22417: 1,\n",
       " 22518: 1,\n",
       " 22551: 1,\n",
       " 22896: 1,\n",
       " 23627: 1,\n",
       " 36917: 1,\n",
       " 50207: 1,\n",
       " 70755: 1,\n",
       " 79699: 1,\n",
       " 99169: 1,\n",
       " 103367: 1,\n",
       " 112438: 1,\n",
       " 121509: 1,\n",
       " 135594: 1,\n",
       " 144870: 1,\n",
       " 155001: 1,\n",
       " 157793: 1,\n",
       " 157818: 1,\n",
       " 157843: 1,\n",
       " 157877: 1,\n",
       " 157914: 1,\n",
       " 157929: 1,\n",
       " 157943: 1,\n",
       " 157992: 1,\n",
       " 158041: 1,\n",
       " 158095: 1,\n",
       " 158173: 1,\n",
       " 158204: 1}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [] \n",
    "sparse_features = defaultdict(dict)\n",
    "propositions = []        \n",
    "\n",
    "for idx, propid in d['P'].items():\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        base_col = columns_mapper[col]\n",
    "        categorical = d[col][idx] \n",
    "        if categorical in lexicons[base_col]:\n",
    "            idx1 = lexicons[base_col][categorical]\n",
    "            sparse_features[idx][lb + idx1]=1 \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse_features[idx][lb]=1 \n",
    "        lb += dimension_mapper[col] \n",
    "\n",
    "    args.append(lexicons['ARG'][d['ARG'][idx]]) \n",
    "    propositions.append( propid )\n",
    "\n",
    "        \n",
    "sparse_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26, 14, 26, 34, 31]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>S</th>\n",
       "      <th>P</th>\n",
       "      <th>P_S</th>\n",
       "      <th>FORM</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>GPOS</th>\n",
       "      <th>MORF</th>\n",
       "      <th>DTREE</th>\n",
       "      <th>FUNC</th>\n",
       "      <th>...</th>\n",
       "      <th>LEMMA+3</th>\n",
       "      <th>LEMMA-1</th>\n",
       "      <th>LEMMA-2</th>\n",
       "      <th>LEMMA-3</th>\n",
       "      <th>GPOS+1</th>\n",
       "      <th>GPOS+2</th>\n",
       "      <th>GPOS+3</th>\n",
       "      <th>GPOS-1</th>\n",
       "      <th>GPOS-2</th>\n",
       "      <th>GPOS-3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>PROP</td>\n",
       "      <td>F|S</td>\n",
       "      <td>5</td>\n",
       "      <td>ADVL</td>\n",
       "      <td>...</td>\n",
       "      <td>hoje</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>V-PCP</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  S  P  P_S      FORM     LEMMA  GPOS MORF  DTREE  FUNC  ...    \\\n",
       "INDEX                                                             ...     \n",
       "0       1  1  1    0  Brasília  Brasília  PROP  F|S      5  ADVL  ...     \n",
       "\n",
       "      LEMMA+3 LEMMA-1 LEMMA-2 LEMMA-3 GPOS+1 GPOS+2 GPOS+3 GPOS-1 GPOS-2  \\\n",
       "INDEX                                                                      \n",
       "0        hoje     NaN     NaN     NaN      N  V-PCP    ADV    NaN    NaN   \n",
       "\n",
       "      GPOS-3  \n",
       "INDEX         \n",
       "0        NaN  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FORM .: first sparse feature = lexicons['FORM']['Brasília'] --> 134\n",
    "# LEMMA .: second sparse feature = dimension_mapper['FORM'] + lexicons['LEMMA']['Brasília'] --> 13386\n",
    "# GPOS .: third sparse feature =  dimension_mapper['FORM'] +  dimension_mapper['LEMMA'] + lexicons['GPOS']['PROP'] --> 22362\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convert ARGS into T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*', 'A0', 'A0', 'A0', 'V']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments = [value for key, value in d['ARG'].items()] \n",
    "targets = propbankbr_arg2t(propositions, arguments)\n",
    "\n",
    "targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_keys = set(targets)\n",
    "target_idxs = range(len(target_keys))\n",
    "targets_mapper = dict(zip(target_keys, target_idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save onehot representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds_type in ('train', 'test', 'valid'):    \n",
    "    if ds_type in ('train'):                \n",
    "      lb = 0\n",
    "      ub = DATASET_TRAIN_SIZE \n",
    "\n",
    "    if ds_type in ('valid'):                \n",
    "      lb = DATASET_TRAIN_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE\n",
    "\n",
    "    if ds_type in ('test'):                \n",
    "      lb = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE + DATASET_TEST_SIZE\n",
    "        \n",
    "    # saves the processed data\n",
    "    svm_path = '{:}/{:}/{:}.svm'.format(SVM_DIR, 'hot', ds_type)\n",
    "    with open(svm_path, mode='w') as f:\n",
    "        for idx in sparse_features:\n",
    "            p = propositions[idx]\n",
    "            if p > lb and p < ub + 1:\n",
    "                target = '{:} '.format(int(targets_mapper[targets[idx]]))\n",
    "                features = ' '.join([ '{:}:{:}'.format(key, val) \n",
    "                     for key, val in sparse_features[idx].items()])\n",
    "                ex = '{:}{:}\\n'.format(target, features)\n",
    "                f.write(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(GLOVE_S50_PATH, unicode_errors=\"ignore\")\n",
    "embeddings_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# converts a word into a token,\n",
    "# word might be in fact a number\n",
    "def tokenize(word):\n",
    "    token = word\n",
    "    if is_number(word):\n",
    "        token = '0'    \n",
    "    elif word.lower() in word2vec:\n",
    "        token = word.lower()\n",
    "    else:\n",
    "        token = 'unk'\n",
    "    return token\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Process replacing sparse with feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -0.35242301,\n",
       " 1: 0.52991003,\n",
       " 2: 1.378052,\n",
       " 3: -2.6353519,\n",
       " 4: 0.064434998,\n",
       " 5: 0.51971298,\n",
       " 6: -0.89432102,\n",
       " 7: -1.146332,\n",
       " 8: -0.71181601,\n",
       " 9: 0.21502399,\n",
       " 10: -0.32224,\n",
       " 11: -0.087746002,\n",
       " 12: 0.54578102,\n",
       " 13: -0.072255999,\n",
       " 14: -0.138069,\n",
       " 15: -1.0330909,\n",
       " 16: 0.374457,\n",
       " 17: 0.41515201,\n",
       " 18: 0.062208001,\n",
       " 19: 0.061988998,\n",
       " 20: 0.53525698,\n",
       " 21: -0.57822698,\n",
       " 22: -0.77802098,\n",
       " 23: -1.77086,\n",
       " 24: -0.867414,\n",
       " 25: 0.44269899,\n",
       " 26: -0.81675398,\n",
       " 27: -0.23604099,\n",
       " 28: -0.16220599,\n",
       " 29: 0.226478,\n",
       " 30: 0.839167,\n",
       " 31: -0.069043003,\n",
       " 32: -0.37729999,\n",
       " 33: -0.138179,\n",
       " 34: -0.15516201,\n",
       " 35: 0.137887,\n",
       " 36: 0.052816,\n",
       " 37: 0.47624999,\n",
       " 38: -0.54324901,\n",
       " 39: -0.35822999,\n",
       " 40: -0.21709099,\n",
       " 41: 0.26028901,\n",
       " 42: 0.0069400002,\n",
       " 43: -0.95268399,\n",
       " 44: 0.558254,\n",
       " 45: -0.28643,\n",
       " 46: -0.211694,\n",
       " 47: 0.59664899,\n",
       " 48: 0.311598,\n",
       " 49: -0.25995699,\n",
       " 50: -0.35242301,\n",
       " 51: 0.52991003,\n",
       " 52: 1.378052,\n",
       " 53: -2.6353519,\n",
       " 54: 0.064434998,\n",
       " 55: 0.51971298,\n",
       " 56: -0.89432102,\n",
       " 57: -1.146332,\n",
       " 58: -0.71181601,\n",
       " 59: 0.21502399,\n",
       " 60: -0.32224,\n",
       " 61: -0.087746002,\n",
       " 62: 0.54578102,\n",
       " 63: -0.072255999,\n",
       " 64: -0.138069,\n",
       " 65: -1.0330909,\n",
       " 66: 0.374457,\n",
       " 67: 0.41515201,\n",
       " 68: 0.062208001,\n",
       " 69: 0.061988998,\n",
       " 70: 0.53525698,\n",
       " 71: -0.57822698,\n",
       " 72: -0.77802098,\n",
       " 73: -1.77086,\n",
       " 74: -0.867414,\n",
       " 75: 0.44269899,\n",
       " 76: -0.81675398,\n",
       " 77: -0.23604099,\n",
       " 78: -0.16220599,\n",
       " 79: 0.226478,\n",
       " 80: 0.839167,\n",
       " 81: -0.069043003,\n",
       " 82: -0.37729999,\n",
       " 83: -0.138179,\n",
       " 84: -0.15516201,\n",
       " 85: 0.137887,\n",
       " 86: 0.052816,\n",
       " 87: 0.47624999,\n",
       " 88: -0.54324901,\n",
       " 89: -0.35822999,\n",
       " 90: -0.21709099,\n",
       " 91: 0.26028901,\n",
       " 92: 0.0069400002,\n",
       " 93: -0.95268399,\n",
       " 94: 0.558254,\n",
       " 95: -0.28643,\n",
       " 96: -0.211694,\n",
       " 97: 0.59664899,\n",
       " 98: 0.311598,\n",
       " 99: -0.25995699,\n",
       " 100: 1,\n",
       " 125: 1,\n",
       " 150: 1,\n",
       " 241: 1,\n",
       " 290: 1,\n",
       " 339: -0.13177501,\n",
       " 340: 0.119078,\n",
       " 341: -0.62300402,\n",
       " 342: -4.10287,\n",
       " 343: 0.116101,\n",
       " 344: 0.017778,\n",
       " 345: 0.125692,\n",
       " 346: -0.69134402,\n",
       " 347: -0.73476398,\n",
       " 348: 0.28201601,\n",
       " 349: -0.25720701,\n",
       " 350: 0.224925,\n",
       " 351: -0.044599999,\n",
       " 352: 0.81935298,\n",
       " 353: 0.137106,\n",
       " 354: -0.44178101,\n",
       " 355: -0.39970899,\n",
       " 356: 0.162916,\n",
       " 357: 0.113267,\n",
       " 358: 0.020202,\n",
       " 359: 0.874089,\n",
       " 360: -0.45386899,\n",
       " 361: -0.39280099,\n",
       " 362: 0.037046999,\n",
       " 363: -0.189419,\n",
       " 364: -0.309971,\n",
       " 365: 0.148041,\n",
       " 366: 0.84257299,\n",
       " 367: 0.29945299,\n",
       " 368: 1.765025,\n",
       " 369: -0.93225503,\n",
       " 370: -0.29690799,\n",
       " 371: 0.477245,\n",
       " 372: 0.52375001,\n",
       " 373: 0.47029299,\n",
       " 374: -0.53934997,\n",
       " 375: -0.50192899,\n",
       " 376: -0.80594897,\n",
       " 377: -0.90731901,\n",
       " 378: -0.057719,\n",
       " 379: 0.177518,\n",
       " 380: -0.015765,\n",
       " 381: -0.79582697,\n",
       " 382: -0.179671,\n",
       " 383: -0.45981801,\n",
       " 384: 0.032226,\n",
       " 385: 0.14668299,\n",
       " 386: -0.18351699,\n",
       " 387: 0.70326602,\n",
       " 388: -0.682172,\n",
       " 389: 1,\n",
       " 13679: 1,\n",
       " 26969: 1,\n",
       " 40259: 1,\n",
       " 53549: 1,\n",
       " 66839: 1,\n",
       " 80129: 1,\n",
       " 89200: 1,\n",
       " 98271: 1,\n",
       " 107342: 1,\n",
       " 116413: 1,\n",
       " 125484: 1,\n",
       " 134555: 1,\n",
       " 134580: 1,\n",
       " 134605: 1,\n",
       " 134630: 1,\n",
       " 134655: 1,\n",
       " 134680: 1,\n",
       " 134705: 1,\n",
       " 134754: 1,\n",
       " 134803: 1,\n",
       " 134852: 1,\n",
       " 134901: 1,\n",
       " 134950: 1}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [] \n",
    "sparse_features = defaultdict(dict)\n",
    "propositions = []        \n",
    "# columns = ['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED']\n",
    "bounds_mapper = defaultdict(dict)\n",
    "for idx, propid in d['P'].items():\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        base_col = columns_mapper[col]\n",
    "        word = d[col][idx] \n",
    "        if not 'lb' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['lb'] = lb \n",
    "        if col in ('FORM', 'LEMMA', 'PRED'):\n",
    "            sz = embeddings_size\n",
    "            token = tokenize(word)\n",
    "            values = list(word2vec[token])\n",
    "                \n",
    "            sparse_features[idx].update({\n",
    "                i + lb: val\n",
    "                for i, val in enumerate(values)\n",
    "            })\n",
    "        elif categorical in lexicons[base_col]:\n",
    "            idx1 = lexicons[base_col][categorical]\n",
    "            sparse_features[idx][lb + idx1]=1 \n",
    "            sz = dimension_mapper[col] \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse_features[idx][lb]=1 \n",
    "            sz = dimension_mapper[col]           \n",
    "        lb += sz\n",
    "        if not 'ub' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['ub'] = lb \n",
    "\n",
    "    args.append(lexicons['ARG'][d['ARG'][idx]]) \n",
    "    propositions.append( propid )\n",
    "\n",
    "        \n",
    "sparse_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'FORM': {'lb': 0, 'ub': 50}, 'LEMMA': {'lb': 50, 'ub': 100}, 'GPOS': {'lb': 100, 'ub': 125}, 'MORF': {'lb': 125, 'ub': 150}, 'DTREE': {'lb': 150, 'ub': 241}, 'FUNC': {'lb': 241, 'ub': 290}, 'CTREE': {'lb': 290, 'ub': 339}, 'PRED': {'lb': 339, 'ub': 389}, 'FORM-3': {'lb': 389, 'ub': 13679}, 'FORM-2': {'lb': 13679, 'ub': 26969}, 'FORM-1': {'lb': 26969, 'ub': 40259}, 'FORM+1': {'lb': 40259, 'ub': 53549}, 'FORM+2': {'lb': 53549, 'ub': 66839}, 'FORM+3': {'lb': 66839, 'ub': 80129}, 'LEMMA-3': {'lb': 80129, 'ub': 89200}, 'LEMMA-2': {'lb': 89200, 'ub': 98271}, 'LEMMA-1': {'lb': 98271, 'ub': 107342}, 'LEMMA+1': {'lb': 107342, 'ub': 116413}, 'LEMMA+2': {'lb': 116413, 'ub': 125484}, 'LEMMA+3': {'lb': 125484, 'ub': 134555}, 'GPOS-3': {'lb': 134555, 'ub': 134580}, 'GPOS-2': {'lb': 134580, 'ub': 134605}, 'GPOS-1': {'lb': 134605, 'ub': 134630}, 'GPOS+1': {'lb': 134630, 'ub': 134655}, 'GPOS+2': {'lb': 134655, 'ub': 134680}, 'GPOS+3': {'lb': 134680, 'ub': 134705}, 'FUNC-3': {'lb': 134705, 'ub': 134754}, 'FUNC-2': {'lb': 134754, 'ub': 134803}, 'FUNC-1': {'lb': 134803, 'ub': 134852}, 'FUNC+1': {'lb': 134852, 'ub': 134901}, 'FUNC+2': {'lb': 134901, 'ub': 134950}, 'FUNC+3': {'lb': 134950, 'ub': 134999}})\n"
     ]
    }
   ],
   "source": [
    "print(bounds_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Scale mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "390",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-9d8db503d4a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msparse_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0mseries_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# standardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 390"
     ]
    }
   ],
   "source": [
    "series_d = defaultdict(list)\n",
    "for col in columns:\n",
    "    if is_dense(col, columns_mapper):\n",
    "        lb = bounds_mapper[col]['lb']\n",
    "        ub = bounds_mapper[col]['ub']                \n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                series_d[x].append(sparse_features[idx][x])\n",
    "\n",
    "        # standardize\n",
    "        for f in range(lb, ub):\n",
    "            n = len(series_d[f])\n",
    "            mu_x = sum(series_d[f]) / n\n",
    "            ssq_x = sum([(x - mu_x)*(x - mu_x) for x in series_d[f]])\n",
    "            std_x = math.sqrt(ssq_x/ (n-1))\n",
    "            \n",
    "            series_d[f] = [(x - mu_x)/ std_x for x in series_d[f]]            \n",
    "        # rescale\n",
    "        for f in range(lb, ub):\n",
    "            min_x = min(series_d[f])\n",
    "            max_x = max(series_d[f])\n",
    "            series_d[f] = [\n",
    "                (2*x - min_x - max_x)/ (max_x - min_x)\n",
    "                for x in series_d[f]\n",
    "            ]            \n",
    "        # move rescaled and standardized back to sparse_features\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                sparse_features[idx][x] = series_d[x][idx]\n",
    "\n",
    "        # round values\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):                \n",
    "                sparse_features[idx][x] = round(sparse_features[idx][x], 4)\n",
    "            \n",
    "                \n",
    "        \n",
    "sparse_features[0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Save mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds_type in ('train', 'test', 'valid'):    \n",
    "    if ds_type in ('train'):                \n",
    "      lb = 0\n",
    "      ub = DATASET_TRAIN_SIZE \n",
    "\n",
    "    if ds_type in ('valid'):                \n",
    "      lb = DATASET_TRAIN_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE\n",
    "\n",
    "    if ds_type in ('test'):                \n",
    "      lb = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE + DATASET_TEST_SIZE\n",
    "        \n",
    "    # saves the processed data\n",
    "    svm_path = '{:}/{:}/{:}.svm'.format(SVM_DIR, 'glo', ds_type)\n",
    "    with open(svm_path, mode='w') as f:\n",
    "        for idx in sparse_features:\n",
    "            p = propositions[idx]\n",
    "            if p > lb and p < ub + 1:\n",
    "                target = '{:} '.format(int(targets_mapper[targets[idx]]))\n",
    "                features = ' '.join([ '{:}:{:}'.format(key, val) \n",
    "                     for key, val in sparse_features[idx].items()])\n",
    "                ex = '{:}{:}\\n'.format(target, features)\n",
    "                f.write(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Wang2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(WANG_S100_PATH, unicode_errors=\"ignore\")\n",
    "embeddings_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Process replacing sparse with wang2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -0.52029401,\n",
       " 1: -1.084011,\n",
       " 2: 0.57885402,\n",
       " 3: -0.63992798,\n",
       " 4: -0.038910002,\n",
       " 5: 0.62952298,\n",
       " 6: -0.082349002,\n",
       " 7: 0.29049999,\n",
       " 8: -0.83230901,\n",
       " 9: 0.70121199,\n",
       " 10: -0.115194,\n",
       " 11: 0.22070201,\n",
       " 12: 0.27586901,\n",
       " 13: -0.26365501,\n",
       " 14: -0.177855,\n",
       " 15: 0.145326,\n",
       " 16: 0.58414203,\n",
       " 17: -0.49399501,\n",
       " 18: 0.089759,\n",
       " 19: 0.47134301,\n",
       " 20: 0.16844399,\n",
       " 21: -0.239599,\n",
       " 22: -0.035000999,\n",
       " 23: -0.318086,\n",
       " 24: -0.044199001,\n",
       " 25: 0.39588401,\n",
       " 26: 0.51004899,\n",
       " 27: 0.461573,\n",
       " 28: 0.36443901,\n",
       " 29: -0.147663,\n",
       " 30: 0.012673,\n",
       " 31: 0.469439,\n",
       " 32: -0.54493499,\n",
       " 33: 0.60724401,\n",
       " 34: -0.32190999,\n",
       " 35: -0.0071990001,\n",
       " 36: 0.043249,\n",
       " 37: -0.38506499,\n",
       " 38: -0.35674,\n",
       " 39: -0.47903901,\n",
       " 40: -0.31924799,\n",
       " 41: 0.155983,\n",
       " 42: 0.091351002,\n",
       " 43: -0.218468,\n",
       " 44: 0.14129899,\n",
       " 45: 0.481749,\n",
       " 46: 0.077671997,\n",
       " 47: 0.19820599,\n",
       " 48: -0.72299701,\n",
       " 49: -0.33969,\n",
       " 50: -0.055128001,\n",
       " 51: -0.31261799,\n",
       " 52: -0.64407998,\n",
       " 53: -0.31589401,\n",
       " 54: -0.61545199,\n",
       " 55: 0.708318,\n",
       " 56: 0.106625,\n",
       " 57: -0.15074199,\n",
       " 58: -0.47371799,\n",
       " 59: 0.30649301,\n",
       " 60: -0.403703,\n",
       " 61: 0.87191802,\n",
       " 62: 0.071199,\n",
       " 63: -0.237854,\n",
       " 64: 0.084390998,\n",
       " 65: 0.102083,\n",
       " 66: 0.524333,\n",
       " 67: -0.48130101,\n",
       " 68: 0.433521,\n",
       " 69: 0.73176497,\n",
       " 70: 0.051911999,\n",
       " 71: -0.126195,\n",
       " 72: 0.293378,\n",
       " 73: -0.27858999,\n",
       " 74: -0.53096598,\n",
       " 75: 0.37584201,\n",
       " 76: -0.30789599,\n",
       " 77: 0.19755299,\n",
       " 78: -0.33704001,\n",
       " 79: 0.132925,\n",
       " 80: 0.22403,\n",
       " 81: 0.16534901,\n",
       " 82: -0.386498,\n",
       " 83: 0.044962998,\n",
       " 84: -0.10936,\n",
       " 85: 0.744672,\n",
       " 86: -0.292669,\n",
       " 87: -0.183264,\n",
       " 88: 1.053728,\n",
       " 89: -1.050774,\n",
       " 90: 0.272176,\n",
       " 91: 0.51497102,\n",
       " 92: 0.27353001,\n",
       " 93: -0.23726299,\n",
       " 94: 0.189299,\n",
       " 95: 0.049828999,\n",
       " 96: -0.55716801,\n",
       " 97: 0.25677899,\n",
       " 98: -0.101224,\n",
       " 99: -0.85618502,\n",
       " 100: -0.52029401,\n",
       " 101: -1.084011,\n",
       " 102: 0.57885402,\n",
       " 103: -0.63992798,\n",
       " 104: -0.038910002,\n",
       " 105: 0.62952298,\n",
       " 106: -0.082349002,\n",
       " 107: 0.29049999,\n",
       " 108: -0.83230901,\n",
       " 109: 0.70121199,\n",
       " 110: -0.115194,\n",
       " 111: 0.22070201,\n",
       " 112: 0.27586901,\n",
       " 113: -0.26365501,\n",
       " 114: -0.177855,\n",
       " 115: 0.145326,\n",
       " 116: 0.58414203,\n",
       " 117: -0.49399501,\n",
       " 118: 0.089759,\n",
       " 119: 0.47134301,\n",
       " 120: 0.16844399,\n",
       " 121: -0.239599,\n",
       " 122: -0.035000999,\n",
       " 123: -0.318086,\n",
       " 124: -0.044199001,\n",
       " 125: 0.39588401,\n",
       " 126: 0.51004899,\n",
       " 127: 0.461573,\n",
       " 128: 0.36443901,\n",
       " 129: -0.147663,\n",
       " 130: 0.012673,\n",
       " 131: 0.469439,\n",
       " 132: -0.54493499,\n",
       " 133: 0.60724401,\n",
       " 134: -0.32190999,\n",
       " 135: -0.0071990001,\n",
       " 136: 0.043249,\n",
       " 137: -0.38506499,\n",
       " 138: -0.35674,\n",
       " 139: -0.47903901,\n",
       " 140: -0.31924799,\n",
       " 141: 0.155983,\n",
       " 142: 0.091351002,\n",
       " 143: -0.218468,\n",
       " 144: 0.14129899,\n",
       " 145: 0.481749,\n",
       " 146: 0.077671997,\n",
       " 147: 0.19820599,\n",
       " 148: -0.72299701,\n",
       " 149: -0.33969,\n",
       " 150: -0.055128001,\n",
       " 151: -0.31261799,\n",
       " 152: -0.64407998,\n",
       " 153: -0.31589401,\n",
       " 154: -0.61545199,\n",
       " 155: 0.708318,\n",
       " 156: 0.106625,\n",
       " 157: -0.15074199,\n",
       " 158: -0.47371799,\n",
       " 159: 0.30649301,\n",
       " 160: -0.403703,\n",
       " 161: 0.87191802,\n",
       " 162: 0.071199,\n",
       " 163: -0.237854,\n",
       " 164: 0.084390998,\n",
       " 165: 0.102083,\n",
       " 166: 0.524333,\n",
       " 167: -0.48130101,\n",
       " 168: 0.433521,\n",
       " 169: 0.73176497,\n",
       " 170: 0.051911999,\n",
       " 171: -0.126195,\n",
       " 172: 0.293378,\n",
       " 173: -0.27858999,\n",
       " 174: -0.53096598,\n",
       " 175: 0.37584201,\n",
       " 176: -0.30789599,\n",
       " 177: 0.19755299,\n",
       " 178: -0.33704001,\n",
       " 179: 0.132925,\n",
       " 180: 0.22403,\n",
       " 181: 0.16534901,\n",
       " 182: -0.386498,\n",
       " 183: 0.044962998,\n",
       " 184: -0.10936,\n",
       " 185: 0.744672,\n",
       " 186: -0.292669,\n",
       " 187: -0.183264,\n",
       " 188: 1.053728,\n",
       " 189: -1.050774,\n",
       " 190: 0.272176,\n",
       " 191: 0.51497102,\n",
       " 192: 0.27353001,\n",
       " 193: -0.23726299,\n",
       " 194: 0.189299,\n",
       " 195: 0.049828999,\n",
       " 196: -0.55716801,\n",
       " 197: 0.25677899,\n",
       " 198: -0.101224,\n",
       " 199: -0.85618502,\n",
       " 200: 1,\n",
       " 225: 1,\n",
       " 250: 1,\n",
       " 341: 1,\n",
       " 390: 1,\n",
       " 439: 0.137961,\n",
       " 440: -0.40723401,\n",
       " 441: 0.052871998,\n",
       " 442: -0.031874999,\n",
       " 443: 0.74560601,\n",
       " 444: -0.224337,\n",
       " 445: 0.021869,\n",
       " 446: -0.47269499,\n",
       " 447: -0.25640199,\n",
       " 448: 0.220019,\n",
       " 449: 0.74274999,\n",
       " 450: 0.60324001,\n",
       " 451: -0.18155999,\n",
       " 452: -0.034256998,\n",
       " 453: 0.115018,\n",
       " 454: 0.40557399,\n",
       " 455: 0.48113799,\n",
       " 456: -0.34459299,\n",
       " 457: 0.38944399,\n",
       " 458: 0.208827,\n",
       " 459: -0.20047,\n",
       " 460: 0.066243999,\n",
       " 461: 0.29349899,\n",
       " 462: -0.19375899,\n",
       " 463: -0.34377,\n",
       " 464: 0.31036299,\n",
       " 465: 0.24153,\n",
       " 466: 0.31575301,\n",
       " 467: 0.179635,\n",
       " 468: 0.111344,\n",
       " 469: 0.115479,\n",
       " 470: 0.077885002,\n",
       " 471: -0.099453002,\n",
       " 472: -0.30831999,\n",
       " 473: -0.44126999,\n",
       " 474: -0.303119,\n",
       " 475: -0.033282001,\n",
       " 476: -0.57817298,\n",
       " 477: -0.276618,\n",
       " 478: -0.56031102,\n",
       " 479: -0.299288,\n",
       " 480: 0.098879002,\n",
       " 481: 0.2237,\n",
       " 482: -0.092825003,\n",
       " 483: -0.18926901,\n",
       " 484: 0.88391101,\n",
       " 485: -0.349953,\n",
       " 486: 0.056129999,\n",
       " 487: 0.48563701,\n",
       " 488: 0.23273601,\n",
       " 489: -0.540416,\n",
       " 490: -0.24455699,\n",
       " 491: 0.210683,\n",
       " 492: 0.059089001,\n",
       " 493: -0.51285398,\n",
       " 494: -0.080779999,\n",
       " 495: 0.114038,\n",
       " 496: 0.121438,\n",
       " 497: -0.187953,\n",
       " 498: 0.140093,\n",
       " 499: 0.042066,\n",
       " 500: 0.111179,\n",
       " 501: 0.911865,\n",
       " 502: -0.103896,\n",
       " 503: -0.050174002,\n",
       " 504: 0.463498,\n",
       " 505: 0.53728801,\n",
       " 506: 0.064563997,\n",
       " 507: 0.91207498,\n",
       " 508: 0.63691998,\n",
       " 509: -0.148498,\n",
       " 510: -0.011893,\n",
       " 511: -0.086809002,\n",
       " 512: 0.25254101,\n",
       " 513: -0.216534,\n",
       " 514: -0.083806999,\n",
       " 515: 0.069761001,\n",
       " 516: 0.26986,\n",
       " 517: -0.160542,\n",
       " 518: -0.026272001,\n",
       " 519: 0.15245301,\n",
       " 520: 0.473019,\n",
       " 521: 0.074653,\n",
       " 522: 0.057535999,\n",
       " 523: 0.0055359998,\n",
       " 524: 0.21799099,\n",
       " 525: 0.046466999,\n",
       " 526: -0.20648099,\n",
       " 527: 0.75293398,\n",
       " 528: 0.191084,\n",
       " 529: -0.519117,\n",
       " 530: 0.076277003,\n",
       " 531: -0.66232002,\n",
       " 532: 0.131412,\n",
       " 533: -0.187397,\n",
       " 534: -0.128473,\n",
       " 535: -0.56984401,\n",
       " 536: -0.349709,\n",
       " 537: -0.45932299,\n",
       " 538: 0.203252}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [] \n",
    "sparse_features = defaultdict(dict)\n",
    "propositions = []        \n",
    "columns = ['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED']\n",
    "bounds_mapper = defaultdict(dict)\n",
    "for idx, propid in d['P'].items():\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        base_col = columns_mapper[col]\n",
    "        word = d[col][idx] \n",
    "        if not 'lb' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['lb'] = lb \n",
    "        if base_col in ('FORM', 'LEMMA', 'PRED'):\n",
    "            sz = embeddings_size\n",
    "            token = tokenize(word)\n",
    "            values = list(word2vec[token])\n",
    "                \n",
    "            sparse_features[idx].update({\n",
    "                i + lb: val\n",
    "                for i, val in enumerate(values)\n",
    "            })\n",
    "        elif categorical in lexicons[base_col]:\n",
    "            idx1 = lexicons[base_col][categorical]\n",
    "            sparse_features[idx][lb + idx1]=1 \n",
    "            sz = dimension_mapper[col] \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse_features[idx][lb]=1 \n",
    "            sz = dimension_mapper[col]           \n",
    "        lb += sz\n",
    "        if not 'ub' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['ub'] = lb \n",
    "\n",
    "    args.append(lexicons['ARG'][d['ARG'][idx]]) \n",
    "    propositions.append( propid )\n",
    "\n",
    "        \n",
    "sparse_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Scale mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -0.41410000000000002,\n",
       " 1: -0.4829,\n",
       " 2: 0.043400000000000001,\n",
       " 3: -0.45650000000000002,\n",
       " 4: 0.1202,\n",
       " 5: 0.45839999999999997,\n",
       " 6: 0.035799999999999998,\n",
       " 7: 0.40610000000000002,\n",
       " 8: -0.34379999999999999,\n",
       " 9: 0.26929999999999998,\n",
       " 10: -0.13420000000000001,\n",
       " 11: 0.0562,\n",
       " 12: 0.3216,\n",
       " 13: 0.37890000000000001,\n",
       " 14: -0.055599999999999997,\n",
       " 15: 0.044499999999999998,\n",
       " 16: 0.02,\n",
       " 17: -0.50980000000000003,\n",
       " 18: -0.13619999999999999,\n",
       " 19: 0.3488,\n",
       " 20: 0.24279999999999999,\n",
       " 21: -0.39300000000000002,\n",
       " 22: -0.28570000000000001,\n",
       " 23: 0.26250000000000001,\n",
       " 24: 0.085099999999999995,\n",
       " 25: 0.33279999999999998,\n",
       " 26: 0.26869999999999999,\n",
       " 27: 0.32240000000000002,\n",
       " 28: 0.11899999999999999,\n",
       " 29: -0.0134,\n",
       " 30: 0.016,\n",
       " 31: 0.52170000000000005,\n",
       " 32: 0.1469,\n",
       " 33: 0.13639999999999999,\n",
       " 34: -0.0654,\n",
       " 35: -0.085599999999999996,\n",
       " 36: -0.111,\n",
       " 37: 0.0012999999999999999,\n",
       " 38: -0.38929999999999998,\n",
       " 39: 0.081000000000000003,\n",
       " 40: -0.36470000000000002,\n",
       " 41: -0.079399999999999998,\n",
       " 42: 0.033300000000000003,\n",
       " 43: 0.049500000000000002,\n",
       " 44: -0.015900000000000001,\n",
       " 45: 0.078600000000000003,\n",
       " 46: 0.15709999999999999,\n",
       " 47: 0.050799999999999998,\n",
       " 48: -0.1394,\n",
       " 49: -0.18129999999999999,\n",
       " 50: -0.1678,\n",
       " 51: -0.11459999999999999,\n",
       " 52: -0.40870000000000001,\n",
       " 53: -0.27589999999999998,\n",
       " 54: -0.19120000000000001,\n",
       " 55: 0.62309999999999999,\n",
       " 56: -0.0223,\n",
       " 57: -0.0155,\n",
       " 58: -0.2974,\n",
       " 59: 0.2737,\n",
       " 60: -0.31519999999999998,\n",
       " 61: 0.59819999999999995,\n",
       " 62: -0.2132,\n",
       " 63: -0.21870000000000001,\n",
       " 64: -0.015699999999999999,\n",
       " 65: -0.2848,\n",
       " 66: 0.28249999999999997,\n",
       " 67: -0.13489999999999999,\n",
       " 68: -0.046300000000000001,\n",
       " 69: 0.54269999999999996,\n",
       " 70: 0.065600000000000006,\n",
       " 71: 0.026800000000000001,\n",
       " 72: -0.035099999999999999,\n",
       " 73: -0.15160000000000001,\n",
       " 74: -0.108,\n",
       " 75: 0.094700000000000006,\n",
       " 76: -0.032500000000000001,\n",
       " 77: 0.19070000000000001,\n",
       " 78: 0.092799999999999994,\n",
       " 79: 0.30249999999999999,\n",
       " 80: 0.0195,\n",
       " 81: -0.12139999999999999,\n",
       " 82: -0.081299999999999997,\n",
       " 83: -0.052299999999999999,\n",
       " 84: -0.28960000000000002,\n",
       " 85: 0.094700000000000006,\n",
       " 86: -0.21970000000000001,\n",
       " 87: -0.1552,\n",
       " 88: 0.37659999999999999,\n",
       " 89: -0.51780000000000004,\n",
       " 90: 0.31309999999999999,\n",
       " 91: 0.21210000000000001,\n",
       " 92: 0.28970000000000001,\n",
       " 93: -0.28620000000000001,\n",
       " 94: 0.085000000000000006,\n",
       " 95: 0.073700000000000002,\n",
       " 96: -0.50490000000000002,\n",
       " 97: -0.17949999999999999,\n",
       " 98: 0.080000000000000002,\n",
       " 99: -0.4733,\n",
       " 100: -0.4587,\n",
       " 101: -0.49880000000000002,\n",
       " 102: 0.088099999999999998,\n",
       " 103: -0.48099999999999998,\n",
       " 104: 0.1202,\n",
       " 105: 0.35659999999999997,\n",
       " 106: 0.1197,\n",
       " 107: 0.35239999999999999,\n",
       " 108: -0.31019999999999998,\n",
       " 109: 0.2046,\n",
       " 110: -0.33850000000000002,\n",
       " 111: 0.0562,\n",
       " 112: 0.3216,\n",
       " 113: 0.44950000000000001,\n",
       " 114: -0.1583,\n",
       " 115: 0.056599999999999998,\n",
       " 116: 0.074499999999999997,\n",
       " 117: -0.71160000000000001,\n",
       " 118: -0.1094,\n",
       " 119: 0.45090000000000002,\n",
       " 120: 0.10879999999999999,\n",
       " 121: -0.40550000000000003,\n",
       " 122: -0.28570000000000001,\n",
       " 123: 0.26250000000000001,\n",
       " 124: 0.20999999999999999,\n",
       " 125: 0.3367,\n",
       " 126: 0.3291,\n",
       " 127: 0.1646,\n",
       " 128: -0.1201,\n",
       " 129: -0.0154,\n",
       " 130: 0.077700000000000005,\n",
       " 131: 0.52170000000000005,\n",
       " 132: -0.0195,\n",
       " 133: 0.0088999999999999999,\n",
       " 134: 0.0011000000000000001,\n",
       " 135: -0.049299999999999997,\n",
       " 136: -0.1192,\n",
       " 137: -0.011900000000000001,\n",
       " 138: -0.45150000000000001,\n",
       " 139: 0.081000000000000003,\n",
       " 140: -0.29470000000000002,\n",
       " 141: -0.16400000000000001,\n",
       " 142: 0.044200000000000003,\n",
       " 143: 0.1152,\n",
       " 144: -0.032800000000000003,\n",
       " 145: 0.12709999999999999,\n",
       " 146: 0.15709999999999999,\n",
       " 147: 0.055800000000000002,\n",
       " 148: -0.085199999999999998,\n",
       " 149: -0.216,\n",
       " 150: -0.1678,\n",
       " 151: -0.15429999999999999,\n",
       " 152: -0.3896,\n",
       " 153: -0.26390000000000002,\n",
       " 154: -0.20949999999999999,\n",
       " 155: 0.64990000000000003,\n",
       " 156: -0.0223,\n",
       " 157: -0.0155,\n",
       " 158: -0.38440000000000002,\n",
       " 159: 0.27750000000000002,\n",
       " 160: -0.31519999999999998,\n",
       " 161: 0.57920000000000005,\n",
       " 162: -0.27110000000000001,\n",
       " 163: -0.3306,\n",
       " 164: 0.1368,\n",
       " 165: -0.41839999999999999,\n",
       " 166: 0.21340000000000001,\n",
       " 167: -0.23599999999999999,\n",
       " 168: -0.089800000000000005,\n",
       " 169: 0.44890000000000002,\n",
       " 170: 0.065600000000000006,\n",
       " 171: 0.1227,\n",
       " 172: 0.058999999999999997,\n",
       " 173: -0.15160000000000001,\n",
       " 174: -0.25800000000000001,\n",
       " 175: 0.19270000000000001,\n",
       " 176: 0.035799999999999998,\n",
       " 177: 0.0086999999999999994,\n",
       " 178: -0.0061999999999999998,\n",
       " 179: 0.34699999999999998,\n",
       " 180: 0.10390000000000001,\n",
       " 181: -0.16689999999999999,\n",
       " 182: -0.156,\n",
       " 183: -0.016899999999999998,\n",
       " 184: -0.26550000000000001,\n",
       " 185: 0.35580000000000001,\n",
       " 186: -0.2833,\n",
       " 187: -0.21179999999999999,\n",
       " 188: 0.17399999999999999,\n",
       " 189: -0.55579999999999996,\n",
       " 190: 0.2414,\n",
       " 191: 0.28449999999999998,\n",
       " 192: 0.1822,\n",
       " 193: -0.24690000000000001,\n",
       " 194: -0.094600000000000004,\n",
       " 195: -0.032300000000000002,\n",
       " 196: -0.53700000000000003,\n",
       " 197: -0.1847,\n",
       " 198: 0.080000000000000002,\n",
       " 199: -0.45229999999999998,\n",
       " 200: 1,\n",
       " 225: 1,\n",
       " 250: 1,\n",
       " 341: 1,\n",
       " 390: 1,\n",
       " 439: -0.14419999999999999,\n",
       " 440: -0.042200000000000001,\n",
       " 441: -0.6099,\n",
       " 442: 0.25490000000000002,\n",
       " 443: 0.31819999999999998,\n",
       " 444: -0.28939999999999999,\n",
       " 445: 0.224,\n",
       " 446: -0.3377,\n",
       " 447: -0.032899999999999999,\n",
       " 448: -0.1055,\n",
       " 449: 0.4748,\n",
       " 450: 0.24779999999999999,\n",
       " 451: -0.19059999999999999,\n",
       " 452: 0.33589999999999998,\n",
       " 453: 0.26640000000000003,\n",
       " 454: -0.060400000000000002,\n",
       " 455: 0.12770000000000001,\n",
       " 456: -0.7641,\n",
       " 457: 0.45340000000000003,\n",
       " 458: -0.30980000000000002,\n",
       " 459: 0.025499999999999998,\n",
       " 460: -0.020799999999999999,\n",
       " 461: -0.0304,\n",
       " 462: 0.43140000000000001,\n",
       " 463: -0.31680000000000003,\n",
       " 464: 0.1363,\n",
       " 465: 0.62790000000000001,\n",
       " 466: 0.218,\n",
       " 467: 0.0252,\n",
       " 468: 0.2238,\n",
       " 469: 0.1386,\n",
       " 470: -0.098400000000000001,\n",
       " 471: 0.54220000000000002,\n",
       " 472: -0.64270000000000005,\n",
       " 473: -0.52559999999999996,\n",
       " 474: -0.059400000000000001,\n",
       " 475: 0.0074999999999999997,\n",
       " 476: -0.46920000000000001,\n",
       " 477: -0.34870000000000001,\n",
       " 478: -0.26169999999999999,\n",
       " 479: -0.41499999999999998,\n",
       " 480: -0.31080000000000002,\n",
       " 481: 0.36349999999999999,\n",
       " 482: 0.39829999999999999,\n",
       " 483: -0.62139999999999995,\n",
       " 484: 0.61470000000000002,\n",
       " 485: -0.32640000000000002,\n",
       " 486: 0.067900000000000002,\n",
       " 487: 0.54169999999999996,\n",
       " 488: 0.32500000000000001,\n",
       " 489: -0.69330000000000003,\n",
       " 490: 0.029700000000000001,\n",
       " 491: 0.18160000000000001,\n",
       " 492: -0.40789999999999998,\n",
       " 493: -0.39510000000000001,\n",
       " 494: 0.40739999999999998,\n",
       " 495: 0.1701,\n",
       " 496: 0.067400000000000002,\n",
       " 497: -0.2326,\n",
       " 498: 0.41010000000000002,\n",
       " 499: -0.20200000000000001,\n",
       " 500: 0.27379999999999999,\n",
       " 501: 0.47170000000000001,\n",
       " 502: 0.18029999999999999,\n",
       " 503: -0.090700000000000003,\n",
       " 504: -0.17899999999999999,\n",
       " 505: 0.2361,\n",
       " 506: 0.3075,\n",
       " 507: -0.12509999999999999,\n",
       " 508: 0.66339999999999999,\n",
       " 509: -0.22370000000000001,\n",
       " 510: 0.082500000000000004,\n",
       " 511: -0.33789999999999998,\n",
       " 512: 0.76180000000000003,\n",
       " 513: -0.1232,\n",
       " 514: -0.16819999999999999,\n",
       " 515: 0.43659999999999999,\n",
       " 516: -0.12479999999999999,\n",
       " 517: 0.33139999999999997,\n",
       " 518: 0.2109,\n",
       " 519: -0.0177,\n",
       " 520: 0.66839999999999999,\n",
       " 521: 0.1638,\n",
       " 522: 0.1542,\n",
       " 523: -0.1106,\n",
       " 524: -0.35749999999999998,\n",
       " 525: 0.19620000000000001,\n",
       " 526: -0.11650000000000001,\n",
       " 527: -0.039,\n",
       " 528: 0.18140000000000001,\n",
       " 529: -0.58009999999999995,\n",
       " 530: -0.076499999999999999,\n",
       " 531: -1.0,\n",
       " 532: 0.00040000000000000002,\n",
       " 533: -0.31219999999999998,\n",
       " 534: 0.092299999999999993,\n",
       " 535: -0.38350000000000001,\n",
       " 536: -0.69469999999999998,\n",
       " 537: -0.035700000000000003,\n",
       " 538: 0.13420000000000001}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_d = defaultdict(list)\n",
    "for col in columns:\n",
    "    if is_dense(col, columns_mapper):\n",
    "        lb = bounds_mapper[col]['lb']\n",
    "        ub = bounds_mapper[col]['ub']                \n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                series_d[x].append(sparse_features[idx][x])\n",
    "\n",
    "        # standardize\n",
    "        for f in range(lb, ub):\n",
    "            n = len(series_d[f])\n",
    "            mu_x = sum(series_d[f]) / n\n",
    "            ssq_x = sum([(x - mu_x)*(x - mu_x) for x in series_d[f]])\n",
    "            std_x = math.sqrt(ssq_x/ (n-1))\n",
    "            \n",
    "            series_d[f] = [(x - mu_x)/ std_x for x in series_d[f]]            \n",
    "        # rescale\n",
    "        for f in range(lb, ub):\n",
    "            min_x = min(series_d[f])\n",
    "            max_x = max(series_d[f])\n",
    "            series_d[f] = [\n",
    "                (2*x - min_x - max_x)/ (max_x - min_x)\n",
    "                for x in series_d[f]\n",
    "            ]            \n",
    "        # move rescaled and standardized back to sparse_features\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                sparse_features[idx][x] = series_d[x][idx]\n",
    "\n",
    "        # round values\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):                \n",
    "                sparse_features[idx][x] = round(sparse_features[idx][x], 4)\n",
    "            \n",
    "                \n",
    "        \n",
    "sparse_features[0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Saved mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds_type in ('train', 'test', 'valid'):    \n",
    "    if ds_type in ('train'):                \n",
    "      lb = 0\n",
    "      ub = DATASET_TRAIN_SIZE \n",
    "\n",
    "    if ds_type in ('valid'):                \n",
    "      lb = DATASET_TRAIN_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE\n",
    "\n",
    "    if ds_type in ('test'):                \n",
    "      lb = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE + DATASET_TEST_SIZE\n",
    "        \n",
    "    # saves the processed data\n",
    "    svm_path = '{:}/{:}/{:}.svm'.format(SVM_DIR, 'wan', ds_type)\n",
    "    with open(svm_path, mode='w') as f:\n",
    "        for idx in sparse_features:\n",
    "            p = propositions[idx]\n",
    "            if p > lb and p < ub + 1:\n",
    "                target = '{:} '.format(int(targets_mapper[targets[idx]]))\n",
    "                features = ' '.join([ '{:}:{:}'.format(key, val) \n",
    "                     for key, val in sparse_features[idx].items()])\n",
    "                ex = '{:}{:}\\n'.format(target, features)\n",
    "                f.write(ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
