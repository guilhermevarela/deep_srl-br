{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loads Gold Standard and Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import glob \n",
    "import re\n",
    "\n",
    "DATASETS_DIR = '../datasets/csvs/'\n",
    "SCHEMAS_DIR = '../datasets/schemas/'\n",
    "\n",
    "GS_PATH = '{:}{:}'.format(DATASETS_DIR, 'gs.csv')\n",
    "GS_SCHEMA_PATH = '{:}{:}'.format(SCHEMAS_DIR, 'gs.yaml')\n",
    "\n",
    "# re_replace = re.compile(r'[\\+|\\-|\\d]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARG', 'CTREE', 'DTREE', 'FORM', 'FUNC', 'GPOS', 'ID', 'INDEX', 'LEMMA', 'MORF', 'P', 'PRED', 'P_S', 'S']\n"
     ]
    }
   ],
   "source": [
    "with open(GS_SCHEMA_PATH, mode='r') as f:\n",
    "    dictschema = yaml.load(f)\n",
    "\n",
    "print([ i\n",
    "    for i in dictschema])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC',\n",
      "       'CTREE', 'PRED', 'ARG'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(GS_PATH, sep=',', encoding='utf-8', index_col=0)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loads gs_column_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC',\n",
      "       'CTREE', 'PRED', 'ARG', 'FORM+1', 'FORM+2', 'FORM+3', 'FORM-1',\n",
      "       'FORM-2', 'FORM-3', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3', 'LEMMA-1',\n",
      "       'LEMMA-2', 'LEMMA-3', 'GPOS+1', 'GPOS+2', 'GPOS+3', 'GPOS-1', 'GPOS-2',\n",
      "       'GPOS-3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "gs_column_shift = '../datasets/csvs/gs_column_shifts/*'\n",
    "for file_path in glob.glob(gs_column_shift):\n",
    "    _df = pd.read_csv(file_path, sep=',', encoding='utf-8', index_col=0)\n",
    "    df = pd.concat((df, _df), axis=1, ignore_index=False)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Features per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 1, 'S': 1, 'P': 1, 'P_S': 1, 'FORM': 13290, 'LEMMA': 9071, 'GPOS': 25, 'MORF': 25, 'DTREE': 91, 'FUNC': 49, 'CTREE': 49, 'PRED': 1027, 'ARG': 60, 'FORM+1': 13290, 'FORM+2': 13290, 'FORM+3': 13290, 'FORM-1': 13290, 'FORM-2': 13290, 'FORM-3': 13290, 'LEMMA+1': 9071, 'LEMMA+2': 9071, 'LEMMA+3': 9071, 'LEMMA-1': 9071, 'LEMMA-2': 9071, 'LEMMA-3': 9071, 'GPOS+1': 25, 'GPOS+2': 25, 'GPOS+3': 25, 'GPOS-1': 25, 'GPOS-2': 25, 'GPOS-3': 25}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_helper = [(re.sub(r'[\\+|\\-|\\d]', '', col), col) \n",
    "                  for col in df.columns.tolist()]\n",
    "\n",
    "mapper = {rawcol:len(dictschema[basecol].get('domain',[1]))\n",
    "          for basecol, rawcol in columns_helper}\n",
    "          \n",
    "\n",
    "print(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ARG', 'CTREE', 'DTREE', 'FORM', 'FUNC', 'GPOS', 'LEMMA', 'MORF', 'PRED'])\n",
      "dict_keys(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED', 'ARG', 'FORM+1', 'FORM+2', 'FORM+3', 'FORM-1', 'FORM-2', 'FORM-3', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3', 'LEMMA-1', 'LEMMA-2', 'LEMMA-3', 'GPOS+1', 'GPOS+2', 'GPOS+3', 'GPOS-1', 'GPOS-2', 'GPOS-3'])\n"
     ]
    }
   ],
   "source": [
    "lexicons = {col : \n",
    "                dict(\n",
    "                     zip(dictschema[col]['domain'], \n",
    "                         range(1, mapper[col]+1)\n",
    "                        )\n",
    "                    )\n",
    "             for col in dictschema if 'domain' in dictschema[col]}\n",
    "\n",
    "\n",
    "columns = ['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED',\n",
    "          'FORM-3', 'FORM-2', 'FORM-1', 'FORM+1', 'FORM+2', 'FORM+3',\n",
    "          'LEMMA-3', 'LEMMA-2', 'LEMMA-1', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3',\n",
    "          'GPOS-3', 'GPOS-2', 'GPOS-1', 'GPOS+1', 'GPOS+2', 'GPOS+3']\n",
    "\n",
    "\n",
    "d = df.to_dict()\n",
    "\n",
    "print(lexicons.keys())\n",
    "print(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED', 'FORM-3', 'FORM-2', 'FORM-1', 'FORM+1', 'FORM+2', 'FORM+3', 'LEMMA-3', 'LEMMA-2', 'LEMMA-1', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3', 'GPOS-3', 'GPOS-2', 'GPOS-1', 'GPOS+1', 'GPOS+2', 'GPOS+3']\n",
      "FORM Brasília\n",
      "LEMMA Brasília\n",
      "GPOS PROP\n",
      "MORF F|S\n",
      "DTREE 5\n",
      "FUNC ADVL\n",
      "CTREE (FCL(NP*)\n",
      "PRED -\n",
      "FORM-3 nan\n",
      "FORM-2 nan\n",
      "FORM-1 nan\n",
      "FORM+1 Pesquisa_Datafolha\n",
      "FORM+2 publicada\n",
      "FORM+3 hoje\n",
      "LEMMA-3 nan\n",
      "LEMMA-2 nan\n",
      "LEMMA-1 nan\n",
      "LEMMA+1 Pesquisa_Datafolha\n",
      "LEMMA+2 publicar\n",
      "LEMMA+3 hoje\n",
      "GPOS-3 nan\n",
      "GPOS-2 nan\n",
      "GPOS-1 nan\n",
      "GPOS+1 N\n",
      "GPOS+2 V-PCP\n",
      "GPOS+3 ADV\n",
      "FORM Pesquisa_Datafolha\n",
      "LEMMA Pesquisa_Datafolha\n",
      "GPOS N\n",
      "MORF F|S\n",
      "DTREE 5\n",
      "FUNC SUBJ\n",
      "CTREE (NP*\n",
      "PRED -\n",
      "FORM-3 nan\n",
      "FORM-2 nan\n",
      "FORM-1 Brasília\n",
      "FORM+1 publicada\n",
      "FORM+2 hoje\n",
      "FORM+3 revela\n",
      "LEMMA-3 nan\n",
      "LEMMA-2 nan\n",
      "LEMMA-1 Brasília\n",
      "LEMMA+1 publicar\n",
      "LEMMA+2 hoje\n",
      "LEMMA+3 revelar\n",
      "GPOS-3 nan\n",
      "GPOS-2 nan\n",
      "GPOS-1 PROP\n",
      "GPOS+1 V-PCP\n",
      "GPOS+2 ADV\n",
      "GPOS+3 V-FIN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(columns)\n",
    "sparse = defaultdict(dict)\n",
    "for idx in range(2):\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        categorical = d[col][idx] \n",
    "        if categorical in lexicons[col]:\n",
    "            sparse[idx][lb+lexicons[col][d[col][idx]]] \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse[idx][lb+lexicons[col][d[col][idx]]] \n",
    "            lb += mapper[col] \n",
    "\n",
    "sparse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
