{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loads Gold Standard and Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../datasets')\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import glob \n",
    "import re\n",
    "import math\n",
    "from gensim.models import KeyedVectors\n",
    "from data_propbankbr import propbankbr_arg2t\n",
    "\n",
    "DATASETS_DIR = '../datasets/csvs/'\n",
    "SCHEMAS_DIR = '../datasets/schemas/'\n",
    "SVM_DIR = '../datasets/svms/'\n",
    "EMBEDDINGS_DIR = '../datasets/txts/embeddings/'\n",
    "\n",
    "GS_PATH = '{:}{:}'.format(DATASETS_DIR, 'gs.csv')\n",
    "GS_SCHEMA_PATH = '{:}{:}'.format(SCHEMAS_DIR, 'gs.yaml')\n",
    "\n",
    "GLOVE_S50_PATH = '{:}glove_s50.txt'.format(EMBEDDINGS_DIR)\n",
    "WANG_S100_PATH = '{:}wang2vec_s100.txt'.format(EMBEDDINGS_DIR)\n",
    "\n",
    "\n",
    "\n",
    "DATASET_SIZE= 5931\n",
    "DATASET_TRAIN_SIZE= 5099\n",
    "DATASET_VALID_SIZE= 569\n",
    "DATASET_TEST_SIZE=  263\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARG', 'CTREE', 'DTREE', 'FORM', 'FUNC', 'GPOS', 'ID', 'INDEX', 'LEMMA', 'MORF', 'P', 'PRED', 'P_S', 'S']\n"
     ]
    }
   ],
   "source": [
    "with open(GS_SCHEMA_PATH, mode='r') as f:\n",
    "    dictschema = yaml.load(f)\n",
    "\n",
    "print([ i\n",
    "    for i in dictschema])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC',\n",
      "       'CTREE', 'PRED', 'ARG'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(GS_PATH, sep=',', encoding='utf-8', index_col=0)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loads gs_column_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC',\n",
      "       'CTREE', 'PRED', 'ARG', 'FORM+1', 'FORM+2', 'FORM+3', 'FORM-1',\n",
      "       'FORM-2', 'FORM-3', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3', 'LEMMA-1',\n",
      "       'LEMMA-2', 'LEMMA-3', 'GPOS+1', 'GPOS+2', 'GPOS+3', 'GPOS-1', 'GPOS-2',\n",
      "       'GPOS-3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "gs_column_shift = '../datasets/csvs/gs_column_shifts/*'\n",
    "for file_path in glob.glob(gs_column_shift):\n",
    "    _df = pd.read_csv(file_path, sep=',', encoding='utf-8', index_col=0)\n",
    "    df = pd.concat((df, _df), axis=1, ignore_index=False)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Features per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 1, 'S': 1, 'P': 1, 'P_S': 1, 'FORM': 13290, 'LEMMA': 9071, 'GPOS': 25, 'MORF': 25, 'DTREE': 91, 'FUNC': 49, 'CTREE': 49, 'PRED': 1027, 'ARG': 60, 'FORM+1': 13290, 'FORM+2': 13290, 'FORM+3': 13290, 'FORM-1': 13290, 'FORM-2': 13290, 'FORM-3': 13290, 'LEMMA+1': 9071, 'LEMMA+2': 9071, 'LEMMA+3': 9071, 'LEMMA-1': 9071, 'LEMMA-2': 9071, 'LEMMA-3': 9071, 'GPOS+1': 25, 'GPOS+2': 25, 'GPOS+3': 25, 'GPOS-1': 25, 'GPOS-2': 25, 'GPOS-3': 25}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_mapper = {col: re.sub(r'[\\+|\\-|\\d]', '', col) for col in df.columns.tolist()}\n",
    "\n",
    "dimension_mapper = {colfeat:len(dictschema[colbase].get('domain',[1]))\n",
    "          for colfeat, colbase in columns_mapper.items()}\n",
    "          \n",
    "def bounds_fn(columns, embeddings_size, dimension_mapper, columns_mapper):\n",
    "    bmapper = {}\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        if is_dense(col, columns_mapper):\n",
    "            ub = lb +  embeddings_size        \n",
    "        else:\n",
    "            ub = lb +  dimension_mapper[col]            \n",
    "        bmapper[col] = {'lb': lb, 'ub':ub }\n",
    "        lb = ub + 1\n",
    "    return bmapper\n",
    "\n",
    "def is_dense(col, columns_mapper):\n",
    "    return columns_mapper[col] in ('FORM', 'LEMMA', 'PRED')\n",
    "\n",
    "print(dimension_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ARG', 'CTREE', 'DTREE', 'FORM', 'FUNC', 'GPOS', 'LEMMA', 'MORF', 'PRED'])\n",
      "dict_keys(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED', 'ARG', 'FORM+1', 'FORM+2', 'FORM+3', 'FORM-1', 'FORM-2', 'FORM-3', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3', 'LEMMA-1', 'LEMMA-2', 'LEMMA-3', 'GPOS+1', 'GPOS+2', 'GPOS+3', 'GPOS-1', 'GPOS-2', 'GPOS-3'])\n"
     ]
    }
   ],
   "source": [
    "lexicons = {col : \n",
    "                dict(\n",
    "                     zip(dictschema[col]['domain'], \n",
    "                         range(1, dimension_mapper[col]+1)\n",
    "                        )\n",
    "                    )\n",
    "             for col in dictschema if 'domain' in dictschema[col]}\n",
    "\n",
    "\n",
    "columns = ['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED',\n",
    "          'FORM-3', 'FORM-2', 'FORM-1', 'FORM+1', 'FORM+2', 'FORM+3',\n",
    "          'LEMMA-3', 'LEMMA-2', 'LEMMA-1', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3',\n",
    "          'GPOS-3', 'GPOS-2', 'GPOS-1', 'GPOS+1', 'GPOS+2', 'GPOS+3']\n",
    "\n",
    "\n",
    "d = df.to_dict()\n",
    "\n",
    "print(lexicons.keys())\n",
    "print(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4098: 1,\n",
       " 16148: 1,\n",
       " 22378: 1,\n",
       " 22386: 1,\n",
       " 22417: 1,\n",
       " 22549: 1,\n",
       " 22551: 1,\n",
       " 23222: 1,\n",
       " 23627: 1,\n",
       " 36917: 1,\n",
       " 50207: 1,\n",
       " 69831: 1,\n",
       " 89101: 1,\n",
       " 92169: 1,\n",
       " 103367: 1,\n",
       " 112438: 1,\n",
       " 121509: 1,\n",
       " 134938: 1,\n",
       " 142802: 1,\n",
       " 150198: 1,\n",
       " 157793: 1,\n",
       " 157818: 1,\n",
       " 157843: 1,\n",
       " 157890: 1,\n",
       " 157908: 1,\n",
       " 157943: 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [] \n",
    "sparse_features = defaultdict(dict)\n",
    "propositions = []        \n",
    "\n",
    "for idx, propid in d['P'].items():\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        base_col = columns_mapper[col]\n",
    "        categorical = d[col][idx] \n",
    "        if categorical in lexicons[base_col]:\n",
    "            idx1 = lexicons[base_col][categorical]\n",
    "            sparse_features[idx][lb + idx1]=1 \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse_features[idx][lb]=1 \n",
    "        lb += dimension_mapper[col] \n",
    "\n",
    "    args.append(lexicons['ARG'][d['ARG'][idx]]) \n",
    "    propositions.append( propid )\n",
    "\n",
    "        \n",
    "sparse_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 8, 30, 45, 41]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>S</th>\n",
       "      <th>P</th>\n",
       "      <th>P_S</th>\n",
       "      <th>FORM</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>GPOS</th>\n",
       "      <th>MORF</th>\n",
       "      <th>DTREE</th>\n",
       "      <th>FUNC</th>\n",
       "      <th>...</th>\n",
       "      <th>LEMMA+3</th>\n",
       "      <th>LEMMA-1</th>\n",
       "      <th>LEMMA-2</th>\n",
       "      <th>LEMMA-3</th>\n",
       "      <th>GPOS+1</th>\n",
       "      <th>GPOS+2</th>\n",
       "      <th>GPOS+3</th>\n",
       "      <th>GPOS-1</th>\n",
       "      <th>GPOS-2</th>\n",
       "      <th>GPOS-3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>PROP</td>\n",
       "      <td>F|S</td>\n",
       "      <td>5</td>\n",
       "      <td>ADVL</td>\n",
       "      <td>...</td>\n",
       "      <td>hoje</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>V-PCP</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  S  P  P_S      FORM     LEMMA  GPOS MORF  DTREE  FUNC  ...    \\\n",
       "INDEX                                                             ...     \n",
       "0       1  1  1    0  Brasília  Brasília  PROP  F|S      5  ADVL  ...     \n",
       "\n",
       "      LEMMA+3 LEMMA-1 LEMMA-2 LEMMA-3 GPOS+1 GPOS+2 GPOS+3 GPOS-1 GPOS-2  \\\n",
       "INDEX                                                                      \n",
       "0        hoje     NaN     NaN     NaN      N  V-PCP    ADV    NaN    NaN   \n",
       "\n",
       "      GPOS-3  \n",
       "INDEX         \n",
       "0        NaN  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FORM .: first sparse feature = lexicons['FORM']['Brasília'] --> 134\n",
    "# LEMMA .: second sparse feature = dimension_mapper['FORM'] + lexicons['LEMMA']['Brasília'] --> 13386\n",
    "# GPOS .: third sparse feature =  dimension_mapper['FORM'] +  dimension_mapper['LEMMA'] + lexicons['GPOS']['PROP'] --> 22362\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convert ARGS into T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*', 'A0', 'A0', 'A0', 'V']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments = [value for key, value in d['ARG'].items()] \n",
    "targets = propbankbr_arg2t(propositions, arguments)\n",
    "\n",
    "targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_keys = set(targets)\n",
    "target_idxs = range(len(target_keys))\n",
    "targets_mapper = dict(zip(target_keys, target_idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save onehot representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds_type in ('train', 'test', 'valid'):    \n",
    "    if ds_type in ('train'):                \n",
    "      lb = 0\n",
    "      ub = DATASET_TRAIN_SIZE \n",
    "\n",
    "    if ds_type in ('valid'):                \n",
    "      lb = DATASET_TRAIN_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE\n",
    "\n",
    "    if ds_type in ('test'):                \n",
    "      lb = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE + DATASET_TEST_SIZE\n",
    "        \n",
    "    # saves the processed data\n",
    "    svm_path = '{:}/{:}/{:}.svm'.format(SVM_DIR, 'hot', ds_type)\n",
    "    with open(svm_path, mode='w') as f:\n",
    "        for idx in sparse_features:\n",
    "            p = propositions[idx]\n",
    "            if p > lb and p < ub + 1:\n",
    "                target = '{:} '.format(int(targets_mapper[targets[idx]]))\n",
    "                features = ' '.join([ '{:}:{:}'.format(key, val) \n",
    "                     for key, val in sparse_features[idx].items()])\n",
    "                ex = '{:}{:}\\n'.format(target, features)\n",
    "                f.write(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(GLOVE_S50_PATH, unicode_errors=\"ignore\")\n",
    "embeddings_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# converts a word into a token,\n",
    "# word might be in fact a number\n",
    "def tokenize(word):\n",
    "    token = word\n",
    "    if is_number(word):\n",
    "        token = '0'    \n",
    "    elif word.lower() in word2vec:\n",
    "        token = word.lower()\n",
    "    else:\n",
    "        token = 'unk'\n",
    "    return token\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Process replacing sparse with feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -0.35242301,\n",
       " 1: 0.52991003,\n",
       " 2: 1.378052,\n",
       " 3: -2.6353519,\n",
       " 4: 0.064434998,\n",
       " 5: 0.51971298,\n",
       " 6: -0.89432102,\n",
       " 7: -1.146332,\n",
       " 8: -0.71181601,\n",
       " 9: 0.21502399,\n",
       " 10: -0.32224,\n",
       " 11: -0.087746002,\n",
       " 12: 0.54578102,\n",
       " 13: -0.072255999,\n",
       " 14: -0.138069,\n",
       " 15: -1.0330909,\n",
       " 16: 0.374457,\n",
       " 17: 0.41515201,\n",
       " 18: 0.062208001,\n",
       " 19: 0.061988998,\n",
       " 20: 0.53525698,\n",
       " 21: -0.57822698,\n",
       " 22: -0.77802098,\n",
       " 23: -1.77086,\n",
       " 24: -0.867414,\n",
       " 25: 0.44269899,\n",
       " 26: -0.81675398,\n",
       " 27: -0.23604099,\n",
       " 28: -0.16220599,\n",
       " 29: 0.226478,\n",
       " 30: 0.839167,\n",
       " 31: -0.069043003,\n",
       " 32: -0.37729999,\n",
       " 33: -0.138179,\n",
       " 34: -0.15516201,\n",
       " 35: 0.137887,\n",
       " 36: 0.052816,\n",
       " 37: 0.47624999,\n",
       " 38: -0.54324901,\n",
       " 39: -0.35822999,\n",
       " 40: -0.21709099,\n",
       " 41: 0.26028901,\n",
       " 42: 0.0069400002,\n",
       " 43: -0.95268399,\n",
       " 44: 0.558254,\n",
       " 45: -0.28643,\n",
       " 46: -0.211694,\n",
       " 47: 0.59664899,\n",
       " 48: 0.311598,\n",
       " 49: -0.25995699,\n",
       " 50: -0.35242301,\n",
       " 51: 0.52991003,\n",
       " 52: 1.378052,\n",
       " 53: -2.6353519,\n",
       " 54: 0.064434998,\n",
       " 55: 0.51971298,\n",
       " 56: -0.89432102,\n",
       " 57: -1.146332,\n",
       " 58: -0.71181601,\n",
       " 59: 0.21502399,\n",
       " 60: -0.32224,\n",
       " 61: -0.087746002,\n",
       " 62: 0.54578102,\n",
       " 63: -0.072255999,\n",
       " 64: -0.138069,\n",
       " 65: -1.0330909,\n",
       " 66: 0.374457,\n",
       " 67: 0.41515201,\n",
       " 68: 0.062208001,\n",
       " 69: 0.061988998,\n",
       " 70: 0.53525698,\n",
       " 71: -0.57822698,\n",
       " 72: -0.77802098,\n",
       " 73: -1.77086,\n",
       " 74: -0.867414,\n",
       " 75: 0.44269899,\n",
       " 76: -0.81675398,\n",
       " 77: -0.23604099,\n",
       " 78: -0.16220599,\n",
       " 79: 0.226478,\n",
       " 80: 0.839167,\n",
       " 81: -0.069043003,\n",
       " 82: -0.37729999,\n",
       " 83: -0.138179,\n",
       " 84: -0.15516201,\n",
       " 85: 0.137887,\n",
       " 86: 0.052816,\n",
       " 87: 0.47624999,\n",
       " 88: -0.54324901,\n",
       " 89: -0.35822999,\n",
       " 90: -0.21709099,\n",
       " 91: 0.26028901,\n",
       " 92: 0.0069400002,\n",
       " 93: -0.95268399,\n",
       " 94: 0.558254,\n",
       " 95: -0.28643,\n",
       " 96: -0.211694,\n",
       " 97: 0.59664899,\n",
       " 98: 0.311598,\n",
       " 99: -0.25995699,\n",
       " 100: 1,\n",
       " 125: 1,\n",
       " 150: 1,\n",
       " 241: 1,\n",
       " 290: 1,\n",
       " 339: -0.13177501,\n",
       " 340: 0.119078,\n",
       " 341: -0.62300402,\n",
       " 342: -4.10287,\n",
       " 343: 0.116101,\n",
       " 344: 0.017778,\n",
       " 345: 0.125692,\n",
       " 346: -0.69134402,\n",
       " 347: -0.73476398,\n",
       " 348: 0.28201601,\n",
       " 349: -0.25720701,\n",
       " 350: 0.224925,\n",
       " 351: -0.044599999,\n",
       " 352: 0.81935298,\n",
       " 353: 0.137106,\n",
       " 354: -0.44178101,\n",
       " 355: -0.39970899,\n",
       " 356: 0.162916,\n",
       " 357: 0.113267,\n",
       " 358: 0.020202,\n",
       " 359: 0.874089,\n",
       " 360: -0.45386899,\n",
       " 361: -0.39280099,\n",
       " 362: 0.037046999,\n",
       " 363: -0.189419,\n",
       " 364: -0.309971,\n",
       " 365: 0.148041,\n",
       " 366: 0.84257299,\n",
       " 367: 0.29945299,\n",
       " 368: 1.765025,\n",
       " 369: -0.93225503,\n",
       " 370: -0.29690799,\n",
       " 371: 0.477245,\n",
       " 372: 0.52375001,\n",
       " 373: 0.47029299,\n",
       " 374: -0.53934997,\n",
       " 375: -0.50192899,\n",
       " 376: -0.80594897,\n",
       " 377: -0.90731901,\n",
       " 378: -0.057719,\n",
       " 379: 0.177518,\n",
       " 380: -0.015765,\n",
       " 381: -0.79582697,\n",
       " 382: -0.179671,\n",
       " 383: -0.45981801,\n",
       " 384: 0.032226,\n",
       " 385: 0.14668299,\n",
       " 386: -0.18351699,\n",
       " 387: 0.70326602,\n",
       " 388: -0.682172}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [] \n",
    "sparse_features = defaultdict(dict)\n",
    "propositions = []        \n",
    "columns = ['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED']\n",
    "bounds_mapper = defaultdict(dict)\n",
    "for idx, propid in d['P'].items():\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        base_col = columns_mapper[col]\n",
    "        word = d[col][idx] \n",
    "        if not 'lb' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['lb'] = lb \n",
    "        if base_col in ('FORM', 'LEMMA', 'PRED'):\n",
    "            sz = embeddings_size\n",
    "            token = tokenize(word)\n",
    "            values = list(word2vec[token])\n",
    "                \n",
    "            sparse_features[idx].update({\n",
    "                i + lb: round(val, 7) \n",
    "                for i, val in enumerate(values)\n",
    "            })\n",
    "        elif categorical in lexicons[base_col]:\n",
    "            idx1 = lexicons[base_col][categorical]\n",
    "            sparse_features[idx][lb + idx1]=1 \n",
    "            sz = dimension_mapper[col] \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse_features[idx][lb]=1 \n",
    "            sz = dimension_mapper[col]           \n",
    "        lb += sz\n",
    "        if not 'ub' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['ub'] = lb \n",
    "\n",
    "    args.append(lexicons['ARG'][d['ARG'][idx]]) \n",
    "    propositions.append( propid )\n",
    "\n",
    "        \n",
    "sparse_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'FORM': {'lb': 0, 'ub': 50}, 'LEMMA': {'lb': 50, 'ub': 100}, 'GPOS': {'lb': 100, 'ub': 125}, 'MORF': {'lb': 125, 'ub': 150}, 'DTREE': {'lb': 150, 'ub': 241}, 'FUNC': {'lb': 241, 'ub': 290}, 'CTREE': {'lb': 290, 'ub': 339}, 'PRED': {'lb': 339, 'ub': 389}})\n"
     ]
    }
   ],
   "source": [
    "print(bounds_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Scale mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_d = defaultdict(list)\n",
    "for col in columns:\n",
    "    if is_dense(col, columns_mapper):\n",
    "        lb = bounds_mapper[col]['lb']\n",
    "        ub = bounds_mapper[col]['ub']                \n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                series_d[x].append(sparse_features[idx][x])\n",
    "        # rescale\n",
    "        for d in range(lb, ub):\n",
    "            min_x = min(series_d[d])\n",
    "            max_x = max(series_d[d])\n",
    "            for x in series_d[d]:\n",
    "                if (2*x - min_x - max_x)/ (max_x - min_x) > 1 + 1e-5:\n",
    "                    import code; code.interact(local=dict(globals(), **locals()))\n",
    "                    \n",
    "            series_d[d] = [\n",
    "                (2*x - min_x - max_x)/ (max_x - min_x)\n",
    "                for x in series_d[d]\n",
    "            ]\n",
    "\n",
    "        # standardize\n",
    "        for d in range(lb, ub):\n",
    "            n = len(series_d[d])\n",
    "            mu_x = sum(series_d[d]) / n\n",
    "            ssq_x = sum([(x - mu_x)*(x - mu_x) for x in series_d[d]])\n",
    "            std_x = math.sqrt(ssq_x/ (n-1))\n",
    "            for x in series_d[d]:\n",
    "                if (x - mu_x)/ std_x  > 1 + 1e-5:\n",
    "                    import code; code.interact(local=dict(globals(), **locals()))\n",
    "                    \n",
    "            series_d[d] = [(x - mu_x)/ std_x for x in series_d[d]]\n",
    "            \n",
    "\n",
    "        # move rescaled and standardized back to sparse_features\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                sparse_features[idx][x] = series_d[x][idx]\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "sparse_features[0]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED']\n",
      "{'lb': 22607, 'ub': 23634}\n",
      "{'lb': 0, 'ub': 13290}\n"
     ]
    }
   ],
   "source": [
    "print(columns)\n",
    "print(bounds_mapper['PRED'])\n",
    "print(bounds_mapper['FORM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Save mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds_type in ('train', 'test', 'valid'):    \n",
    "    if ds_type in ('train'):                \n",
    "      lb = 0\n",
    "      ub = DATASET_TRAIN_SIZE \n",
    "\n",
    "    if ds_type in ('valid'):                \n",
    "      lb = DATASET_TRAIN_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE\n",
    "\n",
    "    if ds_type in ('test'):                \n",
    "      lb = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE + DATASET_TEST_SIZE\n",
    "        \n",
    "    # saves the processed data\n",
    "    svm_path = '{:}/{:}/{:}.svm'.format(SVM_DIR, 'glo', ds_type)\n",
    "    with open(svm_path, mode='w') as f:\n",
    "        for idx in sparse_features:\n",
    "            p = propositions[idx]\n",
    "            if p > lb and p < ub + 1:\n",
    "                target = '{:} '.format(int(targets_mapper[targets[idx]]))\n",
    "                features = ' '.join([ '{:}:{:}'.format(key, val) \n",
    "                     for key, val in sparse_features[idx].items()])\n",
    "                ex = '{:}{:}\\n'.format(target, features)\n",
    "                f.write(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Wang2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(WANG_S100_PATH, unicode_errors=\"ignore\")\n",
    "embeddings_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Process replacing sparse with wang2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -0.52029401,\n",
       " 1: -1.084011,\n",
       " 2: 0.57885402,\n",
       " 3: -0.63992798,\n",
       " 4: -0.038910002,\n",
       " 5: 0.62952298,\n",
       " 6: -0.082349002,\n",
       " 7: 0.29049999,\n",
       " 8: -0.83230901,\n",
       " 9: 0.70121199,\n",
       " 10: -0.115194,\n",
       " 11: 0.22070201,\n",
       " 12: 0.27586901,\n",
       " 13: -0.26365501,\n",
       " 14: -0.177855,\n",
       " 15: 0.145326,\n",
       " 16: 0.58414203,\n",
       " 17: -0.49399501,\n",
       " 18: 0.089759,\n",
       " 19: 0.47134301,\n",
       " 20: 0.16844399,\n",
       " 21: -0.239599,\n",
       " 22: -0.035000999,\n",
       " 23: -0.318086,\n",
       " 24: -0.044199001,\n",
       " 25: 0.39588401,\n",
       " 26: 0.51004899,\n",
       " 27: 0.461573,\n",
       " 28: 0.36443901,\n",
       " 29: -0.147663,\n",
       " 30: 0.012673,\n",
       " 31: 0.469439,\n",
       " 32: -0.54493499,\n",
       " 33: 0.60724401,\n",
       " 34: -0.32190999,\n",
       " 35: -0.0071990001,\n",
       " 36: 0.043249,\n",
       " 37: -0.38506499,\n",
       " 38: -0.35674,\n",
       " 39: -0.47903901,\n",
       " 40: -0.31924799,\n",
       " 41: 0.155983,\n",
       " 42: 0.091351002,\n",
       " 43: -0.218468,\n",
       " 44: 0.14129899,\n",
       " 45: 0.481749,\n",
       " 46: 0.077671997,\n",
       " 47: 0.19820599,\n",
       " 48: -0.72299701,\n",
       " 49: -0.33969,\n",
       " 50: -0.055128001,\n",
       " 51: -0.31261799,\n",
       " 52: -0.64407998,\n",
       " 53: -0.31589401,\n",
       " 54: -0.61545199,\n",
       " 55: 0.708318,\n",
       " 56: 0.106625,\n",
       " 57: -0.15074199,\n",
       " 58: -0.47371799,\n",
       " 59: 0.30649301,\n",
       " 60: -0.403703,\n",
       " 61: 0.87191802,\n",
       " 62: 0.071199,\n",
       " 63: -0.237854,\n",
       " 64: 0.084390998,\n",
       " 65: 0.102083,\n",
       " 66: 0.524333,\n",
       " 67: -0.48130101,\n",
       " 68: 0.433521,\n",
       " 69: 0.73176497,\n",
       " 70: 0.051911999,\n",
       " 71: -0.126195,\n",
       " 72: 0.293378,\n",
       " 73: -0.27858999,\n",
       " 74: -0.53096598,\n",
       " 75: 0.37584201,\n",
       " 76: -0.30789599,\n",
       " 77: 0.19755299,\n",
       " 78: -0.33704001,\n",
       " 79: 0.132925,\n",
       " 80: 0.22403,\n",
       " 81: 0.16534901,\n",
       " 82: -0.386498,\n",
       " 83: 0.044962998,\n",
       " 84: -0.10936,\n",
       " 85: 0.744672,\n",
       " 86: -0.292669,\n",
       " 87: -0.183264,\n",
       " 88: 1.053728,\n",
       " 89: -1.050774,\n",
       " 90: 0.272176,\n",
       " 91: 0.51497102,\n",
       " 92: 0.27353001,\n",
       " 93: -0.23726299,\n",
       " 94: 0.189299,\n",
       " 95: 0.049828999,\n",
       " 96: -0.55716801,\n",
       " 97: 0.25677899,\n",
       " 98: -0.101224,\n",
       " 99: -0.85618502,\n",
       " 100: -0.52029401,\n",
       " 101: -1.084011,\n",
       " 102: 0.57885402,\n",
       " 103: -0.63992798,\n",
       " 104: -0.038910002,\n",
       " 105: 0.62952298,\n",
       " 106: -0.082349002,\n",
       " 107: 0.29049999,\n",
       " 108: -0.83230901,\n",
       " 109: 0.70121199,\n",
       " 110: -0.115194,\n",
       " 111: 0.22070201,\n",
       " 112: 0.27586901,\n",
       " 113: -0.26365501,\n",
       " 114: -0.177855,\n",
       " 115: 0.145326,\n",
       " 116: 0.58414203,\n",
       " 117: -0.49399501,\n",
       " 118: 0.089759,\n",
       " 119: 0.47134301,\n",
       " 120: 0.16844399,\n",
       " 121: -0.239599,\n",
       " 122: -0.035000999,\n",
       " 123: -0.318086,\n",
       " 124: -0.044199001,\n",
       " 125: 0.39588401,\n",
       " 126: 0.51004899,\n",
       " 127: 0.461573,\n",
       " 128: 0.36443901,\n",
       " 129: -0.147663,\n",
       " 130: 0.012673,\n",
       " 131: 0.469439,\n",
       " 132: -0.54493499,\n",
       " 133: 0.60724401,\n",
       " 134: -0.32190999,\n",
       " 135: -0.0071990001,\n",
       " 136: 0.043249,\n",
       " 137: -0.38506499,\n",
       " 138: -0.35674,\n",
       " 139: -0.47903901,\n",
       " 140: -0.31924799,\n",
       " 141: 0.155983,\n",
       " 142: 0.091351002,\n",
       " 143: -0.218468,\n",
       " 144: 0.14129899,\n",
       " 145: 0.481749,\n",
       " 146: 0.077671997,\n",
       " 147: 0.19820599,\n",
       " 148: -0.72299701,\n",
       " 149: -0.33969,\n",
       " 150: -0.055128001,\n",
       " 151: -0.31261799,\n",
       " 152: -0.64407998,\n",
       " 153: -0.31589401,\n",
       " 154: -0.61545199,\n",
       " 155: 0.708318,\n",
       " 156: 0.106625,\n",
       " 157: -0.15074199,\n",
       " 158: -0.47371799,\n",
       " 159: 0.30649301,\n",
       " 160: -0.403703,\n",
       " 161: 0.87191802,\n",
       " 162: 0.071199,\n",
       " 163: -0.237854,\n",
       " 164: 0.084390998,\n",
       " 165: 0.102083,\n",
       " 166: 0.524333,\n",
       " 167: -0.48130101,\n",
       " 168: 0.433521,\n",
       " 169: 0.73176497,\n",
       " 170: 0.051911999,\n",
       " 171: -0.126195,\n",
       " 172: 0.293378,\n",
       " 173: -0.27858999,\n",
       " 174: -0.53096598,\n",
       " 175: 0.37584201,\n",
       " 176: -0.30789599,\n",
       " 177: 0.19755299,\n",
       " 178: -0.33704001,\n",
       " 179: 0.132925,\n",
       " 180: 0.22403,\n",
       " 181: 0.16534901,\n",
       " 182: -0.386498,\n",
       " 183: 0.044962998,\n",
       " 184: -0.10936,\n",
       " 185: 0.744672,\n",
       " 186: -0.292669,\n",
       " 187: -0.183264,\n",
       " 188: 1.053728,\n",
       " 189: -1.050774,\n",
       " 190: 0.272176,\n",
       " 191: 0.51497102,\n",
       " 192: 0.27353001,\n",
       " 193: -0.23726299,\n",
       " 194: 0.189299,\n",
       " 195: 0.049828999,\n",
       " 196: -0.55716801,\n",
       " 197: 0.25677899,\n",
       " 198: -0.101224,\n",
       " 199: -0.85618502,\n",
       " 200: 1,\n",
       " 225: 1,\n",
       " 250: 1,\n",
       " 341: 1,\n",
       " 390: 1,\n",
       " 439: 1,\n",
       " 1466: 1.1448621,\n",
       " 1467: -0.51813298,\n",
       " 1468: -0.068783,\n",
       " 1469: -0.56286299,\n",
       " 1470: 0.028821001,\n",
       " 1471: 0.36297801,\n",
       " 1472: 0.80521297,\n",
       " 1473: 0.155617,\n",
       " 1474: -0.215854,\n",
       " 1475: 0.88608497,\n",
       " 1476: 0.191892,\n",
       " 1477: 0.14794099,\n",
       " 1478: 0.22555301,\n",
       " 1479: -0.227863,\n",
       " 1480: 0.02173,\n",
       " 1481: 0.467002,\n",
       " 1482: -0.132634,\n",
       " 1483: 0.44917801,\n",
       " 1484: 0.17579401,\n",
       " 1485: 0.486927,\n",
       " 1486: -0.211703,\n",
       " 1487: 0.55130899,\n",
       " 1488: 0.34937599,\n",
       " 1489: -0.067661002,\n",
       " 1490: -0.42948499,\n",
       " 1491: 0.141004,\n",
       " 1492: 0.23221301,\n",
       " 1493: 0.12586699,\n",
       " 1494: 0.58594602,\n",
       " 1495: -0.38744199,\n",
       " 1496: 0.56945902,\n",
       " 1497: 0.055707,\n",
       " 1498: -0.293513,\n",
       " 1499: 0.62359601,\n",
       " 1500: -0.45051,\n",
       " 1501: -0.67623597,\n",
       " 1502: -0.085584998,\n",
       " 1503: -0.78929901,\n",
       " 1504: 0.37213299,\n",
       " 1505: -0.33090499,\n",
       " 1506: 0.37965801,\n",
       " 1507: -0.14294299,\n",
       " 1508: -0.120831,\n",
       " 1509: -0.42539701,\n",
       " 1510: 0.26454201,\n",
       " 1511: 0.026347,\n",
       " 1512: -0.657646,\n",
       " 1513: 0.36338499,\n",
       " 1514: -0.028554,\n",
       " 1515: -0.045216002,\n",
       " 1516: -0.23164199,\n",
       " 1517: -0.31404501,\n",
       " 1518: -0.115341,\n",
       " 1519: -0.381015,\n",
       " 1520: -0.66835701,\n",
       " 1521: -0.089726001,\n",
       " 1522: 0.26675999,\n",
       " 1523: -0.060520999,\n",
       " 1524: 0.068446003,\n",
       " 1525: -0.21705601,\n",
       " 1526: 0.033787999,\n",
       " 1527: -0.098241001,\n",
       " 1528: 0.41965699,\n",
       " 1529: -0.135428,\n",
       " 1530: -0.039772999,\n",
       " 1531: 0.50862497,\n",
       " 1532: 0.120657,\n",
       " 1533: 0.047238,\n",
       " 1534: 0.27522501,\n",
       " 1535: 0.87243402,\n",
       " 1536: 0.810049,\n",
       " 1537: 0.465725,\n",
       " 1538: 0.036664002,\n",
       " 1539: 0.089584,\n",
       " 1540: -0.328982,\n",
       " 1541: 0.46322501,\n",
       " 1542: -0.16676,\n",
       " 1543: -0.44076899,\n",
       " 1544: -0.789087,\n",
       " 1545: 0.31090999,\n",
       " 1546: -0.54851598,\n",
       " 1547: 0.97160298,\n",
       " 1548: -0.41817299,\n",
       " 1549: 0.43823799,\n",
       " 1550: -0.157087,\n",
       " 1551: -0.156703,\n",
       " 1552: 0.0050249998,\n",
       " 1553: 0.382983,\n",
       " 1554: 1.302206,\n",
       " 1555: 0.46588901,\n",
       " 1556: 0.41125101,\n",
       " 1557: 0.031647999,\n",
       " 1558: -0.426642,\n",
       " 1559: 0.113937,\n",
       " 1560: 0.470119,\n",
       " 1561: -0.074575998,\n",
       " 1562: -0.55221999,\n",
       " 1563: 0.14634299,\n",
       " 1564: -0.58846998,\n",
       " 1565: 0.683038,\n",
       " 1566: 1.1448621,\n",
       " 1567: -0.51813298,\n",
       " 1568: -0.068783,\n",
       " 1569: -0.56286299,\n",
       " 1570: 0.028821001,\n",
       " 1571: 0.36297801,\n",
       " 1572: 0.80521297,\n",
       " 1573: 0.155617,\n",
       " 1574: -0.215854,\n",
       " 1575: 0.88608497,\n",
       " 1576: 0.191892,\n",
       " 1577: 0.14794099,\n",
       " 1578: 0.22555301,\n",
       " 1579: -0.227863,\n",
       " 1580: 0.02173,\n",
       " 1581: 0.467002,\n",
       " 1582: -0.132634,\n",
       " 1583: 0.44917801,\n",
       " 1584: 0.17579401,\n",
       " 1585: 0.486927,\n",
       " 1586: -0.211703,\n",
       " 1587: 0.55130899,\n",
       " 1588: 0.34937599,\n",
       " 1589: -0.067661002,\n",
       " 1590: -0.42948499,\n",
       " 1591: 0.141004,\n",
       " 1592: 0.23221301,\n",
       " 1593: 0.12586699,\n",
       " 1594: 0.58594602,\n",
       " 1595: -0.38744199,\n",
       " 1596: 0.56945902,\n",
       " 1597: 0.055707,\n",
       " 1598: -0.293513,\n",
       " 1599: 0.62359601,\n",
       " 1600: -0.45051,\n",
       " 1601: -0.67623597,\n",
       " 1602: -0.085584998,\n",
       " 1603: -0.78929901,\n",
       " 1604: 0.37213299,\n",
       " 1605: -0.33090499,\n",
       " 1606: 0.37965801,\n",
       " 1607: -0.14294299,\n",
       " 1608: -0.120831,\n",
       " 1609: -0.42539701,\n",
       " 1610: 0.26454201,\n",
       " 1611: 0.026347,\n",
       " 1612: -0.657646,\n",
       " 1613: 0.36338499,\n",
       " 1614: -0.028554,\n",
       " 1615: -0.045216002,\n",
       " 1616: -0.23164199,\n",
       " 1617: -0.31404501,\n",
       " 1618: -0.115341,\n",
       " 1619: -0.381015,\n",
       " 1620: -0.66835701,\n",
       " 1621: -0.089726001,\n",
       " 1622: 0.26675999,\n",
       " 1623: -0.060520999,\n",
       " 1624: 0.068446003,\n",
       " 1625: -0.21705601,\n",
       " 1626: 0.033787999,\n",
       " 1627: -0.098241001,\n",
       " 1628: 0.41965699,\n",
       " 1629: -0.135428,\n",
       " 1630: -0.039772999,\n",
       " 1631: 0.50862497,\n",
       " 1632: 0.120657,\n",
       " 1633: 0.047238,\n",
       " 1634: 0.27522501,\n",
       " 1635: 0.87243402,\n",
       " 1636: 0.810049,\n",
       " 1637: 0.465725,\n",
       " 1638: 0.036664002,\n",
       " 1639: 0.089584,\n",
       " 1640: -0.328982,\n",
       " 1641: 0.46322501,\n",
       " 1642: -0.16676,\n",
       " 1643: -0.44076899,\n",
       " 1644: -0.789087,\n",
       " 1645: 0.31090999,\n",
       " 1646: -0.54851598,\n",
       " 1647: 0.97160298,\n",
       " 1648: -0.41817299,\n",
       " 1649: 0.43823799,\n",
       " 1650: -0.157087,\n",
       " 1651: -0.156703,\n",
       " 1652: 0.0050249998,\n",
       " 1653: 0.382983,\n",
       " 1654: 1.302206,\n",
       " 1655: 0.46588901,\n",
       " 1656: 0.41125101,\n",
       " 1657: 0.031647999,\n",
       " 1658: -0.426642,\n",
       " 1659: 0.113937,\n",
       " 1660: 0.470119,\n",
       " 1661: -0.074575998,\n",
       " 1662: -0.55221999,\n",
       " 1663: 0.14634299,\n",
       " 1664: -0.58846998,\n",
       " 1665: 0.683038,\n",
       " 1666: 1.1448621,\n",
       " 1667: -0.51813298,\n",
       " 1668: -0.068783,\n",
       " 1669: -0.56286299,\n",
       " 1670: 0.028821001,\n",
       " 1671: 0.36297801,\n",
       " 1672: 0.80521297,\n",
       " 1673: 0.155617,\n",
       " 1674: -0.215854,\n",
       " 1675: 0.88608497,\n",
       " 1676: 0.191892,\n",
       " 1677: 0.14794099,\n",
       " 1678: 0.22555301,\n",
       " 1679: -0.227863,\n",
       " 1680: 0.02173,\n",
       " 1681: 0.467002,\n",
       " 1682: -0.132634,\n",
       " 1683: 0.44917801,\n",
       " 1684: 0.17579401,\n",
       " 1685: 0.486927,\n",
       " 1686: -0.211703,\n",
       " 1687: 0.55130899,\n",
       " 1688: 0.34937599,\n",
       " 1689: -0.067661002,\n",
       " 1690: -0.42948499,\n",
       " 1691: 0.141004,\n",
       " 1692: 0.23221301,\n",
       " 1693: 0.12586699,\n",
       " 1694: 0.58594602,\n",
       " 1695: -0.38744199,\n",
       " 1696: 0.56945902,\n",
       " 1697: 0.055707,\n",
       " 1698: -0.293513,\n",
       " 1699: 0.62359601,\n",
       " 1700: -0.45051,\n",
       " 1701: -0.67623597,\n",
       " 1702: -0.085584998,\n",
       " 1703: -0.78929901,\n",
       " 1704: 0.37213299,\n",
       " 1705: -0.33090499,\n",
       " 1706: 0.37965801,\n",
       " 1707: -0.14294299,\n",
       " 1708: -0.120831,\n",
       " 1709: -0.42539701,\n",
       " 1710: 0.26454201,\n",
       " 1711: 0.026347,\n",
       " 1712: -0.657646,\n",
       " 1713: 0.36338499,\n",
       " 1714: -0.028554,\n",
       " 1715: -0.045216002,\n",
       " 1716: -0.23164199,\n",
       " 1717: -0.31404501,\n",
       " 1718: -0.115341,\n",
       " 1719: -0.381015,\n",
       " 1720: -0.66835701,\n",
       " 1721: -0.089726001,\n",
       " 1722: 0.26675999,\n",
       " 1723: -0.060520999,\n",
       " 1724: 0.068446003,\n",
       " 1725: -0.21705601,\n",
       " 1726: 0.033787999,\n",
       " 1727: -0.098241001,\n",
       " 1728: 0.41965699,\n",
       " 1729: -0.135428,\n",
       " 1730: -0.039772999,\n",
       " 1731: 0.50862497,\n",
       " 1732: 0.120657,\n",
       " 1733: 0.047238,\n",
       " 1734: 0.27522501,\n",
       " 1735: 0.87243402,\n",
       " 1736: 0.810049,\n",
       " 1737: 0.465725,\n",
       " 1738: 0.036664002,\n",
       " 1739: 0.089584,\n",
       " 1740: -0.328982,\n",
       " 1741: 0.46322501,\n",
       " 1742: -0.16676,\n",
       " 1743: -0.44076899,\n",
       " 1744: -0.789087,\n",
       " 1745: 0.31090999,\n",
       " 1746: -0.54851598,\n",
       " 1747: 0.97160298,\n",
       " 1748: -0.41817299,\n",
       " 1749: 0.43823799,\n",
       " 1750: -0.157087,\n",
       " 1751: -0.156703,\n",
       " 1752: 0.0050249998,\n",
       " 1753: 0.382983,\n",
       " 1754: 1.302206,\n",
       " 1755: 0.46588901,\n",
       " 1756: 0.41125101,\n",
       " 1757: 0.031647999,\n",
       " 1758: -0.426642,\n",
       " 1759: 0.113937,\n",
       " 1760: 0.470119,\n",
       " 1761: -0.074575998,\n",
       " 1762: -0.55221999,\n",
       " 1763: 0.14634299,\n",
       " 1764: -0.58846998,\n",
       " 1765: 0.683038,\n",
       " 1766: 0.19297101,\n",
       " 1767: -0.17129099,\n",
       " 1768: 0.15860499,\n",
       " 1769: -0.136016,\n",
       " 1770: -0.00746,\n",
       " 1771: 0.214004,\n",
       " 1772: 0.015691999,\n",
       " 1773: -0.201662,\n",
       " 1774: -0.27849701,\n",
       " 1775: 0.25288501,\n",
       " 1776: 0.22942799,\n",
       " 1777: 0.240687,\n",
       " 1778: -0.042830002,\n",
       " 1779: -0.25402799,\n",
       " 1780: 0.100881,\n",
       " 1781: 0.276858,\n",
       " 1782: 0.193239,\n",
       " 1783: 0.12586799,\n",
       " 1784: 0.297941,\n",
       " 1785: -0.230147,\n",
       " 1786: -0.15345,\n",
       " 1787: 0.213981,\n",
       " 1788: 0.48398599,\n",
       " 1789: -0.115721,\n",
       " 1790: -0.31992701,\n",
       " 1791: -0.069385,\n",
       " 1792: 0.175005,\n",
       " 1793: 0.22187901,\n",
       " 1794: 0.027696,\n",
       " 1795: -0.127708,\n",
       " 1796: -0.051270001,\n",
       " 1797: 0.062654004,\n",
       " 1798: -0.29449701,\n",
       " 1799: 0.127672,\n",
       " 1800: 0.058120999,\n",
       " 1801: -0.15857901,\n",
       " 1802: 0.189044,\n",
       " 1803: -0.303058,\n",
       " 1804: 0.14544199,\n",
       " 1805: -0.089382,\n",
       " 1806: 0.031339999,\n",
       " 1807: 0.178682,\n",
       " 1808: -0.0075289998,\n",
       " 1809: 0.091990001,\n",
       " 1810: 0.19131599,\n",
       " 1811: 0.189108,\n",
       " 1812: 0.019691,\n",
       " 1813: -0.194741,\n",
       " 1814: -0.151214,\n",
       " 1815: -0.195814,\n",
       " 1816: -0.28204101,\n",
       " 1817: -0.108896,\n",
       " 1818: -0.067712002,\n",
       " 1819: -0.019732,\n",
       " 1820: -0.11739,\n",
       " 1821: -0.237205,\n",
       " 1822: 0.026725,\n",
       " 1823: -0.19326299,\n",
       " 1824: 0.016496001,\n",
       " 1825: 0.200957,\n",
       " 1826: 0.102151,\n",
       " 1827: 0.166674,\n",
       " 1828: 0.283779,\n",
       " 1829: 0.078419,\n",
       " 1830: 0.063418001,\n",
       " 1831: 0.319482,\n",
       " 1832: 0.187603,\n",
       " 1833: 0.040619001,\n",
       " 1834: -0.105884,\n",
       " 1835: 0.150675,\n",
       " 1836: -0.206613,\n",
       " 1837: -0.099682003,\n",
       " 1838: 0.236146,\n",
       " 1839: -0.31914601,\n",
       " 1840: -0.29983699,\n",
       " 1841: -0.140617,\n",
       " 1842: -0.161118,\n",
       " 1843: -0.023435,\n",
       " 1844: -0.092109002,\n",
       " 1845: 0.034359001,\n",
       " 1846: 0.184439,\n",
       " 1847: 0.325073,\n",
       " 1848: 0.25609699,\n",
       " 1849: 0.019462001,\n",
       " 1850: 0.037344001,\n",
       " 1851: 0.095291004,\n",
       " 1852: 0.042989001,\n",
       " 1853: 0.047718,\n",
       " 1854: 0.32089901,\n",
       " 1855: -0.104379,\n",
       " 1856: -0.140645,\n",
       " 1857: 0.24524599,\n",
       " 1858: -0.18102001,\n",
       " 1859: 0.052407,\n",
       " 1860: -0.107465,\n",
       " 1861: 0.161631,\n",
       " 1862: -0.096784003,\n",
       " 1863: 0.079502001,\n",
       " 1864: -0.140626,\n",
       " 1865: 0.032609001,\n",
       " 1866: -0.098426998,\n",
       " 1867: -0.43197,\n",
       " 1868: 0.52657801,\n",
       " 1869: -0.106596,\n",
       " 1870: 0.489369,\n",
       " 1871: 0.33581099,\n",
       " 1872: 0.145476,\n",
       " 1873: 0.30846801,\n",
       " 1874: -0.39036801,\n",
       " 1875: 0.76465601,\n",
       " 1876: -0.51557302,\n",
       " 1877: 0.89838499,\n",
       " 1878: -0.71059197,\n",
       " 1879: -0.359887,\n",
       " 1880: -0.25898501,\n",
       " 1881: 0.49220601,\n",
       " 1882: 1.4284379,\n",
       " 1883: 1.034125,\n",
       " 1884: 0.47533301,\n",
       " 1885: 0.035868,\n",
       " 1886: -0.49508101,\n",
       " 1887: 0.227613,\n",
       " 1888: 0.109545,\n",
       " 1889: -0.95185,\n",
       " 1890: 0.74065298,\n",
       " 1891: 0.029447,\n",
       " 1892: -0.230913,\n",
       " 1893: -0.531995,\n",
       " 1894: -0.115106,\n",
       " 1895: -0.223535,\n",
       " 1896: 0.75413102,\n",
       " 1897: -0.176226,\n",
       " 1898: -0.786874,\n",
       " 1899: 0.179976,\n",
       " 1900: 0.28511,\n",
       " 1901: -0.086930998,\n",
       " 1902: 0.54154003,\n",
       " 1903: -0.45382199,\n",
       " 1904: 0.95653802,\n",
       " 1905: -0.95994103,\n",
       " 1906: 0.63864499,\n",
       " 1907: -0.12278,\n",
       " 1908: -0.394622,\n",
       " 1909: 0.22752599,\n",
       " 1910: 0.57516199,\n",
       " 1911: 0.43962899,\n",
       " 1912: -0.51786202,\n",
       " 1913: -0.95796198,\n",
       " 1914: -0.022955,\n",
       " 1915: -0.031463001,\n",
       " 1916: 0.28908399,\n",
       " 1917: -0.61072499,\n",
       " 1918: -0.61459303,\n",
       " 1919: -0.076090999,\n",
       " 1920: -0.321044,\n",
       " 1921: -0.35309801,\n",
       " 1922: 0.26925501,\n",
       " 1923: 0.097448997,\n",
       " 1924: -0.19159099,\n",
       " 1925: -0.086237997,\n",
       " 1926: -0.600281,\n",
       " 1927: -0.032143999,\n",
       " 1928: 0.85311699,\n",
       " 1929: -0.22949401,\n",
       " 1930: 0.082284003,\n",
       " 1931: 0.154294,\n",
       " 1932: -0.83248299,\n",
       " 1933: -0.237602,\n",
       " 1934: 0.012093,\n",
       " 1935: 0.61722797,\n",
       " 1936: -0.53423101,\n",
       " 1937: -0.086323999,\n",
       " 1938: 0.162158,\n",
       " 1939: -0.30703601,\n",
       " 1940: -0.68657601,\n",
       " 1941: 0.33026099,\n",
       " 1942: 0.87070298,\n",
       " 1943: -0.99765402,\n",
       " 1944: -0.79242098,\n",
       " 1945: -0.31878901,\n",
       " 1946: -1.046083,\n",
       " 1947: -0.016422,\n",
       " 1948: 0.94042301,\n",
       " 1949: -0.67192698,\n",
       " 1950: 0.096486002,\n",
       " 1951: 0.213643,\n",
       " 1952: -0.35049701,\n",
       " 1953: 0.095009997,\n",
       " 1954: 0.77203101,\n",
       " 1955: -0.55475599,\n",
       " 1956: -0.434569,\n",
       " 1957: -0.29777899,\n",
       " 1958: -0.35133001,\n",
       " 1959: 0.056435999,\n",
       " 1960: 0.17597499,\n",
       " 1961: 0.98496801,\n",
       " 1962: -0.923114,\n",
       " 1963: -0.124203,\n",
       " 1964: -0.075880997,\n",
       " 1965: -0.026636999,\n",
       " 1966: 0.12819301,\n",
       " 1967: -0.63502997,\n",
       " 1968: 0.45149201,\n",
       " 1969: -0.477927,\n",
       " 1970: 0.171261,\n",
       " 1971: 0.163753,\n",
       " 1972: 0.215578,\n",
       " 1973: -0.042877998,\n",
       " 1974: -0.84340101,\n",
       " 1975: 0.323856,\n",
       " 1976: -0.275186,\n",
       " 1977: 0.814152,\n",
       " 1978: -0.320416,\n",
       " 1979: -0.243349,\n",
       " 1980: -0.074689001,\n",
       " 1981: 0.101713,\n",
       " 1982: 0.66959798,\n",
       " 1983: -0.50813001,\n",
       " 1984: -0.077303,\n",
       " 1985: 0.60143203,\n",
       " 1986: -0.194801,\n",
       " 1987: 0.46648401,\n",
       " 1988: 0.51123297,\n",
       " 1989: -0.43340099,\n",
       " 1990: 0.37154201,\n",
       " 1991: -0.30737501,\n",
       " 1992: -0.099207997,\n",
       " 1993: 0.24235301,\n",
       " 1994: 0.55653697,\n",
       " 1995: 0.336734,\n",
       " 1996: 0.137272,\n",
       " 1997: 0.198805,\n",
       " 1998: -0.66260302,\n",
       " 1999: 0.18970101,\n",
       " 2000: 0.065546997,\n",
       " 2001: -0.57374901,\n",
       " 2002: -0.48105901,\n",
       " 2003: -0.048858002,\n",
       " 2004: -0.55567098,\n",
       " 2005: -0.547539,\n",
       " 2006: 0.049819998,\n",
       " 2007: -0.41989401,\n",
       " 2008: -0.249255,\n",
       " 2009: -0.456278,\n",
       " 2010: -0.069966003,\n",
       " 2011: 0.83404702,\n",
       " 2012: 0.060947999,\n",
       " 2013: -0.407399,\n",
       " 2014: 0.193928,\n",
       " 2015: -0.31284699,\n",
       " 2016: -0.106585,\n",
       " 2017: 0.0042059999,\n",
       " 2018: -0.022104001,\n",
       " 2019: 0.023906,\n",
       " 2020: 0.0028850001,\n",
       " 2021: -0.13437501,\n",
       " 2022: 0.18274499,\n",
       " 2023: 0.278909,\n",
       " 2024: 0.093883999,\n",
       " 2025: -0.631073,\n",
       " 2026: -0.087508,\n",
       " 2027: 0.59525102,\n",
       " 2028: 0.47548401,\n",
       " 2029: -0.072959997,\n",
       " 2030: 0.083584003,\n",
       " 2031: 0.225655,\n",
       " 2032: 0.62598902,\n",
       " 2033: 0.180061,\n",
       " 2034: 0.44201499,\n",
       " 2035: 0.26752499,\n",
       " 2036: 0.078755997,\n",
       " 2037: -0.154961,\n",
       " 2038: 0.040851001,\n",
       " 2039: 0.072502002,\n",
       " 2040: 0.121423,\n",
       " 2041: 0.0089189997,\n",
       " 2042: 0.053049002,\n",
       " 2043: 0.001029,\n",
       " 2044: 0.245488,\n",
       " 2045: 0.167805,\n",
       " 2046: -0.251304,\n",
       " 2047: 0.41699901,\n",
       " 2048: 0.069232002,\n",
       " 2049: -0.088587999,\n",
       " 2050: 0.53301698,\n",
       " 2051: 0.108945,\n",
       " 2052: -0.029575,\n",
       " 2053: -0.070959002,\n",
       " 2054: 0.97773802,\n",
       " 2055: -0.458341,\n",
       " 2056: -0.091441996,\n",
       " 2057: -0.03224,\n",
       " 2058: -0.13244399,\n",
       " 2059: 0.401696,\n",
       " 2060: 0.14553501,\n",
       " 2061: -0.159337,\n",
       " 2062: -0.223648,\n",
       " 2063: -0.359148,\n",
       " 2064: -0.58250302,\n",
       " 2065: -0.23933201,\n",
       " 2066: 1.1448621,\n",
       " 2067: -0.51813298,\n",
       " 2068: -0.068783,\n",
       " 2069: -0.56286299,\n",
       " 2070: 0.028821001,\n",
       " 2071: 0.36297801,\n",
       " 2072: 0.80521297,\n",
       " 2073: 0.155617,\n",
       " 2074: -0.215854,\n",
       " 2075: 0.88608497,\n",
       " 2076: 0.191892,\n",
       " 2077: 0.14794099,\n",
       " 2078: 0.22555301,\n",
       " 2079: -0.227863,\n",
       " 2080: 0.02173,\n",
       " 2081: 0.467002,\n",
       " 2082: -0.132634,\n",
       " 2083: 0.44917801,\n",
       " 2084: 0.17579401,\n",
       " 2085: 0.486927,\n",
       " 2086: -0.211703,\n",
       " 2087: 0.55130899,\n",
       " 2088: 0.34937599,\n",
       " 2089: -0.067661002,\n",
       " 2090: -0.42948499,\n",
       " 2091: 0.141004,\n",
       " 2092: 0.23221301,\n",
       " 2093: 0.12586699,\n",
       " 2094: 0.58594602,\n",
       " 2095: -0.38744199,\n",
       " 2096: 0.56945902,\n",
       " 2097: 0.055707,\n",
       " 2098: -0.293513,\n",
       " 2099: 0.62359601,\n",
       " 2100: -0.45051,\n",
       " 2101: -0.67623597,\n",
       " 2102: -0.085584998,\n",
       " 2103: -0.78929901,\n",
       " 2104: 0.37213299,\n",
       " 2105: -0.33090499,\n",
       " 2106: 0.37965801,\n",
       " 2107: -0.14294299,\n",
       " 2108: -0.120831,\n",
       " 2109: -0.42539701,\n",
       " 2110: 0.26454201,\n",
       " 2111: 0.026347,\n",
       " 2112: -0.657646,\n",
       " 2113: 0.36338499,\n",
       " 2114: -0.028554,\n",
       " 2115: -0.045216002,\n",
       " 2116: -0.23164199,\n",
       " 2117: -0.31404501,\n",
       " 2118: -0.115341,\n",
       " 2119: -0.381015,\n",
       " 2120: -0.66835701,\n",
       " 2121: -0.089726001,\n",
       " 2122: 0.26675999,\n",
       " 2123: -0.060520999,\n",
       " 2124: 0.068446003,\n",
       " 2125: -0.21705601,\n",
       " 2126: 0.033787999,\n",
       " 2127: -0.098241001,\n",
       " 2128: 0.41965699,\n",
       " 2129: -0.135428,\n",
       " 2130: -0.039772999,\n",
       " 2131: 0.50862497,\n",
       " 2132: 0.120657,\n",
       " 2133: 0.047238,\n",
       " 2134: 0.27522501,\n",
       " 2135: 0.87243402,\n",
       " 2136: 0.810049,\n",
       " 2137: 0.465725,\n",
       " 2138: 0.036664002,\n",
       " 2139: 0.089584,\n",
       " 2140: -0.328982,\n",
       " 2141: 0.46322501,\n",
       " 2142: -0.16676,\n",
       " 2143: -0.44076899,\n",
       " 2144: -0.789087,\n",
       " 2145: 0.31090999,\n",
       " 2146: -0.54851598,\n",
       " 2147: 0.97160298,\n",
       " 2148: -0.41817299,\n",
       " 2149: 0.43823799,\n",
       " 2150: -0.157087,\n",
       " 2151: -0.156703,\n",
       " 2152: 0.0050249998,\n",
       " 2153: 0.382983,\n",
       " 2154: 1.302206,\n",
       " 2155: 0.46588901,\n",
       " 2156: 0.41125101,\n",
       " 2157: 0.031647999,\n",
       " 2158: -0.426642,\n",
       " 2159: 0.113937,\n",
       " 2160: 0.470119,\n",
       " 2161: -0.074575998,\n",
       " 2162: -0.55221999,\n",
       " 2163: 0.14634299,\n",
       " 2164: -0.58846998,\n",
       " 2165: 0.683038,\n",
       " 2166: 1.1448621,\n",
       " 2167: -0.51813298,\n",
       " 2168: -0.068783,\n",
       " 2169: -0.56286299,\n",
       " 2170: 0.028821001,\n",
       " 2171: 0.36297801,\n",
       " 2172: 0.80521297,\n",
       " 2173: 0.155617,\n",
       " 2174: -0.215854,\n",
       " 2175: 0.88608497,\n",
       " 2176: 0.191892,\n",
       " 2177: 0.14794099,\n",
       " 2178: 0.22555301,\n",
       " 2179: -0.227863,\n",
       " 2180: 0.02173,\n",
       " 2181: 0.467002,\n",
       " 2182: -0.132634,\n",
       " 2183: 0.44917801,\n",
       " 2184: 0.17579401,\n",
       " 2185: 0.486927,\n",
       " 2186: -0.211703,\n",
       " 2187: 0.55130899,\n",
       " 2188: 0.34937599,\n",
       " 2189: -0.067661002,\n",
       " 2190: -0.42948499,\n",
       " 2191: 0.141004,\n",
       " 2192: 0.23221301,\n",
       " 2193: 0.12586699,\n",
       " 2194: 0.58594602,\n",
       " 2195: -0.38744199,\n",
       " 2196: 0.56945902,\n",
       " 2197: 0.055707,\n",
       " 2198: -0.293513,\n",
       " 2199: 0.62359601,\n",
       " 2200: -0.45051,\n",
       " 2201: -0.67623597,\n",
       " 2202: -0.085584998,\n",
       " 2203: -0.78929901,\n",
       " 2204: 0.37213299,\n",
       " 2205: -0.33090499,\n",
       " 2206: 0.37965801,\n",
       " 2207: -0.14294299,\n",
       " 2208: -0.120831,\n",
       " 2209: -0.42539701,\n",
       " 2210: 0.26454201,\n",
       " 2211: 0.026347,\n",
       " 2212: -0.657646,\n",
       " 2213: 0.36338499,\n",
       " 2214: -0.028554,\n",
       " 2215: -0.045216002,\n",
       " 2216: -0.23164199,\n",
       " 2217: -0.31404501,\n",
       " 2218: -0.115341,\n",
       " 2219: -0.381015,\n",
       " 2220: -0.66835701,\n",
       " 2221: -0.089726001,\n",
       " 2222: 0.26675999,\n",
       " 2223: -0.060520999,\n",
       " 2224: 0.068446003,\n",
       " 2225: -0.21705601,\n",
       " 2226: 0.033787999,\n",
       " 2227: -0.098241001,\n",
       " 2228: 0.41965699,\n",
       " 2229: -0.135428,\n",
       " 2230: -0.039772999,\n",
       " 2231: 0.50862497,\n",
       " 2232: 0.120657,\n",
       " 2233: 0.047238,\n",
       " 2234: 0.27522501,\n",
       " 2235: 0.87243402,\n",
       " 2236: 0.810049,\n",
       " 2237: 0.465725,\n",
       " 2238: 0.036664002,\n",
       " 2239: 0.089584,\n",
       " 2240: -0.328982,\n",
       " 2241: 0.46322501,\n",
       " 2242: -0.16676,\n",
       " 2243: -0.44076899,\n",
       " 2244: -0.789087,\n",
       " 2245: 0.31090999,\n",
       " 2246: -0.54851598,\n",
       " 2247: 0.97160298,\n",
       " 2248: -0.41817299,\n",
       " 2249: 0.43823799,\n",
       " 2250: -0.157087,\n",
       " 2251: -0.156703,\n",
       " 2252: 0.0050249998,\n",
       " 2253: 0.382983,\n",
       " 2254: 1.302206,\n",
       " 2255: 0.46588901,\n",
       " 2256: 0.41125101,\n",
       " 2257: 0.031647999,\n",
       " 2258: -0.426642,\n",
       " 2259: 0.113937,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [] \n",
    "sparse_features = defaultdict(dict)\n",
    "propositions = []        \n",
    "for idx, propid in d['P'].items():\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        base_col = columns_mapper[col]\n",
    "        word = d[col][idx] \n",
    "        if base_col in ('FORM', 'LEMMA'):\n",
    "            sz = embeddings_size\n",
    "            token = tokenize(word)\n",
    "            values = list(word2vec[token])\n",
    "                \n",
    "            sparse_features[idx].update({\n",
    "                i + lb: round(val, 7) \n",
    "                for i, val in enumerate(values)\n",
    "            })\n",
    "        elif categorical in lexicons[base_col]:\n",
    "            idx1 = lexicons[base_col][categorical]\n",
    "            sparse_features[idx][lb + idx1]=1 \n",
    "            sz = dimension_mapper[col] \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse_features[idx][lb]=1 \n",
    "            sz = dimension_mapper[col] \n",
    "        lb += sz\n",
    "    propositions.append( propid )\n",
    "\n",
    "        \n",
    "sparse_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Saved mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds_type in ('train', 'test', 'valid'):    \n",
    "    if ds_type in ('train'):                \n",
    "      lb = 0\n",
    "      ub = DATASET_TRAIN_SIZE \n",
    "\n",
    "    if ds_type in ('valid'):                \n",
    "      lb = DATASET_TRAIN_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE\n",
    "\n",
    "    if ds_type in ('test'):                \n",
    "      lb = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE + DATASET_TEST_SIZE\n",
    "        \n",
    "    # saves the processed data\n",
    "    svm_path = '{:}/{:}/{:}.svm'.format(SVM_DIR, 'wan', ds_type)\n",
    "    with open(svm_path, mode='w') as f:\n",
    "        for idx in sparse_features:\n",
    "            p = propositions[idx]\n",
    "            if p > lb and p < ub + 1:\n",
    "                target = '{:} '.format(int(targets_mapper[targets[idx]]))\n",
    "                features = ' '.join([ '{:}:{:}'.format(key, val) \n",
    "                     for key, val in sparse_features[idx].items()])\n",
    "                ex = '{:}{:}\\n'.format(target, features)\n",
    "                f.write(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
