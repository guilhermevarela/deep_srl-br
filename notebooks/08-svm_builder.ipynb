{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loads Gold Standard and Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../datasets')\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import glob \n",
    "import re\n",
    "import math\n",
    "from gensim.models import KeyedVectors\n",
    "from data_propbankbr import propbankbr_arg2t\n",
    "\n",
    "DATASETS_DIR = '../datasets/csvs/'\n",
    "SCHEMAS_DIR = '../datasets/schemas/'\n",
    "SVM_DIR = '../datasets/svms/'\n",
    "EMBEDDINGS_DIR = '../datasets/txts/embeddings/'\n",
    "\n",
    "GS_PATH = '{:}{:}'.format(DATASETS_DIR, 'gs.csv')\n",
    "GS_SCHEMA_PATH = '{:}{:}'.format(SCHEMAS_DIR, 'gs.yaml')\n",
    "\n",
    "GLOVE_S50_PATH = '{:}glove_s50.txt'.format(EMBEDDINGS_DIR)\n",
    "WANG_S100_PATH = '{:}wang2vec_s100.txt'.format(EMBEDDINGS_DIR)\n",
    "\n",
    "\n",
    "\n",
    "DATASET_SIZE= 5931\n",
    "DATASET_TRAIN_SIZE= 5099\n",
    "DATASET_VALID_SIZE= 569\n",
    "DATASET_TEST_SIZE=  263\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARG', 'CTREE', 'DTREE', 'FORM', 'FUNC', 'GPOS', 'ID', 'INDEX', 'LEMMA', 'MORF', 'P', 'PRED', 'PRED_MARKER', 'P_S', 'S', 'T']\n"
     ]
    }
   ],
   "source": [
    "with open(GS_SCHEMA_PATH, mode='r') as f:\n",
    "    dictschema = yaml.load(f)\n",
    "\n",
    "print([ i\n",
    "    for i in dictschema])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC',\n",
      "       'CTREE', 'PRED', 'ARG'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(GS_PATH, sep=',', encoding='utf-8', index_col=0)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loads gs_column_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/csvs/column_shifts/form.csv\n",
      "../datasets/csvs/column_shifts/func.csv\n",
      "../datasets/csvs/column_shifts/lemma.csv\n",
      "../datasets/csvs/column_shifts/gpos.csv\n",
      "../datasets/csvs/column_shifts_ctx_p/form.csv\n",
      "../datasets/csvs/column_shifts_ctx_p/func.csv\n",
      "../datasets/csvs/column_shifts_ctx_p/lemma.csv\n",
      "../datasets/csvs/column_shifts_ctx_p/gpos.csv\n",
      "../datasets/csvs/column_t/t.csv\n",
      "../datasets/csvs/column_preddist/predicate_distance.csv\n",
      "../datasets/csvs/column_predmorph/pred_morph.csv\n",
      "../datasets/csvs/column_predmarker/predicate_marker.csv\n",
      "../datasets/csvs/column_passivevoice/passive_voice.csv\n",
      "../datasets/csvs/column_deptree/func.csv\n",
      "../datasets/csvs/column_deptree/lemma.csv\n",
      "../datasets/csvs/column_deptree/gpos.csv\n",
      "Index(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC',\n",
      "       ...\n",
      "       'GPOS_17', 'GPOS_18', 'GPOS_19', 'GPOS_20', 'GPOS_21', 'GPOS_CHILD_1',\n",
      "       'GPOS_CHILD_2', 'GPOS_CHILD_3', 'GPOS_GRAND_PARENT', 'GPOS_PARENT'],\n",
      "      dtype='object', length=560)\n"
     ]
    }
   ],
   "source": [
    "column_paths = ('column_shifts', 'column_shifts_ctx_p', 'column_t', \n",
    "                'column_preddist', 'column_predmorph', 'column_predmarker',\n",
    "                'column_passivevoice', 'column_deptree')\n",
    "\n",
    "numeric_columns = ('column_preddist', 'column_predmorph', \n",
    "                   'column_predmarker', 'column_passivevoice')\n",
    "\n",
    "kwargs = {'sep': ',', 'encoding':'utf-8', 'index_col':0}\n",
    "for column_path in column_paths:\n",
    "    column_pattern = '{:}{:}/*'.format(DATASETS_DIR, column_path)\n",
    "    for file_path in glob.glob(column_pattern):\n",
    "        print(file_path)\n",
    "        if column_path in numeric_columns:\n",
    "            _df = pd.read_csv(file_path, dtype=int, **kwargs)\n",
    "        else:\n",
    "            _df = pd.read_csv(file_path, dtype=str, **kwargs)\n",
    "        df = pd.concat((df, _df), axis=1, ignore_index=False)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bounds_fn(columns, embeddings_size, dimension_mapper, columns_mapper):\n",
    "    bmapper = {}\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        if is_dense(col, columns_mapper):\n",
    "            ub = lb +  embeddings_size        \n",
    "        else:\n",
    "            ub = lb +  dimension_mapper[col]            \n",
    "        bmapper[col] = {'lb': lb, 'ub':ub }\n",
    "        lb = ub + 1\n",
    "    return bmapper\n",
    "\n",
    "def is_dense(col, columns_mapper):\n",
    "    return columns_mapper[col] in ('FORM', 'LEMMA', 'PRED')\n",
    "\n",
    "\n",
    "def subcol(col):\n",
    "    re_ctxp = r'(_CTX_P)|(_\\d)|[\\+|\\-|\\d|]'\n",
    "    re_repl = r'(_CHILD)|(_PARENT)|(_GRAND_PARENT)'\n",
    "\n",
    "    bcol = re.sub(re_ctxp, '', col)\n",
    "    bcol = re.sub(re_repl, '', bcol)\n",
    "    return bcol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Column Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': 'ID', 'S': 'S', 'P': 'P', 'P_S': 'P_S', 'FORM': 'FORM', 'LEMMA': 'LEMMA', 'GPOS': 'GPOS', 'MORF': 'MORF', 'DTREE': 'DTREE', 'FUNC': 'FUNC', 'CTREE': 'CTREE', 'PRED': 'PRED', 'ARG': 'ARG', 'FORM+1': 'FORM', 'FORM+2': 'FORM', 'FORM+3': 'FORM', 'FORM-1': 'FORM', 'FORM-2': 'FORM', 'FORM-3': 'FORM', 'FUNC+1': 'FUNC', 'FUNC+2': 'FUNC', 'FUNC+3': 'FUNC', 'FUNC-1': 'FUNC', 'FUNC-2': 'FUNC', 'FUNC-3': 'FUNC', 'LEMMA+1': 'LEMMA', 'LEMMA+2': 'LEMMA', 'LEMMA+3': 'LEMMA', 'LEMMA-1': 'LEMMA', 'LEMMA-2': 'LEMMA', 'LEMMA-3': 'LEMMA', 'GPOS+1': 'GPOS', 'GPOS+2': 'GPOS', 'GPOS+3': 'GPOS', 'GPOS-1': 'GPOS', 'GPOS-2': 'GPOS', 'GPOS-3': 'GPOS', 'FORM_CTX_P+0': 'FORM', 'FORM_CTX_P+1': 'FORM', 'FORM_CTX_P+2': 'FORM', 'FORM_CTX_P+3': 'FORM', 'FORM_CTX_P-1': 'FORM', 'FORM_CTX_P-2': 'FORM', 'FORM_CTX_P-3': 'FORM', 'FUNC_CTX_P+0': 'FUNC', 'FUNC_CTX_P+1': 'FUNC', 'FUNC_CTX_P-1': 'FUNC', 'LEMMA_CTX_P+0': 'LEMMA', 'LEMMA_CTX_P+1': 'LEMMA', 'LEMMA_CTX_P-1': 'LEMMA', 'GPOS_CTX_P+0': 'GPOS', 'GPOS_CTX_P+1': 'GPOS', 'GPOS_CTX_P-1': 'GPOS', 'PRED_DIST': 'PRED_DIST', 'T': 'T', 'PredMorph_01': 'PredMorph', 'PredMorph_02': 'PredMorph', 'PredMorph_03': 'PredMorph', 'PredMorph_04': 'PredMorph', 'PredMorph_05': 'PredMorph', 'PredMorph_06': 'PredMorph', 'PredMorph_07': 'PredMorph', 'PredMorph_08': 'PredMorph', 'PredMorph_09': 'PredMorph', 'PredMorph_10': 'PredMorph', 'PredMorph_11': 'PredMorph', 'PredMorph_12': 'PredMorph', 'PredMorph_13': 'PredMorph', 'PredMorph_14': 'PredMorph', 'PredMorph_15': 'PredMorph', 'PredMorph_16': 'PredMorph', 'PredMorph_17': 'PredMorph', 'PredMorph_18': 'PredMorph', 'PredMorph_19': 'PredMorph', 'PredMorph_20': 'PredMorph', 'PredMorph_21': 'PredMorph', 'PredMorph_22': 'PredMorph', 'PredMorph_23': 'PredMorph', 'PredMorph_24': 'PredMorph', 'PredMorph_25': 'PredMorph', 'PredMorph_26': 'PredMorph', 'PredMorph_27': 'PredMorph', 'PredMorph_28': 'PredMorph', 'PredMorph_29': 'PredMorph', 'PredMorph_30': 'PredMorph', 'PredMorph_31': 'PredMorph', 'PredMorph_32': 'PredMorph', 'PredMorph_33': 'PredMorph', 'PredMorph_34': 'PredMorph', 'PASSIVE_VOICE': 'PASSIVE_VOICE', 'FUNC_00': 'FUNC', 'FUNC_01': 'FUNC', 'FUNC_02': 'FUNC', 'FUNC_03': 'FUNC', 'FUNC_04': 'FUNC', 'FUNC_05': 'FUNC', 'FUNC_06': 'FUNC', 'FUNC_07': 'FUNC', 'FUNC_08': 'FUNC', 'FUNC_09': 'FUNC', 'FUNC_10': 'FUNC', 'FUNC_11': 'FUNC', 'FUNC_12': 'FUNC', 'FUNC_13': 'FUNC', 'FUNC_14': 'FUNC', 'FUNC_15': 'FUNC', 'FUNC_16': 'FUNC', 'FUNC_17': 'FUNC', 'FUNC_18': 'FUNC', 'FUNC_19': 'FUNC', 'FUNC_20': 'FUNC', 'FUNC_21': 'FUNC', 'FUNC_CHILD_1': 'FUNC', 'FUNC_CHILD_2': 'FUNC', 'FUNC_CHILD_3': 'FUNC', 'FUNC_GRAND_PARENT': 'FUNC', 'FUNC_PARENT': 'FUNC', 'LEMMA_CHILD_1': 'LEMMA', 'LEMMA_CHILD_2': 'LEMMA', 'LEMMA_CHILD_3': 'LEMMA', 'LEMMA_GRAND_PARENT': 'LEMMA', 'LEMMA_PARENT': 'LEMMA', 'GPOS_00': 'GPOS', 'GPOS_01': 'GPOS', 'GPOS_02': 'GPOS', 'GPOS_03': 'GPOS', 'GPOS_04': 'GPOS', 'GPOS_05': 'GPOS', 'GPOS_06': 'GPOS', 'GPOS_07': 'GPOS', 'GPOS_08': 'GPOS', 'GPOS_09': 'GPOS', 'GPOS_10': 'GPOS', 'GPOS_11': 'GPOS', 'GPOS_12': 'GPOS', 'GPOS_13': 'GPOS', 'GPOS_14': 'GPOS', 'GPOS_15': 'GPOS', 'GPOS_16': 'GPOS', 'GPOS_17': 'GPOS', 'GPOS_18': 'GPOS', 'GPOS_19': 'GPOS', 'GPOS_20': 'GPOS', 'GPOS_21': 'GPOS', 'GPOS_CHILD_1': 'GPOS', 'GPOS_CHILD_2': 'GPOS', 'GPOS_CHILD_3': 'GPOS', 'GPOS_GRAND_PARENT': 'GPOS', 'GPOS_PARENT': 'GPOS', 'PRED_MARKER': 'PRED_MARKER'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_mapper = {col: subcol(col) for col in df.columns.tolist()}\n",
    "print(columns_mapper)\n",
    "dimension_mapper = {}\n",
    "for colfeat, colbase in columns_mapper.items():\n",
    "    if colbase in dictschema:\n",
    "        if 'domain' in dictschema[colbase]:\n",
    "            dimension_mapper[colfeat] = len( dictschema[colbase]['domain'])\n",
    "        else:\n",
    "            dimension_mapper[colfeat] = 1\n",
    "    else:\n",
    "        dimension_mapper[colfeat] = 1\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ARG', 'CTREE', 'DTREE', 'FORM', 'FUNC', 'GPOS', 'LEMMA', 'MORF', 'PRED'])\n",
      "dict_keys(['ID', 'S', 'P', 'P_S', 'FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED', 'ARG', 'FORM+1', 'FORM+2', 'FORM+3', 'FORM-1', 'FORM-2', 'FORM-3', 'FUNC+1', 'FUNC+2', 'FUNC+3', 'FUNC-1', 'FUNC-2', 'FUNC-3', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3', 'LEMMA-1', 'LEMMA-2', 'LEMMA-3', 'GPOS+1', 'GPOS+2', 'GPOS+3', 'GPOS-1', 'GPOS-2', 'GPOS-3', 'FUNC_CTX_P+0', 'FUNC_CTX_P+1', 'FUNC_CTX_P-1', 'LEMMA_CTX_P+0', 'LEMMA_CTX_P+1', 'LEMMA_CTX_P-1', 'GPOS_CTX_P+0', 'GPOS_CTX_P+1', 'GPOS_CTX_P-1', 'PRED_DIST'])\n"
     ]
    }
   ],
   "source": [
    "lexicons = {col : \n",
    "                dict(\n",
    "                     zip(dictschema[col]['domain'], \n",
    "                         range(1, dimension_mapper[col]+1)\n",
    "                        )\n",
    "                    )\n",
    "             for col in dictschema if  col in dictschema and 'domain' in dictschema[col]}\n",
    "\n",
    "\n",
    "columns = ['FORM', 'FUNC', 'GPOS', 'LEMMA', 'PRED'\n",
    "          'FORM-1', 'FORM+1', 'FUNC-1', 'FUNC+1',\n",
    "          'LEMMA-3', 'LEMMA-2', 'LEMMA-1', 'LEMMA+1', 'LEMMA+2', 'LEMMA+3',\n",
    "          'GPOS-3', 'GPOS-2', 'GPOS-1', 'GPOS+1', 'GPOS+2', 'GPOS+3',\n",
    "          'FUNC-3', 'FUNC-2',  'FUNC+2', 'FUNC+3',\n",
    "          'GPOS_CTX_P-1', 'GPOS_CTX_P+0', 'GPOS_CTX_P+1',\n",
    "          'LEMMA_CTX_P-1', 'LEMMA_CTX_P+0', 'LEMMA_CTX_P+1', 'PRED_DIST']\n",
    "\n",
    "\n",
    "d = df.to_dict()\n",
    "\n",
    "print(lexicons.keys())\n",
    "print(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1000: 1,\n",
       " 14001: 1,\n",
       " 22368: 1,\n",
       " 22387: 1,\n",
       " 22418: 1,\n",
       " 22512: 1,\n",
       " 22552: 1,\n",
       " 22747: 1,\n",
       " 23628: 1,\n",
       " 36918: 1,\n",
       " 50208: 1,\n",
       " 76627: 1,\n",
       " 85109: 1,\n",
       " 100999: 1,\n",
       " 103368: 1,\n",
       " 112439: 1,\n",
       " 121510: 1,\n",
       " 139542: 1,\n",
       " 140728: 1,\n",
       " 156191: 1,\n",
       " 157794: 1,\n",
       " 157819: 1,\n",
       " 157844: 1,\n",
       " 157891: 1,\n",
       " 157911: 1,\n",
       " 157933: 1,\n",
       " 157944: 1,\n",
       " 157993: 1,\n",
       " 158042: 1,\n",
       " 158126: 1,\n",
       " 158174: 1,\n",
       " 158198: 1,\n",
       " 158252: 1,\n",
       " 158278: 1,\n",
       " 158306: 1,\n",
       " 165781: 1,\n",
       " 169132: 1,\n",
       " 179804: 1,\n",
       " 185526: 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [] \n",
    "sparse_features = defaultdict(dict)\n",
    "propositions = []        \n",
    "\n",
    "for idx, propid in d['P'].items():\n",
    "    lb = 1 \n",
    "    for col in columns:\n",
    "        base_col = columns_mapper[col]\n",
    "        categorical = d[col][idx] \n",
    "        if base_col in lexicons and categorical in lexicons[base_col]:\n",
    "            idx1 = lexicons[base_col][categorical]\n",
    "            sparse_features[idx][lb + idx1]=1 \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse_features[idx][lb]=1 \n",
    "        lb += dimension_mapper[col] \n",
    "\n",
    "    args.append(lexicons['ARG'][d['ARG'][idx]]) \n",
    "    propositions.append( propid )\n",
    "\n",
    "        \n",
    "sparse_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 28, 15, 32, 26]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>S</th>\n",
       "      <th>P</th>\n",
       "      <th>P_S</th>\n",
       "      <th>FORM</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>GPOS</th>\n",
       "      <th>MORF</th>\n",
       "      <th>DTREE</th>\n",
       "      <th>FUNC</th>\n",
       "      <th>...</th>\n",
       "      <th>FUNC_CTX_P+0</th>\n",
       "      <th>FUNC_CTX_P+1</th>\n",
       "      <th>FUNC_CTX_P-1</th>\n",
       "      <th>LEMMA_CTX_P+0</th>\n",
       "      <th>LEMMA_CTX_P+1</th>\n",
       "      <th>LEMMA_CTX_P-1</th>\n",
       "      <th>GPOS_CTX_P+0</th>\n",
       "      <th>GPOS_CTX_P+1</th>\n",
       "      <th>GPOS_CTX_P-1</th>\n",
       "      <th>PRED_DIST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>PROP</td>\n",
       "      <td>F|S</td>\n",
       "      <td>5</td>\n",
       "      <td>ADVL</td>\n",
       "      <td>...</td>\n",
       "      <td>STA</td>\n",
       "      <td>&gt;N</td>\n",
       "      <td>ADVL</td>\n",
       "      <td>revelar</td>\n",
       "      <td>um</td>\n",
       "      <td>hoje</td>\n",
       "      <td>V-FIN</td>\n",
       "      <td>ART</td>\n",
       "      <td>ADV</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  S  P  P_S      FORM     LEMMA  GPOS MORF  DTREE  FUNC    ...     \\\n",
       "INDEX                                                               ...      \n",
       "0       1  1  1    0  Brasília  Brasília  PROP  F|S      5  ADVL    ...      \n",
       "\n",
       "      FUNC_CTX_P+0 FUNC_CTX_P+1 FUNC_CTX_P-1 LEMMA_CTX_P+0 LEMMA_CTX_P+1  \\\n",
       "INDEX                                                                      \n",
       "0              STA           >N         ADVL       revelar            um   \n",
       "\n",
       "      LEMMA_CTX_P-1 GPOS_CTX_P+0 GPOS_CTX_P+1 GPOS_CTX_P-1 PRED_DIST  \n",
       "INDEX                                                                 \n",
       "0              hoje        V-FIN          ART          ADV         4  \n",
       "\n",
       "[1 rows x 47 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FORM .: first sparse feature = lexicons['FORM']['Brasília'] --> 134\n",
    "# LEMMA .: second sparse feature = dimension_mapper['FORM'] + lexicons['LEMMA']['Brasília'] --> 13386\n",
    "# GPOS .: third sparse feature =  dimension_mapper['FORM'] +  dimension_mapper['LEMMA'] + lexicons['GPOS']['PROP'] --> 22362\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convert ARGS into T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*', 'A0', 'A0', 'A0', 'V']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments = [value for key, value in d['ARG'].items()] \n",
    "targets = propbankbr_arg2t(propositions, arguments)\n",
    "\n",
    "targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_keys = set(targets)\n",
    "target_idxs = range(len(target_keys))\n",
    "targets_mapper = dict(zip(target_keys, target_idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save onehot representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds_type in ('train', 'test', 'valid'):    \n",
    "    if ds_type in ('train'):                \n",
    "      lb = 0\n",
    "      ub = DATASET_TRAIN_SIZE \n",
    "\n",
    "    if ds_type in ('valid'):                \n",
    "      lb = DATASET_TRAIN_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE\n",
    "\n",
    "    if ds_type in ('test'):                \n",
    "      lb = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE + DATASET_TEST_SIZE\n",
    "        \n",
    "    # saves the processed data\n",
    "    svm_path = '{:}/{:}/{:}.svm'.format(SVM_DIR, 'hot', ds_type)\n",
    "    with open(svm_path, mode='w') as f:\n",
    "        for idx in sparse_features:\n",
    "            p = propositions[idx]\n",
    "            if p > lb and p < ub + 1:\n",
    "                #1 - indexed value for sparse features, \n",
    "                # segmentation error 11 caused by zero indexed array\n",
    "                target = '{:} '.format(int(targets_mapper[targets[idx]]))\n",
    "                features = ' '.join([ '{:}:{:}'.format(key , val) \n",
    "                     for key, val in sparse_features[idx].items()])\n",
    "                ex = '{:}{:}\\n'.format(target, features)\n",
    "                f.write(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(GLOVE_S50_PATH, unicode_errors=\"ignore\")\n",
    "embeddings_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# converts a word into a token,\n",
    "# word might be in fact a number\n",
    "def tokenize(word):\n",
    "    token = word\n",
    "    if is_number(word):\n",
    "        token = '0'    \n",
    "    elif word.lower() in word2vec:\n",
    "        token = word.lower()\n",
    "    else:\n",
    "        token = 'unk'\n",
    "    return token\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Process replacing sparse with feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: -0.35242301,\n",
       " 2: 0.52991003,\n",
       " 3: 1.378052,\n",
       " 4: -2.6353519,\n",
       " 5: 0.064434998,\n",
       " 6: 0.51971298,\n",
       " 7: -0.89432102,\n",
       " 8: -1.146332,\n",
       " 9: -0.71181601,\n",
       " 10: 0.21502399,\n",
       " 11: -0.32224,\n",
       " 12: -0.087746002,\n",
       " 13: 0.54578102,\n",
       " 14: -0.072255999,\n",
       " 15: -0.138069,\n",
       " 16: -1.0330909,\n",
       " 17: 0.374457,\n",
       " 18: 0.41515201,\n",
       " 19: 0.062208001,\n",
       " 20: 0.061988998,\n",
       " 21: 0.53525698,\n",
       " 22: -0.57822698,\n",
       " 23: -0.77802098,\n",
       " 24: -1.77086,\n",
       " 25: -0.867414,\n",
       " 26: 0.44269899,\n",
       " 27: -0.81675398,\n",
       " 28: -0.23604099,\n",
       " 29: -0.16220599,\n",
       " 30: 0.226478,\n",
       " 31: 0.839167,\n",
       " 32: -0.069043003,\n",
       " 33: -0.37729999,\n",
       " 34: -0.138179,\n",
       " 35: -0.15516201,\n",
       " 36: 0.137887,\n",
       " 37: 0.052816,\n",
       " 38: 0.47624999,\n",
       " 39: -0.54324901,\n",
       " 40: -0.35822999,\n",
       " 41: -0.21709099,\n",
       " 42: 0.26028901,\n",
       " 43: 0.0069400002,\n",
       " 44: -0.95268399,\n",
       " 45: 0.558254,\n",
       " 46: -0.28643,\n",
       " 47: -0.211694,\n",
       " 48: 0.59664899,\n",
       " 49: 0.311598,\n",
       " 50: -0.25995699,\n",
       " 51: -0.35242301,\n",
       " 52: 0.52991003,\n",
       " 53: 1.378052,\n",
       " 54: -2.6353519,\n",
       " 55: 0.064434998,\n",
       " 56: 0.51971298,\n",
       " 57: -0.89432102,\n",
       " 58: -1.146332,\n",
       " 59: -0.71181601,\n",
       " 60: 0.21502399,\n",
       " 61: -0.32224,\n",
       " 62: -0.087746002,\n",
       " 63: 0.54578102,\n",
       " 64: -0.072255999,\n",
       " 65: -0.138069,\n",
       " 66: -1.0330909,\n",
       " 67: 0.374457,\n",
       " 68: 0.41515201,\n",
       " 69: 0.062208001,\n",
       " 70: 0.061988998,\n",
       " 71: 0.53525698,\n",
       " 72: -0.57822698,\n",
       " 73: -0.77802098,\n",
       " 74: -1.77086,\n",
       " 75: -0.867414,\n",
       " 76: 0.44269899,\n",
       " 77: -0.81675398,\n",
       " 78: -0.23604099,\n",
       " 79: -0.16220599,\n",
       " 80: 0.226478,\n",
       " 81: 0.839167,\n",
       " 82: -0.069043003,\n",
       " 83: -0.37729999,\n",
       " 84: -0.138179,\n",
       " 85: -0.15516201,\n",
       " 86: 0.137887,\n",
       " 87: 0.052816,\n",
       " 88: 0.47624999,\n",
       " 89: -0.54324901,\n",
       " 90: -0.35822999,\n",
       " 91: -0.21709099,\n",
       " 92: 0.26028901,\n",
       " 93: 0.0069400002,\n",
       " 94: -0.95268399,\n",
       " 95: 0.558254,\n",
       " 96: -0.28643,\n",
       " 97: -0.211694,\n",
       " 98: 0.59664899,\n",
       " 99: 0.311598,\n",
       " 100: -0.25995699,\n",
       " 101: 1,\n",
       " 126: 1,\n",
       " 151: 1,\n",
       " 242: 1,\n",
       " 291: 1,\n",
       " 340: -0.13177501,\n",
       " 341: 0.119078,\n",
       " 342: -0.62300402,\n",
       " 343: -4.10287,\n",
       " 344: 0.116101,\n",
       " 345: 0.017778,\n",
       " 346: 0.125692,\n",
       " 347: -0.69134402,\n",
       " 348: -0.73476398,\n",
       " 349: 0.28201601,\n",
       " 350: -0.25720701,\n",
       " 351: 0.224925,\n",
       " 352: -0.044599999,\n",
       " 353: 0.81935298,\n",
       " 354: 0.137106,\n",
       " 355: -0.44178101,\n",
       " 356: -0.39970899,\n",
       " 357: 0.162916,\n",
       " 358: 0.113267,\n",
       " 359: 0.020202,\n",
       " 360: 0.874089,\n",
       " 361: -0.45386899,\n",
       " 362: -0.39280099,\n",
       " 363: 0.037046999,\n",
       " 364: -0.189419,\n",
       " 365: -0.309971,\n",
       " 366: 0.148041,\n",
       " 367: 0.84257299,\n",
       " 368: 0.29945299,\n",
       " 369: 1.765025,\n",
       " 370: -0.93225503,\n",
       " 371: -0.29690799,\n",
       " 372: 0.477245,\n",
       " 373: 0.52375001,\n",
       " 374: 0.47029299,\n",
       " 375: -0.53934997,\n",
       " 376: -0.50192899,\n",
       " 377: -0.80594897,\n",
       " 378: -0.90731901,\n",
       " 379: -0.057719,\n",
       " 380: 0.177518,\n",
       " 381: -0.015765,\n",
       " 382: -0.79582697,\n",
       " 383: -0.179671,\n",
       " 384: -0.45981801,\n",
       " 385: 0.032226,\n",
       " 386: 0.14668299,\n",
       " 387: -0.18351699,\n",
       " 388: 0.70326602,\n",
       " 389: -0.682172,\n",
       " 390: 1,\n",
       " 13680: 1,\n",
       " 26970: 1,\n",
       " 40260: 1,\n",
       " 53550: 1,\n",
       " 66840: 1,\n",
       " 80130: 1,\n",
       " 89201: 1,\n",
       " 98272: 1,\n",
       " 107343: 1,\n",
       " 116414: 1,\n",
       " 125485: 1,\n",
       " 134556: 1,\n",
       " 134581: 1,\n",
       " 134606: 1,\n",
       " 134631: 1,\n",
       " 134656: 1,\n",
       " 134681: 1,\n",
       " 134706: 1,\n",
       " 134755: 1,\n",
       " 134804: 1,\n",
       " 134853: 1,\n",
       " 134902: 1,\n",
       " 134951: 1,\n",
       " 135000: 1,\n",
       " 135025: 1,\n",
       " 135050: 1,\n",
       " 135075: 1,\n",
       " 144146: 1,\n",
       " 153217: 1,\n",
       " 162288: 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [] \n",
    "sparse_features = defaultdict(dict)\n",
    "propositions = []        \n",
    "# columns = ['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED']\n",
    "bounds_mapper = defaultdict(dict)\n",
    "for idx, propid in d['P'].items():\n",
    "    lb = 1 \n",
    "    for col in columns:\n",
    "        base_col = columns_mapper[col]\n",
    "        word = d[col][idx] \n",
    "        if not 'lb' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['lb'] = lb \n",
    "        if col in ('FORM', 'LEMMA', 'PRED'):\n",
    "            sz = embeddings_size\n",
    "            token = tokenize(word)\n",
    "            values = list(word2vec[token])\n",
    "                \n",
    "            sparse_features[idx].update({\n",
    "                i + lb: val\n",
    "                for i, val in enumerate(values)\n",
    "            })\n",
    "        elif base_col in lexicons and categorical in lexicons[base_col]:\n",
    "            idx1 = lexicons[base_col][categorical]\n",
    "            sparse_features[idx][lb + idx1]=1 \n",
    "            sz = dimension_mapper[col] \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse_features[idx][lb]=1 \n",
    "            sz = dimension_mapper[col]           \n",
    "        lb += sz\n",
    "        if not 'ub' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['ub'] = lb \n",
    "\n",
    "    args.append(lexicons['ARG'][d['ARG'][idx]]) \n",
    "    propositions.append( propid )\n",
    "\n",
    "        \n",
    "sparse_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'FORM': {'lb': 1, 'ub': 51}, 'LEMMA': {'lb': 51, 'ub': 101}, 'GPOS': {'lb': 101, 'ub': 126}, 'MORF': {'lb': 126, 'ub': 151}, 'DTREE': {'lb': 151, 'ub': 242}, 'FUNC': {'lb': 242, 'ub': 291}, 'CTREE': {'lb': 291, 'ub': 340}, 'PRED': {'lb': 340, 'ub': 390}, 'FORM-3': {'lb': 390, 'ub': 13680}, 'FORM-2': {'lb': 13680, 'ub': 26970}, 'FORM-1': {'lb': 26970, 'ub': 40260}, 'FORM+1': {'lb': 40260, 'ub': 53550}, 'FORM+2': {'lb': 53550, 'ub': 66840}, 'FORM+3': {'lb': 66840, 'ub': 80130}, 'LEMMA-3': {'lb': 80130, 'ub': 89201}, 'LEMMA-2': {'lb': 89201, 'ub': 98272}, 'LEMMA-1': {'lb': 98272, 'ub': 107343}, 'LEMMA+1': {'lb': 107343, 'ub': 116414}, 'LEMMA+2': {'lb': 116414, 'ub': 125485}, 'LEMMA+3': {'lb': 125485, 'ub': 134556}, 'GPOS-3': {'lb': 134556, 'ub': 134581}, 'GPOS-2': {'lb': 134581, 'ub': 134606}, 'GPOS-1': {'lb': 134606, 'ub': 134631}, 'GPOS+1': {'lb': 134631, 'ub': 134656}, 'GPOS+2': {'lb': 134656, 'ub': 134681}, 'GPOS+3': {'lb': 134681, 'ub': 134706}, 'FUNC-3': {'lb': 134706, 'ub': 134755}, 'FUNC-2': {'lb': 134755, 'ub': 134804}, 'FUNC-1': {'lb': 134804, 'ub': 134853}, 'FUNC+1': {'lb': 134853, 'ub': 134902}, 'FUNC+2': {'lb': 134902, 'ub': 134951}, 'FUNC+3': {'lb': 134951, 'ub': 135000}, 'GPOS_CTX_P-1': {'lb': 135000, 'ub': 135025}, 'GPOS_CTX_P+0': {'lb': 135025, 'ub': 135050}, 'GPOS_CTX_P+1': {'lb': 135050, 'ub': 135075}, 'LEMMA_CTX_P-1': {'lb': 135075, 'ub': 144146}, 'LEMMA_CTX_P+0': {'lb': 144146, 'ub': 153217}, 'LEMMA_CTX_P+1': {'lb': 153217, 'ub': 162288}, 'PRED_DIST': {'lb': 162288, 'ub': 162289}})\n"
     ]
    }
   ],
   "source": [
    "print(bounds_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Scale mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: -0.15909999999999999,\n",
       " 2: 0.2671,\n",
       " 3: 0.75890000000000002,\n",
       " 4: -0.33579999999999999,\n",
       " 5: 0.1467,\n",
       " 6: 0.1449,\n",
       " 7: -0.40110000000000001,\n",
       " 8: -0.52400000000000002,\n",
       " 9: -0.185,\n",
       " 10: -0.083000000000000004,\n",
       " 11: -0.069400000000000003,\n",
       " 12: -0.096100000000000005,\n",
       " 13: 0.32290000000000002,\n",
       " 14: 0.02,\n",
       " 15: 0.042900000000000001,\n",
       " 16: -0.59379999999999999,\n",
       " 17: 0.17599999999999999,\n",
       " 18: 0.18629999999999999,\n",
       " 19: -0.1148,\n",
       " 20: -0.056000000000000001,\n",
       " 21: 0.078100000000000003,\n",
       " 22: -0.26019999999999999,\n",
       " 23: -0.30969999999999998,\n",
       " 24: -0.60980000000000001,\n",
       " 25: -0.28510000000000002,\n",
       " 26: 0.31440000000000001,\n",
       " 27: -0.37040000000000001,\n",
       " 28: -0.1996,\n",
       " 29: -0.041700000000000001,\n",
       " 30: -0.17000000000000001,\n",
       " 31: 0.48049999999999998,\n",
       " 32: -0.090300000000000005,\n",
       " 33: -0.25700000000000001,\n",
       " 34: -0.068500000000000005,\n",
       " 35: -0.059999999999999998,\n",
       " 36: 0.2329,\n",
       " 37: 0.0012999999999999999,\n",
       " 38: 0.26700000000000002,\n",
       " 39: 0.017899999999999999,\n",
       " 40: -0.22370000000000001,\n",
       " 41: -0.16619999999999999,\n",
       " 42: 0.1053,\n",
       " 43: 0.0332,\n",
       " 44: -0.36430000000000001,\n",
       " 45: 0.079000000000000001,\n",
       " 46: -0.13919999999999999,\n",
       " 47: -0.19159999999999999,\n",
       " 48: 0.44500000000000001,\n",
       " 49: 0.16309999999999999,\n",
       " 50: -0.191,\n",
       " 51: -0.068599999999999994,\n",
       " 52: 0.2316,\n",
       " 53: 0.72909999999999997,\n",
       " 54: -0.33579999999999999,\n",
       " 55: 0.1239,\n",
       " 56: 0.1449,\n",
       " 57: -0.38600000000000001,\n",
       " 58: -0.52610000000000001,\n",
       " 59: -0.185,\n",
       " 60: -0.0395,\n",
       " 61: -0.084099999999999994,\n",
       " 62: -0.094600000000000004,\n",
       " 63: 0.37969999999999998,\n",
       " 64: 0.02,\n",
       " 65: 0.042900000000000001,\n",
       " 66: -0.60099999999999998,\n",
       " 67: 0.18729999999999999,\n",
       " 68: 0.1827,\n",
       " 69: -0.129,\n",
       " 70: -0.033500000000000002,\n",
       " 71: 0.19739999999999999,\n",
       " 72: -0.34460000000000002,\n",
       " 73: -0.46250000000000002,\n",
       " 74: -0.57730000000000004,\n",
       " 75: -0.34449999999999997,\n",
       " 76: 0.25359999999999999,\n",
       " 77: -0.37040000000000001,\n",
       " 78: -0.219,\n",
       " 79: 0.0016999999999999999,\n",
       " 80: -0.1512,\n",
       " 81: 0.4178,\n",
       " 82: -0.090300000000000005,\n",
       " 83: -0.25700000000000001,\n",
       " 84: -0.00040000000000000002,\n",
       " 85: -0.1492,\n",
       " 86: -0.016799999999999999,\n",
       " 87: 0.021499999999999998,\n",
       " 88: 0.25609999999999999,\n",
       " 89: 0.017899999999999999,\n",
       " 90: -0.2296,\n",
       " 91: -0.16619999999999999,\n",
       " 92: 0.076799999999999993,\n",
       " 93: -0.081500000000000003,\n",
       " 94: -0.29770000000000002,\n",
       " 95: 0.1154,\n",
       " 96: -0.13919999999999999,\n",
       " 97: -0.17580000000000001,\n",
       " 98: 0.46529999999999999,\n",
       " 99: 0.1024,\n",
       " 100: -0.18429999999999999,\n",
       " 101: 1,\n",
       " 126: 1,\n",
       " 151: 1,\n",
       " 242: 1,\n",
       " 291: 1,\n",
       " 340: 0.067500000000000004,\n",
       " 341: 0.39279999999999998,\n",
       " 342: -0.36049999999999999,\n",
       " 343: -1.0,\n",
       " 344: 0.13420000000000001,\n",
       " 345: 0.032000000000000001,\n",
       " 346: 0.10299999999999999,\n",
       " 347: -0.38390000000000002,\n",
       " 348: -0.27379999999999999,\n",
       " 349: 0.00050000000000000001,\n",
       " 350: 0.2235,\n",
       " 351: 0.0091000000000000004,\n",
       " 352: 0.1918,\n",
       " 353: 0.51959999999999995,\n",
       " 354: 0.034299999999999997,\n",
       " 355: -0.083599999999999994,\n",
       " 356: -0.24970000000000001,\n",
       " 357: 0.4078,\n",
       " 358: 0.051900000000000002,\n",
       " 359: -0.27960000000000002,\n",
       " 360: 0.10349999999999999,\n",
       " 361: -0.085099999999999995,\n",
       " 362: -0.48999999999999999,\n",
       " 363: 0.058799999999999998,\n",
       " 364: 0.0149,\n",
       " 365: 0.079299999999999995,\n",
       " 366: -0.27589999999999998,\n",
       " 367: 0.31769999999999998,\n",
       " 368: -0.0458,\n",
       " 369: 0.73980000000000001,\n",
       " 370: -0.41110000000000002,\n",
       " 371: -0.33860000000000001,\n",
       " 372: 0.0402,\n",
       " 373: 0.36799999999999999,\n",
       " 374: 0.54520000000000002,\n",
       " 375: -0.19389999999999999,\n",
       " 376: -0.43240000000000001,\n",
       " 377: -0.70720000000000005,\n",
       " 378: -0.33439999999999998,\n",
       " 379: -0.1772,\n",
       " 380: 0.26779999999999998,\n",
       " 381: 0.0499,\n",
       " 382: -0.71989999999999998,\n",
       " 383: -0.3352,\n",
       " 384: -0.4365,\n",
       " 385: -0.2772,\n",
       " 386: -0.19439999999999999,\n",
       " 387: -0.30930000000000002,\n",
       " 388: 0.36880000000000002,\n",
       " 389: -0.28720000000000001,\n",
       " 390: 1,\n",
       " 13680: 1,\n",
       " 26970: 1,\n",
       " 40260: 1,\n",
       " 53550: 1,\n",
       " 66840: 1,\n",
       " 80130: 1,\n",
       " 89201: 1,\n",
       " 98272: 1,\n",
       " 107343: 1,\n",
       " 116414: 1,\n",
       " 125485: 1,\n",
       " 134556: 1,\n",
       " 134581: 1,\n",
       " 134606: 1,\n",
       " 134631: 1,\n",
       " 134656: 1,\n",
       " 134681: 1,\n",
       " 134706: 1,\n",
       " 134755: 1,\n",
       " 134804: 1,\n",
       " 134853: 1,\n",
       " 134902: 1,\n",
       " 134951: 1,\n",
       " 135000: 1,\n",
       " 135025: 1,\n",
       " 135050: 1,\n",
       " 135075: 1,\n",
       " 144146: 1,\n",
       " 153217: 1,\n",
       " 162288: 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_d = defaultdict(list)\n",
    "for col in columns:\n",
    "#     if is_dense(col, columns_mapper): Missing values not handled FORM-3\n",
    "    if col in ('FORM', 'LEMMA', 'PRED'):\n",
    "        lb = bounds_mapper[col]['lb']\n",
    "        ub = bounds_mapper[col]['ub']\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                series_d[x].append(sparse_features[idx][x])\n",
    "\n",
    "        # standardize\n",
    "        for f in range(lb, ub):\n",
    "            n = len(series_d[f])\n",
    "            mu_x = sum(series_d[f]) / n\n",
    "            ssq_x = sum([(x - mu_x)*(x - mu_x) for x in series_d[f]])\n",
    "            std_x = math.sqrt(ssq_x/ (n-1))\n",
    "            \n",
    "            series_d[f] = [(x - mu_x)/ std_x for x in series_d[f]]            \n",
    "        # rescale\n",
    "        for f in range(lb, ub):\n",
    "            min_x = min(series_d[f])\n",
    "            max_x = max(series_d[f])\n",
    "            series_d[f] = [\n",
    "                (2*x - min_x - max_x)/ (max_x - min_x)\n",
    "                for x in series_d[f]\n",
    "            ]            \n",
    "        # move rescaled and standardized back to sparse_features\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                sparse_features[idx][x] = series_d[x][idx]\n",
    "\n",
    "        # round values\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):                \n",
    "                sparse_features[idx][x] = round(sparse_features[idx][x], 4)\n",
    "            \n",
    "                \n",
    "        \n",
    "sparse_features[0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Save mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds_type in ('train', 'test', 'valid'):    \n",
    "    if ds_type in ('train'):                \n",
    "      lb = 0\n",
    "      ub = DATASET_TRAIN_SIZE \n",
    "\n",
    "    if ds_type in ('valid'):                \n",
    "      lb = DATASET_TRAIN_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE\n",
    "\n",
    "    if ds_type in ('test'):                \n",
    "      lb = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE + DATASET_TEST_SIZE\n",
    "        \n",
    "    # saves the processed data\n",
    "    svm_path = '{:}/{:}/{:}.svm'.format(SVM_DIR, 'glo', ds_type)\n",
    "    with open(svm_path, mode='w') as f:\n",
    "        for idx in sparse_features:\n",
    "            p = propositions[idx]\n",
    "            if p > lb and p < ub + 1:\n",
    "                target = '{:} '.format(int(targets_mapper[targets[idx]]))\n",
    "                features = ' '.join([ '{:}:{:}'.format(key, val) \n",
    "                     for key, val in sparse_features[idx].items()])\n",
    "                ex = '{:}{:}\\n'.format(target, features)\n",
    "                f.write(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Wang2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(WANG_S100_PATH, unicode_errors=\"ignore\")\n",
    "embeddings_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Process replacing sparse with wang2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -0.52029401,\n",
       " 1: -1.084011,\n",
       " 2: 0.57885402,\n",
       " 3: -0.63992798,\n",
       " 4: -0.038910002,\n",
       " 5: 0.62952298,\n",
       " 6: -0.082349002,\n",
       " 7: 0.29049999,\n",
       " 8: -0.83230901,\n",
       " 9: 0.70121199,\n",
       " 10: -0.115194,\n",
       " 11: 0.22070201,\n",
       " 12: 0.27586901,\n",
       " 13: -0.26365501,\n",
       " 14: -0.177855,\n",
       " 15: 0.145326,\n",
       " 16: 0.58414203,\n",
       " 17: -0.49399501,\n",
       " 18: 0.089759,\n",
       " 19: 0.47134301,\n",
       " 20: 0.16844399,\n",
       " 21: -0.239599,\n",
       " 22: -0.035000999,\n",
       " 23: -0.318086,\n",
       " 24: -0.044199001,\n",
       " 25: 0.39588401,\n",
       " 26: 0.51004899,\n",
       " 27: 0.461573,\n",
       " 28: 0.36443901,\n",
       " 29: -0.147663,\n",
       " 30: 0.012673,\n",
       " 31: 0.469439,\n",
       " 32: -0.54493499,\n",
       " 33: 0.60724401,\n",
       " 34: -0.32190999,\n",
       " 35: -0.0071990001,\n",
       " 36: 0.043249,\n",
       " 37: -0.38506499,\n",
       " 38: -0.35674,\n",
       " 39: -0.47903901,\n",
       " 40: -0.31924799,\n",
       " 41: 0.155983,\n",
       " 42: 0.091351002,\n",
       " 43: -0.218468,\n",
       " 44: 0.14129899,\n",
       " 45: 0.481749,\n",
       " 46: 0.077671997,\n",
       " 47: 0.19820599,\n",
       " 48: -0.72299701,\n",
       " 49: -0.33969,\n",
       " 50: -0.055128001,\n",
       " 51: -0.31261799,\n",
       " 52: -0.64407998,\n",
       " 53: -0.31589401,\n",
       " 54: -0.61545199,\n",
       " 55: 0.708318,\n",
       " 56: 0.106625,\n",
       " 57: -0.15074199,\n",
       " 58: -0.47371799,\n",
       " 59: 0.30649301,\n",
       " 60: -0.403703,\n",
       " 61: 0.87191802,\n",
       " 62: 0.071199,\n",
       " 63: -0.237854,\n",
       " 64: 0.084390998,\n",
       " 65: 0.102083,\n",
       " 66: 0.524333,\n",
       " 67: -0.48130101,\n",
       " 68: 0.433521,\n",
       " 69: 0.73176497,\n",
       " 70: 0.051911999,\n",
       " 71: -0.126195,\n",
       " 72: 0.293378,\n",
       " 73: -0.27858999,\n",
       " 74: -0.53096598,\n",
       " 75: 0.37584201,\n",
       " 76: -0.30789599,\n",
       " 77: 0.19755299,\n",
       " 78: -0.33704001,\n",
       " 79: 0.132925,\n",
       " 80: 0.22403,\n",
       " 81: 0.16534901,\n",
       " 82: -0.386498,\n",
       " 83: 0.044962998,\n",
       " 84: -0.10936,\n",
       " 85: 0.744672,\n",
       " 86: -0.292669,\n",
       " 87: -0.183264,\n",
       " 88: 1.053728,\n",
       " 89: -1.050774,\n",
       " 90: 0.272176,\n",
       " 91: 0.51497102,\n",
       " 92: 0.27353001,\n",
       " 93: -0.23726299,\n",
       " 94: 0.189299,\n",
       " 95: 0.049828999,\n",
       " 96: -0.55716801,\n",
       " 97: 0.25677899,\n",
       " 98: -0.101224,\n",
       " 99: -0.85618502,\n",
       " 100: -0.52029401,\n",
       " 101: -1.084011,\n",
       " 102: 0.57885402,\n",
       " 103: -0.63992798,\n",
       " 104: -0.038910002,\n",
       " 105: 0.62952298,\n",
       " 106: -0.082349002,\n",
       " 107: 0.29049999,\n",
       " 108: -0.83230901,\n",
       " 109: 0.70121199,\n",
       " 110: -0.115194,\n",
       " 111: 0.22070201,\n",
       " 112: 0.27586901,\n",
       " 113: -0.26365501,\n",
       " 114: -0.177855,\n",
       " 115: 0.145326,\n",
       " 116: 0.58414203,\n",
       " 117: -0.49399501,\n",
       " 118: 0.089759,\n",
       " 119: 0.47134301,\n",
       " 120: 0.16844399,\n",
       " 121: -0.239599,\n",
       " 122: -0.035000999,\n",
       " 123: -0.318086,\n",
       " 124: -0.044199001,\n",
       " 125: 0.39588401,\n",
       " 126: 0.51004899,\n",
       " 127: 0.461573,\n",
       " 128: 0.36443901,\n",
       " 129: -0.147663,\n",
       " 130: 0.012673,\n",
       " 131: 0.469439,\n",
       " 132: -0.54493499,\n",
       " 133: 0.60724401,\n",
       " 134: -0.32190999,\n",
       " 135: -0.0071990001,\n",
       " 136: 0.043249,\n",
       " 137: -0.38506499,\n",
       " 138: -0.35674,\n",
       " 139: -0.47903901,\n",
       " 140: -0.31924799,\n",
       " 141: 0.155983,\n",
       " 142: 0.091351002,\n",
       " 143: -0.218468,\n",
       " 144: 0.14129899,\n",
       " 145: 0.481749,\n",
       " 146: 0.077671997,\n",
       " 147: 0.19820599,\n",
       " 148: -0.72299701,\n",
       " 149: -0.33969,\n",
       " 150: -0.055128001,\n",
       " 151: -0.31261799,\n",
       " 152: -0.64407998,\n",
       " 153: -0.31589401,\n",
       " 154: -0.61545199,\n",
       " 155: 0.708318,\n",
       " 156: 0.106625,\n",
       " 157: -0.15074199,\n",
       " 158: -0.47371799,\n",
       " 159: 0.30649301,\n",
       " 160: -0.403703,\n",
       " 161: 0.87191802,\n",
       " 162: 0.071199,\n",
       " 163: -0.237854,\n",
       " 164: 0.084390998,\n",
       " 165: 0.102083,\n",
       " 166: 0.524333,\n",
       " 167: -0.48130101,\n",
       " 168: 0.433521,\n",
       " 169: 0.73176497,\n",
       " 170: 0.051911999,\n",
       " 171: -0.126195,\n",
       " 172: 0.293378,\n",
       " 173: -0.27858999,\n",
       " 174: -0.53096598,\n",
       " 175: 0.37584201,\n",
       " 176: -0.30789599,\n",
       " 177: 0.19755299,\n",
       " 178: -0.33704001,\n",
       " 179: 0.132925,\n",
       " 180: 0.22403,\n",
       " 181: 0.16534901,\n",
       " 182: -0.386498,\n",
       " 183: 0.044962998,\n",
       " 184: -0.10936,\n",
       " 185: 0.744672,\n",
       " 186: -0.292669,\n",
       " 187: -0.183264,\n",
       " 188: 1.053728,\n",
       " 189: -1.050774,\n",
       " 190: 0.272176,\n",
       " 191: 0.51497102,\n",
       " 192: 0.27353001,\n",
       " 193: -0.23726299,\n",
       " 194: 0.189299,\n",
       " 195: 0.049828999,\n",
       " 196: -0.55716801,\n",
       " 197: 0.25677899,\n",
       " 198: -0.101224,\n",
       " 199: -0.85618502,\n",
       " 200: 1,\n",
       " 225: 1,\n",
       " 250: 1,\n",
       " 341: 1,\n",
       " 390: 1,\n",
       " 439: 0.137961,\n",
       " 440: -0.40723401,\n",
       " 441: 0.052871998,\n",
       " 442: -0.031874999,\n",
       " 443: 0.74560601,\n",
       " 444: -0.224337,\n",
       " 445: 0.021869,\n",
       " 446: -0.47269499,\n",
       " 447: -0.25640199,\n",
       " 448: 0.220019,\n",
       " 449: 0.74274999,\n",
       " 450: 0.60324001,\n",
       " 451: -0.18155999,\n",
       " 452: -0.034256998,\n",
       " 453: 0.115018,\n",
       " 454: 0.40557399,\n",
       " 455: 0.48113799,\n",
       " 456: -0.34459299,\n",
       " 457: 0.38944399,\n",
       " 458: 0.208827,\n",
       " 459: -0.20047,\n",
       " 460: 0.066243999,\n",
       " 461: 0.29349899,\n",
       " 462: -0.19375899,\n",
       " 463: -0.34377,\n",
       " 464: 0.31036299,\n",
       " 465: 0.24153,\n",
       " 466: 0.31575301,\n",
       " 467: 0.179635,\n",
       " 468: 0.111344,\n",
       " 469: 0.115479,\n",
       " 470: 0.077885002,\n",
       " 471: -0.099453002,\n",
       " 472: -0.30831999,\n",
       " 473: -0.44126999,\n",
       " 474: -0.303119,\n",
       " 475: -0.033282001,\n",
       " 476: -0.57817298,\n",
       " 477: -0.276618,\n",
       " 478: -0.56031102,\n",
       " 479: -0.299288,\n",
       " 480: 0.098879002,\n",
       " 481: 0.2237,\n",
       " 482: -0.092825003,\n",
       " 483: -0.18926901,\n",
       " 484: 0.88391101,\n",
       " 485: -0.349953,\n",
       " 486: 0.056129999,\n",
       " 487: 0.48563701,\n",
       " 488: 0.23273601,\n",
       " 489: -0.540416,\n",
       " 490: -0.24455699,\n",
       " 491: 0.210683,\n",
       " 492: 0.059089001,\n",
       " 493: -0.51285398,\n",
       " 494: -0.080779999,\n",
       " 495: 0.114038,\n",
       " 496: 0.121438,\n",
       " 497: -0.187953,\n",
       " 498: 0.140093,\n",
       " 499: 0.042066,\n",
       " 500: 0.111179,\n",
       " 501: 0.911865,\n",
       " 502: -0.103896,\n",
       " 503: -0.050174002,\n",
       " 504: 0.463498,\n",
       " 505: 0.53728801,\n",
       " 506: 0.064563997,\n",
       " 507: 0.91207498,\n",
       " 508: 0.63691998,\n",
       " 509: -0.148498,\n",
       " 510: -0.011893,\n",
       " 511: -0.086809002,\n",
       " 512: 0.25254101,\n",
       " 513: -0.216534,\n",
       " 514: -0.083806999,\n",
       " 515: 0.069761001,\n",
       " 516: 0.26986,\n",
       " 517: -0.160542,\n",
       " 518: -0.026272001,\n",
       " 519: 0.15245301,\n",
       " 520: 0.473019,\n",
       " 521: 0.074653,\n",
       " 522: 0.057535999,\n",
       " 523: 0.0055359998,\n",
       " 524: 0.21799099,\n",
       " 525: 0.046466999,\n",
       " 526: -0.20648099,\n",
       " 527: 0.75293398,\n",
       " 528: 0.191084,\n",
       " 529: -0.519117,\n",
       " 530: 0.076277003,\n",
       " 531: -0.66232002,\n",
       " 532: 0.131412,\n",
       " 533: -0.187397,\n",
       " 534: -0.128473,\n",
       " 535: -0.56984401,\n",
       " 536: -0.349709,\n",
       " 537: -0.45932299,\n",
       " 538: 0.203252}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [] \n",
    "sparse_features = defaultdict(dict)\n",
    "propositions = []        \n",
    "columns = ['FORM', 'LEMMA', 'GPOS', 'MORF', 'DTREE', 'FUNC', 'CTREE', 'PRED']\n",
    "bounds_mapper = defaultdict(dict)\n",
    "for idx, propid in d['P'].items():\n",
    "    lb = 0 \n",
    "    for col in columns:\n",
    "        base_col = columns_mapper[col]\n",
    "        word = d[col][idx] \n",
    "        if not 'lb' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['lb'] = lb \n",
    "        if base_col in ('FORM', 'LEMMA', 'PRED'):\n",
    "            sz = embeddings_size\n",
    "            token = tokenize(word)\n",
    "            values = list(word2vec[token])\n",
    "                \n",
    "            sparse_features[idx].update({\n",
    "                i + lb: val\n",
    "                for i, val in enumerate(values)\n",
    "            })\n",
    "        elif categorical in lexicons[base_col]:\n",
    "            idx1 = lexicons[base_col][categorical]\n",
    "            sparse_features[idx][lb + idx1]=1 \n",
    "            sz = dimension_mapper[col] \n",
    "        else:\n",
    "            # nan set to zero\n",
    "            sparse_features[idx][lb]=1 \n",
    "            sz = dimension_mapper[col]           \n",
    "        lb += sz\n",
    "        if not 'ub' in bounds_mapper[col]:\n",
    "            bounds_mapper[col]['ub'] = lb \n",
    "\n",
    "    args.append(lexicons['ARG'][d['ARG'][idx]]) \n",
    "    propositions.append( propid )\n",
    "\n",
    "        \n",
    "sparse_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Scale mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -0.41410000000000002,\n",
       " 1: -0.4829,\n",
       " 2: 0.043400000000000001,\n",
       " 3: -0.45650000000000002,\n",
       " 4: 0.1202,\n",
       " 5: 0.45839999999999997,\n",
       " 6: 0.035799999999999998,\n",
       " 7: 0.40610000000000002,\n",
       " 8: -0.34379999999999999,\n",
       " 9: 0.26929999999999998,\n",
       " 10: -0.13420000000000001,\n",
       " 11: 0.0562,\n",
       " 12: 0.3216,\n",
       " 13: 0.37890000000000001,\n",
       " 14: -0.055599999999999997,\n",
       " 15: 0.044499999999999998,\n",
       " 16: 0.02,\n",
       " 17: -0.50980000000000003,\n",
       " 18: -0.13619999999999999,\n",
       " 19: 0.3488,\n",
       " 20: 0.24279999999999999,\n",
       " 21: -0.39300000000000002,\n",
       " 22: -0.28570000000000001,\n",
       " 23: 0.26250000000000001,\n",
       " 24: 0.085099999999999995,\n",
       " 25: 0.33279999999999998,\n",
       " 26: 0.26869999999999999,\n",
       " 27: 0.32240000000000002,\n",
       " 28: 0.11899999999999999,\n",
       " 29: -0.0134,\n",
       " 30: 0.016,\n",
       " 31: 0.52170000000000005,\n",
       " 32: 0.1469,\n",
       " 33: 0.13639999999999999,\n",
       " 34: -0.0654,\n",
       " 35: -0.085599999999999996,\n",
       " 36: -0.111,\n",
       " 37: 0.0012999999999999999,\n",
       " 38: -0.38929999999999998,\n",
       " 39: 0.081000000000000003,\n",
       " 40: -0.36470000000000002,\n",
       " 41: -0.079399999999999998,\n",
       " 42: 0.033300000000000003,\n",
       " 43: 0.049500000000000002,\n",
       " 44: -0.015900000000000001,\n",
       " 45: 0.078600000000000003,\n",
       " 46: 0.15709999999999999,\n",
       " 47: 0.050799999999999998,\n",
       " 48: -0.1394,\n",
       " 49: -0.18129999999999999,\n",
       " 50: -0.1678,\n",
       " 51: -0.11459999999999999,\n",
       " 52: -0.40870000000000001,\n",
       " 53: -0.27589999999999998,\n",
       " 54: -0.19120000000000001,\n",
       " 55: 0.62309999999999999,\n",
       " 56: -0.0223,\n",
       " 57: -0.0155,\n",
       " 58: -0.2974,\n",
       " 59: 0.2737,\n",
       " 60: -0.31519999999999998,\n",
       " 61: 0.59819999999999995,\n",
       " 62: -0.2132,\n",
       " 63: -0.21870000000000001,\n",
       " 64: -0.015699999999999999,\n",
       " 65: -0.2848,\n",
       " 66: 0.28249999999999997,\n",
       " 67: -0.13489999999999999,\n",
       " 68: -0.046300000000000001,\n",
       " 69: 0.54269999999999996,\n",
       " 70: 0.065600000000000006,\n",
       " 71: 0.026800000000000001,\n",
       " 72: -0.035099999999999999,\n",
       " 73: -0.15160000000000001,\n",
       " 74: -0.108,\n",
       " 75: 0.094700000000000006,\n",
       " 76: -0.032500000000000001,\n",
       " 77: 0.19070000000000001,\n",
       " 78: 0.092799999999999994,\n",
       " 79: 0.30249999999999999,\n",
       " 80: 0.0195,\n",
       " 81: -0.12139999999999999,\n",
       " 82: -0.081299999999999997,\n",
       " 83: -0.052299999999999999,\n",
       " 84: -0.28960000000000002,\n",
       " 85: 0.094700000000000006,\n",
       " 86: -0.21970000000000001,\n",
       " 87: -0.1552,\n",
       " 88: 0.37659999999999999,\n",
       " 89: -0.51780000000000004,\n",
       " 90: 0.31309999999999999,\n",
       " 91: 0.21210000000000001,\n",
       " 92: 0.28970000000000001,\n",
       " 93: -0.28620000000000001,\n",
       " 94: 0.085000000000000006,\n",
       " 95: 0.073700000000000002,\n",
       " 96: -0.50490000000000002,\n",
       " 97: -0.17949999999999999,\n",
       " 98: 0.080000000000000002,\n",
       " 99: -0.4733,\n",
       " 100: -0.4587,\n",
       " 101: -0.49880000000000002,\n",
       " 102: 0.088099999999999998,\n",
       " 103: -0.48099999999999998,\n",
       " 104: 0.1202,\n",
       " 105: 0.35659999999999997,\n",
       " 106: 0.1197,\n",
       " 107: 0.35239999999999999,\n",
       " 108: -0.31019999999999998,\n",
       " 109: 0.2046,\n",
       " 110: -0.33850000000000002,\n",
       " 111: 0.0562,\n",
       " 112: 0.3216,\n",
       " 113: 0.44950000000000001,\n",
       " 114: -0.1583,\n",
       " 115: 0.056599999999999998,\n",
       " 116: 0.074499999999999997,\n",
       " 117: -0.71160000000000001,\n",
       " 118: -0.1094,\n",
       " 119: 0.45090000000000002,\n",
       " 120: 0.10879999999999999,\n",
       " 121: -0.40550000000000003,\n",
       " 122: -0.28570000000000001,\n",
       " 123: 0.26250000000000001,\n",
       " 124: 0.20999999999999999,\n",
       " 125: 0.3367,\n",
       " 126: 0.3291,\n",
       " 127: 0.1646,\n",
       " 128: -0.1201,\n",
       " 129: -0.0154,\n",
       " 130: 0.077700000000000005,\n",
       " 131: 0.52170000000000005,\n",
       " 132: -0.0195,\n",
       " 133: 0.0088999999999999999,\n",
       " 134: 0.0011000000000000001,\n",
       " 135: -0.049299999999999997,\n",
       " 136: -0.1192,\n",
       " 137: -0.011900000000000001,\n",
       " 138: -0.45150000000000001,\n",
       " 139: 0.081000000000000003,\n",
       " 140: -0.29470000000000002,\n",
       " 141: -0.16400000000000001,\n",
       " 142: 0.044200000000000003,\n",
       " 143: 0.1152,\n",
       " 144: -0.032800000000000003,\n",
       " 145: 0.12709999999999999,\n",
       " 146: 0.15709999999999999,\n",
       " 147: 0.055800000000000002,\n",
       " 148: -0.085199999999999998,\n",
       " 149: -0.216,\n",
       " 150: -0.1678,\n",
       " 151: -0.15429999999999999,\n",
       " 152: -0.3896,\n",
       " 153: -0.26390000000000002,\n",
       " 154: -0.20949999999999999,\n",
       " 155: 0.64990000000000003,\n",
       " 156: -0.0223,\n",
       " 157: -0.0155,\n",
       " 158: -0.38440000000000002,\n",
       " 159: 0.27750000000000002,\n",
       " 160: -0.31519999999999998,\n",
       " 161: 0.57920000000000005,\n",
       " 162: -0.27110000000000001,\n",
       " 163: -0.3306,\n",
       " 164: 0.1368,\n",
       " 165: -0.41839999999999999,\n",
       " 166: 0.21340000000000001,\n",
       " 167: -0.23599999999999999,\n",
       " 168: -0.089800000000000005,\n",
       " 169: 0.44890000000000002,\n",
       " 170: 0.065600000000000006,\n",
       " 171: 0.1227,\n",
       " 172: 0.058999999999999997,\n",
       " 173: -0.15160000000000001,\n",
       " 174: -0.25800000000000001,\n",
       " 175: 0.19270000000000001,\n",
       " 176: 0.035799999999999998,\n",
       " 177: 0.0086999999999999994,\n",
       " 178: -0.0061999999999999998,\n",
       " 179: 0.34699999999999998,\n",
       " 180: 0.10390000000000001,\n",
       " 181: -0.16689999999999999,\n",
       " 182: -0.156,\n",
       " 183: -0.016899999999999998,\n",
       " 184: -0.26550000000000001,\n",
       " 185: 0.35580000000000001,\n",
       " 186: -0.2833,\n",
       " 187: -0.21179999999999999,\n",
       " 188: 0.17399999999999999,\n",
       " 189: -0.55579999999999996,\n",
       " 190: 0.2414,\n",
       " 191: 0.28449999999999998,\n",
       " 192: 0.1822,\n",
       " 193: -0.24690000000000001,\n",
       " 194: -0.094600000000000004,\n",
       " 195: -0.032300000000000002,\n",
       " 196: -0.53700000000000003,\n",
       " 197: -0.1847,\n",
       " 198: 0.080000000000000002,\n",
       " 199: -0.45229999999999998,\n",
       " 200: 1,\n",
       " 225: 1,\n",
       " 250: 1,\n",
       " 341: 1,\n",
       " 390: 1,\n",
       " 439: -0.14419999999999999,\n",
       " 440: -0.042200000000000001,\n",
       " 441: -0.6099,\n",
       " 442: 0.25490000000000002,\n",
       " 443: 0.31819999999999998,\n",
       " 444: -0.28939999999999999,\n",
       " 445: 0.224,\n",
       " 446: -0.3377,\n",
       " 447: -0.032899999999999999,\n",
       " 448: -0.1055,\n",
       " 449: 0.4748,\n",
       " 450: 0.24779999999999999,\n",
       " 451: -0.19059999999999999,\n",
       " 452: 0.33589999999999998,\n",
       " 453: 0.26640000000000003,\n",
       " 454: -0.060400000000000002,\n",
       " 455: 0.12770000000000001,\n",
       " 456: -0.7641,\n",
       " 457: 0.45340000000000003,\n",
       " 458: -0.30980000000000002,\n",
       " 459: 0.025499999999999998,\n",
       " 460: -0.020799999999999999,\n",
       " 461: -0.0304,\n",
       " 462: 0.43140000000000001,\n",
       " 463: -0.31680000000000003,\n",
       " 464: 0.1363,\n",
       " 465: 0.62790000000000001,\n",
       " 466: 0.218,\n",
       " 467: 0.0252,\n",
       " 468: 0.2238,\n",
       " 469: 0.1386,\n",
       " 470: -0.098400000000000001,\n",
       " 471: 0.54220000000000002,\n",
       " 472: -0.64270000000000005,\n",
       " 473: -0.52559999999999996,\n",
       " 474: -0.059400000000000001,\n",
       " 475: 0.0074999999999999997,\n",
       " 476: -0.46920000000000001,\n",
       " 477: -0.34870000000000001,\n",
       " 478: -0.26169999999999999,\n",
       " 479: -0.41499999999999998,\n",
       " 480: -0.31080000000000002,\n",
       " 481: 0.36349999999999999,\n",
       " 482: 0.39829999999999999,\n",
       " 483: -0.62139999999999995,\n",
       " 484: 0.61470000000000002,\n",
       " 485: -0.32640000000000002,\n",
       " 486: 0.067900000000000002,\n",
       " 487: 0.54169999999999996,\n",
       " 488: 0.32500000000000001,\n",
       " 489: -0.69330000000000003,\n",
       " 490: 0.029700000000000001,\n",
       " 491: 0.18160000000000001,\n",
       " 492: -0.40789999999999998,\n",
       " 493: -0.39510000000000001,\n",
       " 494: 0.40739999999999998,\n",
       " 495: 0.1701,\n",
       " 496: 0.067400000000000002,\n",
       " 497: -0.2326,\n",
       " 498: 0.41010000000000002,\n",
       " 499: -0.20200000000000001,\n",
       " 500: 0.27379999999999999,\n",
       " 501: 0.47170000000000001,\n",
       " 502: 0.18029999999999999,\n",
       " 503: -0.090700000000000003,\n",
       " 504: -0.17899999999999999,\n",
       " 505: 0.2361,\n",
       " 506: 0.3075,\n",
       " 507: -0.12509999999999999,\n",
       " 508: 0.66339999999999999,\n",
       " 509: -0.22370000000000001,\n",
       " 510: 0.082500000000000004,\n",
       " 511: -0.33789999999999998,\n",
       " 512: 0.76180000000000003,\n",
       " 513: -0.1232,\n",
       " 514: -0.16819999999999999,\n",
       " 515: 0.43659999999999999,\n",
       " 516: -0.12479999999999999,\n",
       " 517: 0.33139999999999997,\n",
       " 518: 0.2109,\n",
       " 519: -0.0177,\n",
       " 520: 0.66839999999999999,\n",
       " 521: 0.1638,\n",
       " 522: 0.1542,\n",
       " 523: -0.1106,\n",
       " 524: -0.35749999999999998,\n",
       " 525: 0.19620000000000001,\n",
       " 526: -0.11650000000000001,\n",
       " 527: -0.039,\n",
       " 528: 0.18140000000000001,\n",
       " 529: -0.58009999999999995,\n",
       " 530: -0.076499999999999999,\n",
       " 531: -1.0,\n",
       " 532: 0.00040000000000000002,\n",
       " 533: -0.31219999999999998,\n",
       " 534: 0.092299999999999993,\n",
       " 535: -0.38350000000000001,\n",
       " 536: -0.69469999999999998,\n",
       " 537: -0.035700000000000003,\n",
       " 538: 0.13420000000000001}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_d = defaultdict(list)\n",
    "for col in columns:\n",
    "#     if is_dense(col, columns_mapper):\n",
    "    if col in ('FORM', 'LEMMA', 'PRED'):\n",
    "        lb = bounds_mapper[col]['lb']\n",
    "        ub = bounds_mapper[col]['ub']                \n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                series_d[x].append(sparse_features[idx][x])\n",
    "\n",
    "        # standardize\n",
    "        for f in range(lb, ub):\n",
    "            n = len(series_d[f])\n",
    "            mu_x = sum(series_d[f]) / n\n",
    "            ssq_x = sum([(x - mu_x)*(x - mu_x) for x in series_d[f]])\n",
    "            std_x = math.sqrt(ssq_x/ (n-1))\n",
    "            \n",
    "            series_d[f] = [(x - mu_x)/ std_x for x in series_d[f]]            \n",
    "        # rescale\n",
    "        for f in range(lb, ub):\n",
    "            min_x = min(series_d[f])\n",
    "            max_x = max(series_d[f])\n",
    "            series_d[f] = [\n",
    "                (2*x - min_x - max_x)/ (max_x - min_x)\n",
    "                for x in series_d[f]\n",
    "            ]            \n",
    "        # move rescaled and standardized back to sparse_features\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):\n",
    "                sparse_features[idx][x] = series_d[x][idx]\n",
    "\n",
    "        # round values\n",
    "        for idx in sparse_features:    \n",
    "            for x in range(lb, ub):                \n",
    "                sparse_features[idx][x] = round(sparse_features[idx][x], 4)\n",
    "            \n",
    "                \n",
    "        \n",
    "sparse_features[0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Saved mixed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ds_type in ('train', 'test', 'valid'):    \n",
    "    if ds_type in ('train'):                \n",
    "      lb = 0\n",
    "      ub = DATASET_TRAIN_SIZE \n",
    "\n",
    "    if ds_type in ('valid'):                \n",
    "      lb = DATASET_TRAIN_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE\n",
    "\n",
    "    if ds_type in ('test'):                \n",
    "      lb = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE \n",
    "      ub = DATASET_TRAIN_SIZE + DATASET_VALID_SIZE + DATASET_TEST_SIZE\n",
    "        \n",
    "    # saves the processed data\n",
    "    svm_path = '{:}/{:}/{:}.svm'.format(SVM_DIR, 'wan', ds_type)\n",
    "    with open(svm_path, mode='w') as f:\n",
    "        for idx in sparse_features:\n",
    "            p = propositions[idx]\n",
    "            if p > lb and p < ub + 1:\n",
    "                target = '{:} '.format(int(targets_mapper[targets[idx]]))\n",
    "                features = ' '.join([ '{:}:{:}'.format(key, val) \n",
    "                     for key, val in sparse_features[idx].items()])\n",
    "                ex = '{:}{:}\\n'.format(target, features)\n",
    "                f.write(ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
