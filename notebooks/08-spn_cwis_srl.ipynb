{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../models/')\n",
    "sys.path.insert(0,'../datasets/')\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import re\n",
    "\n",
    "from models import PropbankEncoder\n",
    "import config\n",
    "\n",
    "INPUT_DIR = '../datasets/binaries/'\n",
    "PROPBANK_GLO50_PATH = '{:}deep_glo50.pickle'.format(INPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Structured Predictions Network CWIS SRL (BR)</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>In this notebook we solve the semantic role labeling task using structured predictions networks.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Builds a \"human friendly\" version of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>P</th>\n",
       "      <th>FORM</th>\n",
       "      <th>ARG</th>\n",
       "      <th>T</th>\n",
       "      <th>CHUNK_ID</th>\n",
       "      <th>CHUNK_START</th>\n",
       "      <th>CHUNK_FINISH</th>\n",
       "      <th>CHUNK_LEN</th>\n",
       "      <th>CHUNK_CANDIDATE_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bras√≠lia</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Pesquisa_Datafolha</td>\n",
       "      <td>(A0*</td>\n",
       "      <td>A0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>publicada</td>\n",
       "      <td>*</td>\n",
       "      <td>A0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>hoje</td>\n",
       "      <td>*)</td>\n",
       "      <td>A0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>revela</td>\n",
       "      <td>(V*)</td>\n",
       "      <td>V</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>um</td>\n",
       "      <td>(A1*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>dado</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>supreendente</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>:</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>recusando</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>uma</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>postura</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>radical</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>esmagadora</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>maioria</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>(</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>%</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>)</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>de</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>os</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>eleitores</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>quer</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>o</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>PT</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>participando</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>de</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>o</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>Governo</td>\n",
       "      <td>*</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>Fernando_Henrique_Cardoso</td>\n",
       "      <td>*)</td>\n",
       "      <td>A1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  P                       FORM   ARG   T  CHUNK_ID  CHUNK_START  \\\n",
       "INDEX                                                                      \n",
       "0       1  1                   Bras√≠lia     *   *         1            0   \n",
       "1       2  1         Pesquisa_Datafolha  (A0*  A0         2            1   \n",
       "2       3  1                  publicada     *  A0         2            1   \n",
       "3       4  1                       hoje    *)  A0         2            1   \n",
       "4       5  1                     revela  (V*)   V         3            4   \n",
       "5       6  1                         um  (A1*  A1         4            5   \n",
       "6       7  1                       dado     *  A1         4            5   \n",
       "7       8  1               supreendente     *  A1         4            5   \n",
       "8       9  1                          :     *  A1         4            5   \n",
       "9      10  1                  recusando     *  A1         4            5   \n",
       "10     11  1                        uma     *  A1         4            5   \n",
       "11     12  1                    postura     *  A1         4            5   \n",
       "12     13  1                    radical     *  A1         4            5   \n",
       "13     14  1                          ,     *  A1         4            5   \n",
       "14     15  1                          a     *  A1         4            5   \n",
       "15     16  1                 esmagadora     *  A1         4            5   \n",
       "16     17  1                    maioria     *  A1         4            5   \n",
       "17     18  1                          (     *  A1         4            5   \n",
       "18     19  1                         77     *  A1         4            5   \n",
       "19     20  1                          %     *  A1         4            5   \n",
       "20     21  1                          )     *  A1         4            5   \n",
       "21     22  1                         de     *  A1         4            5   \n",
       "22     23  1                         os     *  A1         4            5   \n",
       "23     24  1                  eleitores     *  A1         4            5   \n",
       "24     25  1                       quer     *  A1         4            5   \n",
       "25     26  1                          o     *  A1         4            5   \n",
       "26     27  1                         PT     *  A1         4            5   \n",
       "27     28  1               participando     *  A1         4            5   \n",
       "28     29  1                         de     *  A1         4            5   \n",
       "29     30  1                          o     *  A1         4            5   \n",
       "30     31  1                    Governo     *  A1         4            5   \n",
       "31     32  1  Fernando_Henrique_Cardoso    *)  A1         4            5   \n",
       "32     33  1                          .     *   *         5           32   \n",
       "\n",
       "       CHUNK_FINISH  CHUNK_LEN  CHUNK_CANDIDATE_ID  \n",
       "INDEX                                               \n",
       "0                 1          1                   0  \n",
       "1                 4          3                  35  \n",
       "2                 4          3                  35  \n",
       "3                 4          3                  35  \n",
       "4                 5          1                 126  \n",
       "5                32         27                 181  \n",
       "6                32         27                 181  \n",
       "7                32         27                 181  \n",
       "8                32         27                 181  \n",
       "9                32         27                 181  \n",
       "10               32         27                 181  \n",
       "11               32         27                 181  \n",
       "12               32         27                 181  \n",
       "13               32         27                 181  \n",
       "14               32         27                 181  \n",
       "15               32         27                 181  \n",
       "16               32         27                 181  \n",
       "17               32         27                 181  \n",
       "18               32         27                 181  \n",
       "19               32         27                 181  \n",
       "20               32         27                 181  \n",
       "21               32         27                 181  \n",
       "22               32         27                 181  \n",
       "23               32         27                 181  \n",
       "24               32         27                 181  \n",
       "25               32         27                 181  \n",
       "26               32         27                 181  \n",
       "27               32         27                 181  \n",
       "28               32         27                 181  \n",
       "29               32         27                 181  \n",
       "30               32         27                 181  \n",
       "31               32         27                 181  \n",
       "32               33          1                 560  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfgs = pd.read_csv('../datasets/csvs/gs.csv', index_col=0, sep=',', encoding='utf-8')\n",
    "column_files = [\n",
    "    '../datasets/csvs/column_chunks/chunks.csv',\n",
    "    '../datasets/csvs/column_predmarker/predicate_marker.csv',\n",
    "    '../datasets/csvs/column_shifts_ctx_p/form.csv',\n",
    "    '../datasets/csvs/column_shifts_ctx_p/gpos.csv',\n",
    "    '../datasets/csvs/column_shifts_ctx_p/lemma.csv',\n",
    "    '../datasets/csvs/column_t/t.csv',\n",
    "    '../datasets/csvs/column_iob/iob.csv'\n",
    "]\n",
    "\n",
    "for col_f in column_files:\n",
    "    _df = pd.read_csv(col_f, index_col=0, encoding='utf-8')\n",
    "    dfgs = pd.concat((dfgs, _df), axis=1)\n",
    "\n",
    "DISPLAY_COLUMNS = ['ID', 'P', 'FORM', 'ARG', 'T', \n",
    "                   'CHUNK_ID', 'CHUNK_START', 'CHUNK_FINISH', 'CHUNK_LEN', 'CHUNK_CANDIDATE_ID']            \n",
    "dfgs[DISPLAY_COLUMNS].head(33)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gets encodings\n",
    "\n",
    "Propbank Encoder holds an indexed version of propbank dataset an answers to FOUR different dataformats: \n",
    "* CAT: this is the raw categorical data.\n",
    "* EMB: tokens are embedding using GloVe embeddings.\n",
    "* HOT: onehot encoding of the words and tokens.\n",
    "* IDX: dense indexed representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ENCODER\n",
    "propbank_encoder = PropbankEncoder.recover(PROPBANK_GLO50_PATH)\n",
    "db = propbank_encoder.db\n",
    "lex2idx = propbank_encoder.lex2idx\n",
    "idx2lex = propbank_encoder.idx2lex\n",
    "\n",
    "# FOR TEXTUAL DATA ONLY\n",
    "\n",
    "lex2tok = propbank_encoder.lex2tok\n",
    "tok2idx = propbank_encoder.tok2idx\n",
    "embeddings = propbank_encoder.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes\t 44 \n",
      " records\t 141730\n"
     ]
    }
   ],
   "source": [
    "print('attributes\\t',\n",
    "       len(db),\n",
    "      '\\n',             \n",
    "      'records\\t',\n",
    "       len(db['ARG'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_type(ds_type, db):\n",
    "    '''Filters only records from train dataset\n",
    "    '''\n",
    "    ds_types = ('train', 'test', 'valid')\n",
    "    if ds_type not in ds_types:\n",
    "        _msg = 'ds_type must be in {:} got {:}'\n",
    "        _msg = _msg.format(ds_types, ds_type)\n",
    "        raise ValueError(_msg)\n",
    "    elif ds_type in ('train',):\n",
    "        lb = 0 \n",
    "        ub = config.DATASET_TRAIN_SIZE\n",
    "    elif ds_type in ('test',):        \n",
    "        lb = config.DATASET_TRAIN_SIZE\n",
    "        ub = lb + config.DATASET_VALID_SIZE         \n",
    "    elif ds_type in ('valid',):                \n",
    "        lb = config.DATASET_TRAIN_SIZE + config.DATASET_VALID_SIZE\n",
    "        ub = lb + config.DATASET_TEST_SIZE         \n",
    "\n",
    "    sel_keys_ = {key_ for key_, prop_ in db['P'].items() if prop_ > lb and prop_ <= ub}\n",
    "\n",
    "    return {\n",
    "                attr_:{ idx_: i_\n",
    "                        for idx_, i_ in dict_.items() if idx_ in sel_keys_\n",
    "                      }        \n",
    "                for attr_, dict_  in db.items()\n",
    "            }\n",
    "\n",
    "def reindex_prop(db):\n",
    "    '''Reindex db by propositions creating a nested dict in which the\n",
    "        outer key is the proposition\n",
    "        \n",
    "        Converts the inner dicts into numpy arrays\n",
    "    '''\n",
    "    \n",
    "    triple_list = []\n",
    "    prev_prop = -1\n",
    "    for idx, prop in db['P'].items():\n",
    "        if prev_prop != prop:\n",
    "            if idx > 0:\n",
    "                ub = idx-1\n",
    "                triple_list.append((lb, ub, prev_prop))\n",
    "            lb = idx\n",
    "        prev_prop = prop\n",
    "    triple_list.append((lb, ub, prev_prop))\n",
    "            \n",
    "\n",
    "        \n",
    "    prop_set = set(db['P'].values())\n",
    "    return { prop_:\n",
    "                    {\n",
    "                        attr_:{ idx_: dict_[idx_]\n",
    "                                for idx_ in range(lb_, ub_ + 1, 1)\n",
    "                          }        \n",
    "                        for attr_, dict_ in db.items() if attr_ not in ('P',)\n",
    "                    }\n",
    "             for lb_, ub_, prop_ in  triple_list\n",
    "            }, {prop_: ub_ - lb_ + 1 for lb_, ub_, prop_ in  triple_list}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes\t 44 \n",
      " records\t 123846\n"
     ]
    }
   ],
   "source": [
    "traindb  = filter_type('train', db)\n",
    "print('attributes\\t',\n",
    "       len(traindb),\n",
    "      '\\n',             \n",
    "      'records\\t',\n",
    "       len(traindb['ARG'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes\t 44 \n",
      " records\t 123837\n"
     ]
    }
   ],
   "source": [
    "traindb1, proplen_dict = reindex_prop(traindb)\n",
    "print('attributes\\t',\n",
    "       len(traindb1[1]) + 1,\n",
    "      '\\n',             \n",
    "      'records\\t',\n",
    "       sum([len(d['ARG']) for p, d in traindb1.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(db1, proplen_dict, propid):\n",
    "    '''Generate inputs\n",
    "    '''\n",
    "    propdb = db1[propid] # nested dict of columns and idx value\n",
    "    proplen = proplen_dict[propid]\n",
    "    if 'CHUNK_SPACE' not in propdb:\n",
    "        propdb['CHUNK_SPACE'] = generate_chunk_space(proplen)\n",
    "\n",
    "    word  = list(propdb['FORM'].values())\n",
    "    pos   = list(propdb['GPOS'].values())\n",
    "    chunk_type  = list(propdb['T'].values())\n",
    "    chunk_start, chunk_finish = propdb['CHUNK_SPACE']\n",
    "    \n",
    "    return word, pos, chunk_type, chunk_start, chunk_finish\n",
    "            \n",
    "def generate_chunk_space(n):\n",
    "    '''Generates all possible spaces for chunks\n",
    "    '''\n",
    "    start_list = []\n",
    "    end_list = []\n",
    "    for i in range(n):\n",
    "        for j in range(i,n,1):\n",
    "            start_list.append(i)\n",
    "            end_list.append(j+1)\n",
    "    return  start_list, end_list\n",
    "\n",
    "def get_outputs(db1, t2idx, propid):\n",
    "    ''' Generate outputs\n",
    "    '''\n",
    "    propdb = db1[propid] # nested dict of columns and idx value\n",
    "    if 'OUTPUTS' not in propdb: \n",
    "        chunk_list = zip(propdb['CHUNK_CANDIDATE_ID'].values(), \n",
    "                         propdb['T'].values())\n",
    "        chunk_list = list(set(chunk_list))\n",
    "\n",
    "        n_targets = len(t2idx)        \n",
    "        propdb['OUTPUTS'] = [ i * n_targets + j for i, j in chunk_list]\n",
    "\n",
    "    return propdb['OUTPUTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.69 ¬µs ¬± 94.6 ns per loop (mean ¬± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "propid = 2\n",
    "word, gpos, chunk_type, chunk_start, chunk_finish = get_inputs(traindb1, proplen_dict, propid)\n",
    "y = get_outputs(traindb1, lex2idx['T'], propid)\n",
    "# worst proposition 1120 size 92!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (2, 21), (4, 18), (12, 30), (25, 26)]\n"
     ]
    }
   ],
   "source": [
    "propid = 1\n",
    "word, gpos, chunk_type, chunk_start, chunk_finish = get_inputs(traindb1, proplen_dict, propid)\n",
    "y = get_outputs(traindb1, lex2idx['T'], propid)\n",
    "\n",
    "_start  = chunk_start * len(lex2idx['T'])\n",
    "_finish = chunk_finish * len(lex2idx['T'])\n",
    "print([(_start[y_], _finish[y_]) for y_ in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import struct_perc.colored_weighted_interval_scheduling as cwis\n",
    "import struct_perc.weighted_interval_scheduling as wis\n",
    "import struct_perc.utils as spu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(lex2idx['FORM']) + 1\n",
    "embed_size = 50\n",
    "\n",
    "n_pos = len(lex2idx['GPOS'])\n",
    "# n_type = len(lex2idx['T'])\n",
    "n_classes  = len(lex2idx['T'])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# word index and gpos \n",
    "tf_words = tf.placeholder(tf.int32, shape=(None,1))\n",
    "tf_pos = tf.placeholder(tf.int32, shape=(None,1))\n",
    "# t_x_type = tf.placeholder(tf.int32, shape=(None,1))\n",
    "\n",
    "# √≠ndices de inicio de intervalo\n",
    "tf_s = tf.placeholder(tf.int32, shape=(None,1))\n",
    "# √≠ndices de fim de intervalo\n",
    "tf_f = tf.placeholder(tf.int32, shape=(None,1))\n",
    "\n",
    "# replicamos os indicies de inicio e fim para cada classe de chunk possivel\n",
    "tf_sc = tf.reshape(\n",
    "      tf.tile(tf_s,  [1, n_classes]), [-1,1])\n",
    "tf_fc = tf.reshape(\n",
    "      tf.tile(tf_f,  [1, n_classes]), [-1,1])\n",
    "\n",
    "# n_features = (embed_size + n_pos + n_type)\n",
    "n_features = (embed_size + n_pos)\n",
    "# hidden_features = 300\n",
    "W_shape = (n_features, n_classes)\n",
    "EMBS = tf.constant(embeddings)\n",
    "# tf_token = tf.Variable(initial_value=None, expected_shape=(embed_size,), dtype=tf.float32, trainable=False)\n",
    "\n",
    "# geramos os paramteros do modelo\n",
    "with tf.variable_scope(\"model\"):\n",
    "    W = tf.Variable(\n",
    "        tf.random_normal(W_shape, 0, 1/np.sqrt(n_features * n_classes), name='W')\n",
    "    )\n",
    "    b = tf.Variable(\n",
    "        tf.random_normal((n_classes,1), 0, 1/np.sqrt(n_classes), name='b')\n",
    "    )\n",
    "    \n",
    "\n",
    "# tf_token = tf.nn.embedding_lookup(tf_embeddings, id) \n",
    "# Recuperamos os embeddings de cada palavra\n",
    "tf_word_features = tf.gather_nd(EMBS, tf_words)\n",
    "\n",
    "tf_pos_flat = tf.reshape(tf_pos, [-1])\n",
    "tf_pos_features = tf.one_hot(tf_pos_flat, depth=n_pos)\n",
    "\n",
    "# t_x_type_flat = tf.reshape(t_x_type,[-1])\n",
    "# t_type_features = tf.one_hot(t_x_type_flat, depth=n_type)\n",
    "\n",
    "# t_tok_features = tf.concat((t_word_features,t_pos_features,t_type_features),axis=1)\n",
    "tf_tok_features = tf.concat((tf_word_features,tf_pos_features),axis=1)\n",
    "\n",
    "# a partir das features do intervalo computamos o score\n",
    "tf_scores = tf.matmul(tf_tok_features, W) + b\n",
    "\n",
    "tf_pred = tf.argmax(tf_scores, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Tensorflow test session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "flat indices[10, :] = [12812] does not index into param (shape: [12038,50]).\n\t [[Node: GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Const, _arg_Placeholder_0_0)]]\n\nCaused by op 'GatherNd', defined at:\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-befffd5df2b5>\", line 45, in <module>\n    tf_word_features = tf.gather_nd(Embs, tf_words)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1971, in gather_nd\n    \"GatherNd\", params=params, indices=indices, name=name)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): flat indices[10, :] = [12812] does not index into param (shape: [12038,50]).\n\t [[Node: GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Const, _arg_Placeholder_0_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: flat indices[10, :] = [12812] does not index into param (shape: [12038,50]).\n\t [[Node: GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Const, _arg_Placeholder_0_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-38389dacdb4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     a = sess.run(tf_tok_features, feed_dict={\n\u001b[1;32m      8\u001b[0m         \u001b[0mtf_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtf_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     })\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: flat indices[10, :] = [12812] does not index into param (shape: [12038,50]).\n\t [[Node: GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Const, _arg_Placeholder_0_0)]]\n\nCaused by op 'GatherNd', defined at:\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-befffd5df2b5>\", line 45, in <module>\n    tf_word_features = tf.gather_nd(Embs, tf_words)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1971, in gather_nd\n    \"GatherNd\", params=params, indices=indices, name=name)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/Users/Varela/anaconda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): flat indices[10, :] = [12812] does not index into param (shape: [12038,50]).\n\t [[Node: GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Const, _arg_Placeholder_0_0)]]\n"
     ]
    }
   ],
   "source": [
    "propid  = 1\n",
    "words, gpos, chunk_type, chunk_start, chunk_finish = get_inputs(traindb1, proplen_dict, propid)\n",
    "y = get_outputs(traindb1, lex2idx['T'], propid)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    a = sess.run(tf_tok_features, feed_dict={\n",
    "        tf_words:np.transpose(np.array([words])),\n",
    "        tf_pos:np.transpose(np.array([gpos])),\n",
    "    })\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
