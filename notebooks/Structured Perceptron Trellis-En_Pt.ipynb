{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Varela/.venv/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  \n",
      "/Users/Varela/.venv/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../models/')\n",
    "sys.path.insert(0,'../datasets/')\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from utils.info import get_db_bounds\n",
    "from datasets import propbankbr_arg2se, propbankbr_iob2arg\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tqdm\n",
    "from models import PropbankEncoder\n",
    "import config \n",
    "\n",
    "LANG = 'en'\n",
    "# INPUT_DIR = '../datasets/binaries/1.0/'\n",
    "# PROPBANK_WAN50_PATH = '{:}wan50/deep_wan50.pickle'.format(INPUT_DIR)\n",
    "# PEARL_SRLEVAL_PATH = '../srlconll04/srl-eval.pl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LANG == 'pt':\n",
    "    LANG_DIR = 'pt/1.0/'\n",
    "    LM = 'wan50'\n",
    "    PEARL_SRLEVAL_PATH = '../srlconll04/srl-eval.pl'\n",
    "else:\n",
    "    LANG_DIR = 'en/'\n",
    "    LM = 'glo50'\n",
    "    PEARL_SRLEVAL_PATH = '../srlconll05/bin/srl-eval.pl'\n",
    "\n",
    "GS_DIR = '../datasets/csvs/{:}'.format(LANG_DIR)\n",
    "LM_DIR = '{:}/'.format(LM)\n",
    "INPUT_DIR = '../datasets/binaries/{:}'.format(LANG_DIR)\n",
    "PROPBANK_PATH = '{:}{:}deep_{:}.pickle'.format(INPUT_DIR, LM_DIR, LM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPN Chunker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma mente insana realiza um experimento *lúcido* com o dataset de chunking da conll e seu script de avaliação :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/numpy/lib/arraysetops.py:518: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>P</th>\n",
       "      <th>FORM</th>\n",
       "      <th>GPOS</th>\n",
       "      <th>MARKER</th>\n",
       "      <th>ARG</th>\n",
       "      <th>T</th>\n",
       "      <th>IOB</th>\n",
       "      <th>CHUNK_ID</th>\n",
       "      <th>CHUNK_START</th>\n",
       "      <th>CHUNK_FINISH</th>\n",
       "      <th>CHUNK_LEN</th>\n",
       "      <th>CHUNK_CANDIDATE_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>an</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Oct.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>``</td>\n",
       "      <td>''</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Misanthrope</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>''</td>\n",
       "      <td>''</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>at</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>'s</td>\n",
       "      <td>POS</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodman</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>Theatre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>``</td>\n",
       "      <td>''</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Revitalized</td>\n",
       "      <td>VBN</td>\n",
       "      <td>1</td>\n",
       "      <td>(V*)</td>\n",
       "      <td>V</td>\n",
       "      <td>B-V</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>Classics</td>\n",
       "      <td>NNS</td>\n",
       "      <td>1</td>\n",
       "      <td>(A1*)</td>\n",
       "      <td>A1</td>\n",
       "      <td>B-A1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>Take</td>\n",
       "      <td>VBP</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Stage</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Windy</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>City</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>''</td>\n",
       "      <td>''</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Leisure</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>CC</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>played</td>\n",
       "      <td>VBN</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>by</td>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Kim</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>Cattrall</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>was</td>\n",
       "      <td>AUX</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>mistakenly</td>\n",
       "      <td>RB</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>attributed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>Christina</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>Haag</td>\n",
       "      <td>NNP</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>In</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>an</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Oct.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>``</td>\n",
       "      <td>''</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Misanthrope</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>''</td>\n",
       "      <td>''</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>at</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>'s</td>\n",
       "      <td>POS</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Goodman</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Theatre</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>``</td>\n",
       "      <td>''</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  P         FORM  GPOS  MARKER    ARG   T   IOB  CHUNK_ID  \\\n",
       "INDEX                                                                \n",
       "0       1  1           In    IN       0      *   *     O         1   \n",
       "1       2  1           an    DT       0      *   *     O         1   \n",
       "2       3  1         Oct.   NNP       0      *   *     O         1   \n",
       "3       4  1           19    CD       0      *   *     O         1   \n",
       "4       5  1       review    NN       0      *   *     O         1   \n",
       "5       6  1           of    IN       0      *   *     O         1   \n",
       "6       7  1           ``    ''       0      *   *     O         1   \n",
       "7       8  1          The    DT       0      *   *     O         1   \n",
       "8       9  1  Misanthrope    NN       0      *   *     O         1   \n",
       "9      10  1           ''    ''       0      *   *     O         1   \n",
       "10     11  1           at    IN       0      *   *     O         1   \n",
       "11     12  1      Chicago   NNP       0      *   *     O         1   \n",
       "12     13  1           's   POS       0      *   *     O         1   \n",
       "13     14  1      Goodman   NNP       0      *   *     O         1   \n",
       "14     15  1      Theatre   NNP       0      *   *     O         1   \n",
       "15     16  1            (     (       0      *   *     O         1   \n",
       "16     17  1           ``    ''       0      *   *     O         1   \n",
       "17     18  1  Revitalized   VBN       1   (V*)   V   B-V         2   \n",
       "18     19  1     Classics   NNS       1  (A1*)  A1  B-A1         3   \n",
       "19     20  1         Take   VBP       1      *   *     O         4   \n",
       "20     21  1          the    DT       1      *   *     O         4   \n",
       "21     22  1        Stage    NN       1      *   *     O         4   \n",
       "22     23  1           in    IN       1      *   *     O         4   \n",
       "23     24  1        Windy   NNP       1      *   *     O         4   \n",
       "24     25  1         City   NNP       1      *   *     O         4   \n",
       "25     26  1            ,     ,       1      *   *     O         4   \n",
       "26     27  1           ''    ''       1      *   *     O         4   \n",
       "27     28  1      Leisure   NNP       1      *   *     O         4   \n",
       "28     29  1            &    CC       1      *   *     O         4   \n",
       "29     30  1         Arts  NNPS       1      *   *     O         4   \n",
       "...    .. ..          ...   ...     ...    ...  ..   ...       ...   \n",
       "36     37  1            ,     ,       1      *   *     O         4   \n",
       "37     38  1       played   VBN       1      *   *     O         4   \n",
       "38     39  1           by    IN       1      *   *     O         4   \n",
       "39     40  1          Kim   NNP       1      *   *     O         4   \n",
       "40     41  1     Cattrall   NNP       1      *   *     O         4   \n",
       "41     42  1            ,     ,       1      *   *     O         4   \n",
       "42     43  1          was   AUX       1      *   *     O         4   \n",
       "43     44  1   mistakenly    RB       1      *   *     O         4   \n",
       "44     45  1   attributed   VBN       1      *   *     O         4   \n",
       "45     46  1           to    TO       1      *   *     O         4   \n",
       "46     47  1    Christina   NNP       1      *   *     O         4   \n",
       "47     48  1         Haag   NNP       1      *   *     O         4   \n",
       "48     49  1            .     .       1      *   *     O         4   \n",
       "49      1  2           In    IN       0      *   *     O         5   \n",
       "50      2  2           an    DT       0      *   *     O         5   \n",
       "51      3  2         Oct.   NNP       0      *   *     O         5   \n",
       "52      4  2           19    CD       0      *   *     O         5   \n",
       "53      5  2       review    NN       0      *   *     O         5   \n",
       "54      6  2           of    IN       0      *   *     O         5   \n",
       "55      7  2           ``    ''       0      *   *     O         5   \n",
       "56      8  2          The    DT       0      *   *     O         5   \n",
       "57      9  2  Misanthrope    NN       0      *   *     O         5   \n",
       "58     10  2           ''    ''       0      *   *     O         5   \n",
       "59     11  2           at    IN       0      *   *     O         5   \n",
       "60     12  2      Chicago   NNP       0      *   *     O         5   \n",
       "61     13  2           's   POS       0      *   *     O         5   \n",
       "62     14  2      Goodman   NNP       0      *   *     O         5   \n",
       "63     15  2      Theatre   NNP       0      *   *     O         5   \n",
       "64     16  2            (     (       0      *   *     O         5   \n",
       "65     17  2           ``    ''       0      *   *     O         5   \n",
       "\n",
       "       CHUNK_START  CHUNK_FINISH  CHUNK_LEN  CHUNK_CANDIDATE_ID  \n",
       "INDEX                                                            \n",
       "0                0            17         17                  16  \n",
       "1                0            17         17                  16  \n",
       "2                0            17         17                  16  \n",
       "3                0            17         17                  16  \n",
       "4                0            17         17                  16  \n",
       "5                0            17         17                  16  \n",
       "6                0            17         17                  16  \n",
       "7                0            17         17                  16  \n",
       "8                0            17         17                  16  \n",
       "9                0            17         17                  16  \n",
       "10               0            17         17                  16  \n",
       "11               0            17         17                  16  \n",
       "12               0            17         17                  16  \n",
       "13               0            17         17                  16  \n",
       "14               0            17         17                  16  \n",
       "15               0            17         17                  16  \n",
       "16               0            17         17                  16  \n",
       "17              17            18          1                 697  \n",
       "18              18            19          1                 729  \n",
       "19              19            49         30                 789  \n",
       "20              19            49         30                 789  \n",
       "21              19            49         30                 789  \n",
       "22              19            49         30                 789  \n",
       "23              19            49         30                 789  \n",
       "24              19            49         30                 789  \n",
       "25              19            49         30                 789  \n",
       "26              19            49         30                 789  \n",
       "27              19            49         30                 789  \n",
       "28              19            49         30                 789  \n",
       "29              19            49         30                 789  \n",
       "...            ...           ...        ...                 ...  \n",
       "36              19            49         30                 789  \n",
       "37              19            49         30                 789  \n",
       "38              19            49         30                 789  \n",
       "39              19            49         30                 789  \n",
       "40              19            49         30                 789  \n",
       "41              19            49         30                 789  \n",
       "42              19            49         30                 789  \n",
       "43              19            49         30                 789  \n",
       "44              19            49         30                 789  \n",
       "45              19            49         30                 789  \n",
       "46              19            49         30                 789  \n",
       "47              19            49         30                 789  \n",
       "48              19            49         30                 789  \n",
       "49               0            17         17                  16  \n",
       "50               0            17         17                  16  \n",
       "51               0            17         17                  16  \n",
       "52               0            17         17                  16  \n",
       "53               0            17         17                  16  \n",
       "54               0            17         17                  16  \n",
       "55               0            17         17                  16  \n",
       "56               0            17         17                  16  \n",
       "57               0            17         17                  16  \n",
       "58               0            17         17                  16  \n",
       "59               0            17         17                  16  \n",
       "60               0            17         17                  16  \n",
       "61               0            17         17                  16  \n",
       "62               0            17         17                  16  \n",
       "63               0            17         17                  16  \n",
       "64               0            17         17                  16  \n",
       "65               0            17         17                  16  \n",
       "\n",
       "[66 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_PATH = '{:}gs.csv'.format(GS_DIR)\n",
    "dfgs = pd.read_csv(GS_PATH, index_col=0, sep=',', encoding='utf-8')\n",
    "column_files = [\n",
    "    '{:}column_chunks/chunks.csv'.format(GS_DIR),\n",
    "    '{:}column_predmarker/predicate_marker.csv'.format(GS_DIR),\n",
    "    '{:}column_shifts_ctx_p/form.csv'.format(GS_DIR),\n",
    "    '{:}column_shifts_ctx_p/gpos.csv'.format(GS_DIR),\n",
    "    '{:}column_iob/iob.csv'.format(GS_DIR),\n",
    "    '{:}column_t/t.csv'.format(GS_DIR)\n",
    "]\n",
    "\n",
    "if LANG == 'pt':\n",
    "    column_files.append(\n",
    "        '{:}column_shifts_ctx_p/lemma.csv'.format(GS_DIR)\n",
    "    )\n",
    "\n",
    "for col_f in column_files:\n",
    "    _df = pd.read_csv(col_f, index_col=0, encoding='utf-8')\n",
    "    dfgs = pd.concat((dfgs, _df), axis=1)\n",
    "\n",
    "DISPLAY_COLUMNS = ['ID', 'P', 'FORM', 'GPOS', 'MARKER', 'ARG', 'T', 'IOB',\n",
    "                   'CHUNK_ID', 'CHUNK_START', 'CHUNK_FINISH', 'CHUNK_LEN', 'CHUNK_CANDIDATE_ID']            \n",
    "dfgs[DISPLAY_COLUMNS].head(66)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Encodings\n",
    "\n",
    "Propbank Encoder holds an indexed version of propbank dataset an answers to FOUR different dataformats: \n",
    "* CAT: this is the raw categorical data.\n",
    "* EMB: tokens are embedding using GloVe embeddings.\n",
    "* HOT: onehot encoding of the words and tokens.\n",
    "* IDX: dense indexed representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ENCODER\n",
    "propbank_encoder = PropbankEncoder.recover(PROPBANK_PATH)\n",
    "db = propbank_encoder.db\n",
    "lex2idx = propbank_encoder.lex2idx\n",
    "idx2lex = propbank_encoder.idx2lex\n",
    "\n",
    "# FOR TEXTUAL DATA ONLY\n",
    "tok2idx = propbank_encoder.tok2idx\n",
    "lex2tok = propbank_encoder.lex2tok\n",
    "idx2word = propbank_encoder.idx2word\n",
    "\n",
    "#Numpyfy embeddings\n",
    "embeddings = propbank_encoder.embeddings\n",
    "\n",
    "embeddings = np.concatenate([np.array(embs).reshape((1,50))\n",
    "                             for embs in embeddings], axis=0)\n",
    "n_targets = len(lex2idx['IOB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# dfgs.to_csv('ptb.en-set.csv', sep='\\t', encoding='utf-8')\n",
    "# with open('idx2word.en-set.json', mode='w') as f:\n",
    "#     json.dump(idx2word, f)\n",
    "np.save('glo50.eng.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall:\n",
      "  \tattributes:34\trecords:2681866\tvocab:43440\tpropositions:93998\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "'''Overall:\n",
    "  \\tattributes:{:}\\trecords:{:}\\tvocab:{:}\\tpropositions:{:}'''\n",
    "    .format(len(db), len(db['ARG'].keys()), \n",
    "            len(set([form for _, form in db['FORM'].items()])),\n",
    "            len(set([p for _, p in db['P'].items()]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Wrangling\n",
    "\n",
    "## 2.1 Helpful  function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_type(ds_type, db):\n",
    "    '''Filters only records from train dataset\n",
    "    '''\n",
    "    lb, ub = get_db_bounds(ds_type, lang=LANG)\n",
    "\n",
    "    sel_keys_ = {key_ for key_, prop_ in db['P'].items() if prop_ >= lb and prop_ < ub}\n",
    "\n",
    "    return {\n",
    "                attr_:{ idx_: i_\n",
    "                        for idx_, i_ in dict_.items() if idx_ in sel_keys_\n",
    "                      }        \n",
    "                for attr_, dict_  in db.items()\n",
    "            }\n",
    "\n",
    "def make_propositions_dict(db):\n",
    "    '''Reindex db by propositions creating a nested dict in which the\n",
    "        outer key is the proposition        \n",
    "    '''\n",
    "    \n",
    "    triple_list = []\n",
    "    prev_idx = min(db['P'].keys())\n",
    "    prev_prop = min(db['P'].values()) - 1 # Always enter first time\n",
    "    first = True\n",
    "    for idx, prop in db['P'].items():        \n",
    "        if prev_prop != prop:\n",
    "            if not first:\n",
    "                ub = prev_idx\n",
    "                triple_list.append((lb, ub, prev_prop))\n",
    "            lb = idx\n",
    "            first = False\n",
    "        prev_prop = prop\n",
    "        prev_idx = idx\n",
    "    triple_list.append((lb, prev_idx, prev_prop))\n",
    "            \n",
    "\n",
    "        \n",
    "    prop_set = set(db['P'].values())\n",
    "    return { prop_:\n",
    "                    {\n",
    "                        attr_:{ idx_: dict_[idx_]\n",
    "                                for idx_ in range(lb_, ub_ + 1, 1)\n",
    "                          }        \n",
    "                        for attr_, dict_ in db.items() if attr_ not in ('P',)\n",
    "                    }\n",
    "             for lb_, ub_, prop_ in  triple_list\n",
    "            }, {prop_: ub_ - lb_ + 1 for lb_, ub_, prop_ in  triple_list}   \n",
    "\n",
    "\n",
    "def numpfy_propositions_dict(prop_dict, proplen_dict):\n",
    "    '''Converts inner dict examples into numpy arrays\n",
    "    '''\n",
    "    prop_dict_ = defaultdict(dict)    \n",
    "    for prop, columns_dict in prop_dict.items():\n",
    "        len_ = proplen_dict[prop]\n",
    "        shape_ = (len_, 1)\n",
    "        for column, values_dict in columns_dict.items():\n",
    "            tuple_list = [idx_value \n",
    "                          for idx_value in values_dict.items()]\n",
    "\n",
    "            tuple_list = sorted(tuple_list, key=lambda x: x[0])            \n",
    "            # Converts lexicon (raw/indexed) into token (embedded/indexed)\n",
    "            if (('FORM' in column) or ('LEMMA' in column)):\n",
    "                values_list = [tok2idx[lex2tok[idx2word[tuple_[1]]]]                \n",
    "                                   for tuple_ in tuple_list]\n",
    "            else:\n",
    "                values_list = [tuple_[1] for tuple_ in tuple_list]\n",
    "\n",
    "            prop_dict_[prop][column]  = np.array(values_list).reshape(shape_)\n",
    "\n",
    "    return prop_dict_        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "print(lex2tok['77'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtrain = filter_type('train', db)\n",
    "dbvalid = filter_type('valid', db)\n",
    "if LANG == 'pt':\n",
    "    dbtest = filter_type('test', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "  \tattributes:34\trecords:2587103\tvocab:0042711\tpropositions:90750\n",
      "Valid:\n",
      "  \tattributes:34\trecords:0094763\tvocab:0006126\tpropositions:3248\n",
      "Overall:\n",
      "      \tattributes:68\trecords:2681866\tvocab:0043440\tpropositions:93998\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "'''Train:\n",
    "  \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "    .format(len(dbtrain), \n",
    "            len(dbtrain['ARG'].keys()), \n",
    "            len(set([form for _, form in dbtrain['FORM'].items()])),\n",
    "            len(set([p for _, p in dbtrain['P'].items()]))))\n",
    "\n",
    "print(\n",
    "'''Valid:\n",
    "  \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "    .format(len(dbvalid),\n",
    "            len(dbvalid['ARG'].keys()), \n",
    "            len(set([form for _, form in dbvalid['FORM'].items()])),\n",
    "            len(set([p for _, p in dbvalid['P'].items()]))))\n",
    "\n",
    "if LANG == 'pt':\n",
    "    print(\n",
    "    '''Test:\n",
    "      \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "        .format(len(dbtest),\n",
    "                len(dbtest['ARG'].keys()), \n",
    "                len(set([form for _, form in dbtest['FORM'].items()])),\n",
    "                len(set([p for _, p in dbtest['P'].items()]))))\n",
    "\n",
    "    print(\n",
    "    '''Overall:\n",
    "      \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "        .format(len(dbtrain) + len(dbvalid) + len(dbtest), \n",
    "                len(set(list(dbtrain['ARG'].keys()) + list(dbvalid['ARG'].keys()) + list(dbtest['ARG'].keys()))), \n",
    "                len(set([form for _, form in dbtrain['FORM'].items()] +\n",
    "                        [form for _, form in dbvalid['FORM'].items()] +\n",
    "                        [form for _, form in dbtest['FORM'].items()])),\n",
    "                 len(set([form for _, form in dbtrain['P'].items()] +\n",
    "                        [form for _, form in dbvalid['P'].items()] +\n",
    "                        [form for _, form in dbtest['P'].items()]))))\n",
    "else:\n",
    "    print(\n",
    "    '''Overall:\n",
    "      \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "        .format(len(dbtrain) + len(dbvalid), \n",
    "                len(set(list(dbtrain['ARG'].keys()) + list(dbvalid['ARG'].keys()))), \n",
    "                len(set([form for _, form in dbtrain['FORM'].items()] +\n",
    "                        [form for _, form in dbvalid['FORM'].items()])),\n",
    "                 len(set([form for _, form in dbtrain['P'].items()] +\n",
    "                        [form for _, form in dbvalid['P'].items()]))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Nested proposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtrain, lentrain = make_propositions_dict(dbtrain)\n",
    "dbvalid, lenvalid = make_propositions_dict(dbvalid)\n",
    "if LANG == 'pt':\n",
    "    dbtest, lentest = make_propositions_dict(dbtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "  \tattributes:34\trecords:2587103\tvocab:0042711\tpropositions:90750\n",
      "Valid:\n",
      "  \tattributes:34\trecords:0094763\tvocab:0006126\tpropositions:3248\n",
      "Overall:\n",
      "      \tattributes:34\trecords:2681866\tvocab:0043440\tpropositions:93998\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "'''Train:\n",
    "  \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "    .format(len(dbtrain[1]) + 1, \n",
    "            sum([len(d['ARG']) for p, d in dbtrain.items()]), \n",
    "            len(set([v                    \n",
    "                     for p, d in dbtrain.items()\n",
    "                     for v in d['FORM'].values()])),\n",
    "            len(lentrain)))\n",
    "\n",
    "print(\n",
    "'''Valid:\n",
    "  \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "    .format(len(dbvalid[min(dbvalid)]) + 1,\n",
    "            sum([len(d['ARG']) for p, d in dbvalid.items()]), \n",
    "            len(set([v\n",
    "                     for p, d in dbvalid.items()\n",
    "                     for v in d['FORM'].values()])),\n",
    "            len(lenvalid)))\n",
    "\n",
    "if LANG == 'pt':\n",
    "    print(\n",
    "    '''Test:\n",
    "      \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "        .format(len(dbtest[min(dbtest)]) + 1,\n",
    "                sum([len(d['ARG']) for p, d in dbtest.items()]), \n",
    "                len(set([v\n",
    "                         for p, d in dbtest.items()\n",
    "                         for v in d['FORM'].values()])),\n",
    "                len(lentest)))\n",
    "\n",
    "    print(\n",
    "    '''Overall:\n",
    "      \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "        .format(len(dbtrain[1]) + 1, \n",
    "                sum([len(d['ARG']) for p, d in dbtrain.items()] +\n",
    "                    [len(d['ARG']) for p, d in dbvalid.items()] +\n",
    "                    [len(d['ARG']) for p, d in dbtest.items()]), \n",
    "                len(set([v                    \n",
    "                         for p, d in dbtrain.items()\n",
    "                         for v in d['FORM'].values()] +\n",
    "                        [v                    \n",
    "                         for p, d in dbvalid.items()\n",
    "                         for v in d['FORM'].values()] +\n",
    "                        [v\n",
    "                         for p, d in dbtest.items()  \n",
    "                         for v in d['FORM'].values()])),\n",
    "                 len(lentrain) + len(lenvalid) + len(lentest)))\n",
    "else:\n",
    "\n",
    "    print(\n",
    "    '''Overall:\n",
    "      \\tattributes:{:}\\trecords:{:07d}\\tvocab:{:07d}\\tpropositions:{:}'''\n",
    "        .format(len(dbtrain[1]) + 1, \n",
    "                sum([len(d['ARG']) for p, d in dbtrain.items()] +\n",
    "                    [len(d['ARG']) for p, d in dbvalid.items()]), \n",
    "                len(set([v                    \n",
    "                         for p, d in dbtrain.items()\n",
    "                         for v in d['FORM'].values()] +\n",
    "                        [v                    \n",
    "                         for p, d in dbvalid.items()\n",
    "                         for v in d['FORM'].values()])),\n",
    "                 len(lentrain) + len(lenvalid)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Numpfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtrain = numpfy_propositions_dict(dbtrain, lentrain)\n",
    "dbvalid = numpfy_propositions_dict(dbvalid, lenvalid)\n",
    "if LANG == 'pt':\n",
    "    dbtest = numpfy_propositions_dict(dbtest, lentest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(db1, propid):\n",
    "    '''Generate inputs\n",
    "    '''\n",
    "    propdb = db1[propid] # nested dict of columns and idx value\n",
    "\n",
    "    \n",
    "    \n",
    "    # Replaces word with tokens\n",
    "    word    = propdb['FORM']\n",
    "    ctx_p_left  = propdb['FORM_CTX_P-1']\n",
    "    ctx_p0  = propdb['FORM_CTX_P+0']\n",
    "    ctx_p_right  = propdb['FORM_CTX_P+1']\n",
    "\n",
    "    marker  = propdb['MARKER']\n",
    "    pos     = propdb['GPOS']\n",
    "    chunk_type  = propdb['T']\n",
    "    \n",
    "    return word, ctx_p_left, ctx_p0, ctx_p_right, marker, pos\n",
    "            \n",
    "# def generate_chunk_space(n):\n",
    "#     '''Generates all possible spaces for chunks\n",
    "#     '''\n",
    "#     start_list = []\n",
    "#     end_list = []\n",
    "#     for i in range(n):\n",
    "#         for j in range(i,n,1):\n",
    "#             start_list.append(i)\n",
    "#             end_list.append(j+1)\n",
    "#     shape_ = (len(start_list), 1)\n",
    "#     start_ = np.array(start_list).reshape(shape_)\n",
    "#     finish_ = np.array(end_list).reshape(shape_)\n",
    "#     return start_, finish_\n",
    "            \n",
    "\n",
    "def get_outputs(db1, propid, n_targets):\n",
    "    ''' Generate outputs\n",
    "    '''\n",
    "    return db1[propid]['IOB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718 ns ± 14.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "propid = 1120\n",
    "word, ctx_p_left, ctx_p0, ctx_p_right, marker, pos = get_inputs(dbtrain, propid)\n",
    "targets = get_outputs(dbtrain, propid, n_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('B-A0', 0), ('B-A1', 1), ('B-A2', 2), ('B-A3', 3), ('B-A4', 4), ('B-A5', 5), ('B-AA', 6), ('B-AM', 7), ('B-AM-ADV', 8), ('B-AM-CAU', 9), ('B-AM-DIR', 10), ('B-AM-DIS', 11), ('B-AM-EXT', 12), ('B-AM-LOC', 13), ('B-AM-MNR', 14), ('B-AM-MOD', 15), ('B-AM-NEG', 16), ('B-AM-PNC', 17), ('B-AM-PRD', 18), ('B-AM-REC', 19), ('B-AM-TM', 20), ('B-AM-TMP', 21), ('B-V', 22), ('I-A0', 23), ('I-A1', 24), ('I-A2', 25), ('I-A3', 26), ('I-A4', 27), ('I-A5', 28), ('I-AA', 29), ('I-AM', 30), ('I-AM-ADV', 31), ('I-AM-CAU', 32), ('I-AM-DIR', 33), ('I-AM-DIS', 34), ('I-AM-EXT', 35), ('I-AM-LOC', 36), ('I-AM-MNR', 37), ('I-AM-MOD', 38), ('I-AM-NEG', 39), ('I-AM-PNC', 40), ('I-AM-PRD', 41), ('I-AM-REC', 42), ('I-AM-TM', 43), ('I-AM-TMP', 44), ('I-V', 45), ('O', 46)])\n",
      "[[46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [ 0]\n",
      " [46]\n",
      " [16]\n",
      " [22]\n",
      " [10]\n",
      " [46]\n",
      " [46]]\n"
     ]
    }
   ],
   "source": [
    "propid = 1120\n",
    "labels = get_outputs(dbtrain, propid, n_targets)\n",
    "print(lex2idx['IOB'])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>P</th>\n",
       "      <th>FORM</th>\n",
       "      <th>GPOS</th>\n",
       "      <th>MARKER</th>\n",
       "      <th>ARG</th>\n",
       "      <th>T</th>\n",
       "      <th>IOB</th>\n",
       "      <th>CHUNK_ID</th>\n",
       "      <th>CHUNK_START</th>\n",
       "      <th>CHUNK_FINISH</th>\n",
       "      <th>CHUNK_LEN</th>\n",
       "      <th>CHUNK_CANDIDATE_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32051</th>\n",
       "      <td>1</td>\n",
       "      <td>1120</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>6708</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32052</th>\n",
       "      <td>2</td>\n",
       "      <td>1120</td>\n",
       "      <td>So</td>\n",
       "      <td>RB</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>6708</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32053</th>\n",
       "      <td>3</td>\n",
       "      <td>1120</td>\n",
       "      <td>long</td>\n",
       "      <td>RB</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>6708</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32054</th>\n",
       "      <td>4</td>\n",
       "      <td>1120</td>\n",
       "      <td>as</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>6708</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32055</th>\n",
       "      <td>5</td>\n",
       "      <td>1120</td>\n",
       "      <td>you</td>\n",
       "      <td>PRP</td>\n",
       "      <td>0</td>\n",
       "      <td>(A0*)</td>\n",
       "      <td>A0</td>\n",
       "      <td>B-A0</td>\n",
       "      <td>6709</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32056</th>\n",
       "      <td>6</td>\n",
       "      <td>1120</td>\n",
       "      <td>do</td>\n",
       "      <td>AUX</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>6710</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32057</th>\n",
       "      <td>7</td>\n",
       "      <td>1120</td>\n",
       "      <td>n't</td>\n",
       "      <td>RB</td>\n",
       "      <td>0</td>\n",
       "      <td>(AM-NEG*)</td>\n",
       "      <td>AM-NEG</td>\n",
       "      <td>B-AM-NEG</td>\n",
       "      <td>6711</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32058</th>\n",
       "      <td>8</td>\n",
       "      <td>1120</td>\n",
       "      <td>look</td>\n",
       "      <td>VB</td>\n",
       "      <td>1</td>\n",
       "      <td>(V*)</td>\n",
       "      <td>V</td>\n",
       "      <td>B-V</td>\n",
       "      <td>6712</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32059</th>\n",
       "      <td>9</td>\n",
       "      <td>1120</td>\n",
       "      <td>down</td>\n",
       "      <td>RB</td>\n",
       "      <td>1</td>\n",
       "      <td>(AM-DIR*)</td>\n",
       "      <td>AM-DIR</td>\n",
       "      <td>B-AM-DIR</td>\n",
       "      <td>6713</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32060</th>\n",
       "      <td>10</td>\n",
       "      <td>1120</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>6714</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32061</th>\n",
       "      <td>11</td>\n",
       "      <td>1120</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>6714</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID     P  FORM GPOS  MARKER        ARG       T       IOB  CHUNK_ID  \\\n",
       "INDEX                                                                       \n",
       "32051   1  1120     (    (       0          *       *         O      6708   \n",
       "32052   2  1120    So   RB       0          *       *         O      6708   \n",
       "32053   3  1120  long   RB       0          *       *         O      6708   \n",
       "32054   4  1120    as   IN       0          *       *         O      6708   \n",
       "32055   5  1120   you  PRP       0      (A0*)      A0      B-A0      6709   \n",
       "32056   6  1120    do  AUX       0          *       *         O      6710   \n",
       "32057   7  1120   n't   RB       0  (AM-NEG*)  AM-NEG  B-AM-NEG      6711   \n",
       "32058   8  1120  look   VB       1       (V*)       V       B-V      6712   \n",
       "32059   9  1120  down   RB       1  (AM-DIR*)  AM-DIR  B-AM-DIR      6713   \n",
       "32060  10  1120     .    .       1          *       *         O      6714   \n",
       "32061  11  1120     )    )       1          *       *         O      6714   \n",
       "\n",
       "       CHUNK_START  CHUNK_FINISH  CHUNK_LEN  CHUNK_CANDIDATE_ID  \n",
       "INDEX                                                            \n",
       "32051            0             4          4                   3  \n",
       "32052            0             4          4                   3  \n",
       "32053            0             4          4                   3  \n",
       "32054            0             4          4                   3  \n",
       "32055            4             5          1                  38  \n",
       "32056            5             6          1                  45  \n",
       "32057            6             7          1                  51  \n",
       "32058            7             8          1                  56  \n",
       "32059            8             9          1                  60  \n",
       "32060            9            11          2                  64  \n",
       "32061            9            11          2                  64  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfgs[dfgs['P'] == 1120]\n",
    "df[DISPLAY_COLUMNS].head(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Viterbi Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_path(t_out, t_edge_scores, n_tags):\n",
    "    \n",
    "    def step(prev, et):\n",
    "        # last computed scores and last computed transitions\n",
    "        prev_scores, prev_selections = prev\n",
    "        \n",
    "        current_scores = tf.transpose(prev_scores + et)\n",
    "\n",
    "        best_scores = tf.reduce_max(current_scores, axis=0)\n",
    "        best_options = tf.argmax(current_scores, axis=0)\n",
    "\n",
    "        return best_scores, best_options\n",
    "    \n",
    "    score_matrix, selection_matrix = tf.scan(\n",
    "        fn=step,\n",
    "        elems=t_edge_scores,\n",
    "        initializer=(tf.zeros(n_tags), tf.to_int64(tf.zeros(n_tags))),\n",
    "    )\n",
    "    \n",
    "    return score_matrix, selection_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_path(selection_matrix, last_tag):\n",
    "    \n",
    "    def step(prev, t):\n",
    "        selection_matrix, prev_best = prev\n",
    "\n",
    "        current = selection_matrix[t][prev_best]\n",
    "\n",
    "        return selection_matrix, current\n",
    "\n",
    "    m = tf.shape(selection_matrix)[0]\n",
    "    _, rev_path = tf.scan(\n",
    "        fn = step,\n",
    "        elems=m-1-tf.range(m),\n",
    "        initializer=(selection_matrix, last_tag)\n",
    "\n",
    "    )\n",
    "\n",
    "    best_path = tf.concat((tf.reverse(rev_path,axis=[0]),[last_tag]),axis=0)\n",
    "    return best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_score(t_edge_scores, path, n):\n",
    "    \n",
    "    def step(prev, t):\n",
    "        edge_scores, path, prev_score = prev\n",
    "        \n",
    "        transition_score = edge_scores[t]\n",
    "        \n",
    "        p_t = path[t]\n",
    "        p_tp1 = path[t+1]\n",
    "\n",
    "        current_score = transition_score[p_tp1,p_t] + prev_score\n",
    "\n",
    "        return edge_scores, path, current_score\n",
    "\n",
    "    _, _, path_score = tf.scan(\n",
    "    fn = step,\n",
    "    elems=tf.range(n-1),\n",
    "    initializer=(t_edge_scores, path, tf.zeros(1))\n",
    "    )\n",
    "    return path_score[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'hidden_features':200,\n",
    "    'state_size':200,\n",
    "    'learning_rate':0.001,\n",
    "    'spn_layer':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(hparams):\n",
    "\n",
    "    # Determine parameters for the computation graph\n",
    "#     vocab_size = len(set(lex2tok.values()))\n",
    "#     capt_size = model_meta['capt_size']\n",
    "    pos_size = len(lex2idx['GPOS'])\n",
    "#     char_size = model_meta['char_size']\n",
    "    ck_size = len(lex2idx['IOB'])\n",
    "    embed_size = embeddings.shape[1]\n",
    "#     capt_embed_size = model_meta['capt_embed_size']\n",
    "#     char_embed_size = model_meta['char_embed_size']\n",
    "#     char_hidden = model_meta['char_hidden_features']\n",
    "    pos_embed_size = len(idx2lex['GPOS'])\n",
    "\n",
    "    hidden_features = hparams['hidden_features']\n",
    "    state_size = hparams['state_size']\n",
    "    lr = hparams['learning_rate']\n",
    "    spn_layer = hparams['spn_layer']\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "# word, ctx_p_left, ctx_p0, ctx_p_right, marker, pos, \n",
    "\n",
    "    t_x_words = tf.placeholder(tf.int32,(None,1))   # ids form\n",
    "    t_x_ctx_p_left = tf.placeholder(tf.int32,(None,1))\n",
    "    t_x_ctx_p0 = tf.placeholder(tf.int32,(None,1)) \n",
    "    t_x_ctx_p_right = tf.placeholder(tf.int32,(None,1))\n",
    "    \n",
    "    t_x_pos = tf.placeholder(tf.int32,(None,1))     # ids POS\n",
    "    t_x_marker = tf.placeholder(tf.int32, (None,1))\n",
    "    \n",
    "    t_y_ck = tf.placeholder(tf.int32, shape=(None,)) # ids IOB-SRL\n",
    "    \n",
    "    \n",
    "    t_inputs = [t_x_words, t_x_ctx_p_left, t_x_ctx_p0, t_x_ctx_p_right, t_x_marker, t_x_pos]\n",
    "    t_targets = [t_y_ck]\n",
    "\n",
    "    with tf.variable_scope('Feature_Vars'):\n",
    "        t_W_embed = tf.Variable(embeddings.astype(np.float32))\n",
    "#         t_W_char = tf.Variable(np.random.normal(0,0.1,(char_size+1, char_embed_size)).astype(np.float32))\n",
    "\n",
    "        t_gamma = tf.Variable(np.random.normal(0,1.0, 1).astype(np.float32))\n",
    "        t_beta = tf.Variable(np.random.normal(0,1.0, 1).astype(np.float32))\n",
    "\n",
    "        dim = state_size\n",
    "        if dim is None:\n",
    "            dim = 2*hidden_features\n",
    "        if spn_layer:\n",
    "            t_W_tran = tf.Variable(np.random.normal(0,1.0/np.sqrt(3*dim),(3*dim, ck_size*ck_size)).astype(np.float32))\n",
    "        else:\n",
    "            t_W_ck = tf.Variable(np.random.normal(0,0.1,(dim, ck_size)).astype(np.float32))\n",
    "        \n",
    "\n",
    "\n",
    "    t_words = tf.gather_nd(t_W_embed, t_x_words)\n",
    "    t_ctx_p_left = tf.gather_nd(t_W_embed, t_x_ctx_p_left)\n",
    "    t_ctx_p0 = tf.gather_nd(t_W_embed, t_x_ctx_p0)\n",
    "    t_ctx_p_right = tf.gather_nd(t_W_embed, t_x_ctx_p_right)\n",
    "                                     \n",
    "    t_x_pos_flat = tf.squeeze(t_x_pos, axis=1)\n",
    "\n",
    "    t_pos = tf.to_float(tf.one_hot(indices= t_x_pos_flat, depth=pos_size, on_value=1,off_value=0))\n",
    "    t_marker = tf.cast(t_x_marker, tf.float32)\n",
    "    \n",
    "    t_word_feats = tf.concat((t_words, t_ctx_p_left, t_ctx_p0, t_ctx_p_right, t_marker, t_pos), axis=1)\n",
    "    print(t_word_feats.get_shape())\n",
    "\n",
    "    t_sq_len = tf.shape(t_x_words)[0]\n",
    "    print(t_sq_len)\n",
    "\n",
    "    n_features = embed_size\n",
    "\n",
    "    t_words_shp = tf.reshape(\n",
    "        t_word_feats, (1,t_sq_len, pos_size + embed_size * 4 + 1)\n",
    "    )\n",
    "\n",
    "    cell_fw = tf.nn.rnn_cell.LSTMCell(num_units=hidden_features, state_is_tuple=True)\n",
    "    cell_bw = tf.nn.rnn_cell.LSTMCell(num_units=hidden_features, state_is_tuple=True)\n",
    "\n",
    "    with tf.variable_scope(\"Bilstm\"):\n",
    "        t_h1, t_last_states =tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw=cell_fw,\n",
    "            cell_bw=cell_bw,\n",
    "            dtype=tf.float32,\n",
    "            inputs=t_words_shp)\n",
    "\n",
    "        t_hidden = tf.concat((t_h1[0][0],t_h1[1][0]),axis=1)\n",
    "\n",
    "    if state_size is not None:\n",
    "        t_lstmcell = tf.nn.rnn_cell.LSTMCell(num_units=state_size, state_is_tuple=True)\n",
    "        t_hidden_shp = tf.reshape(t_hidden, (1,t_sq_len, 2*hidden_features))\n",
    "\n",
    "        with tf.variable_scope('LSTM_last'):\n",
    "            t_h2, t_last_states2 =tf.nn.dynamic_rnn(\n",
    "                cell=t_lstmcell,\n",
    "                dtype=tf.float32,\n",
    "                sequence_length=[t_sq_len],\n",
    "                inputs=t_hidden_shp)\n",
    "\n",
    "        t_out = t_h2[0]\n",
    "    else:\n",
    "        t_out = t_hidden\n",
    "        \n",
    "    n = tf.shape(t_out)[0]\n",
    "    \n",
    "    t_outputs = []\n",
    "    if spn_layer:\n",
    "        t_edges = tf.concat((t_out[1:],t_out[:-1],t_out[1:]*t_out[:-1]),axis=1)\n",
    "        t_edge_scores = tf.matmul(t_edges, t_W_tran)\n",
    "\n",
    "        t_edge_scores = tf.reshape(t_edge_scores, ((n-1)*ck_size*ck_size,))\n",
    "\n",
    "        # Batch Normalization\n",
    "        t_es_mean = tf.reduce_mean(t_edge_scores)\n",
    "        t_es_m2 = tf.reduce_mean(t_edge_scores**2)\n",
    "\n",
    "        t_es_var = t_es_m2 - t_es_mean**2\n",
    "        t_es_std = tf.sqrt(t_es_var + 1e-8)\n",
    "\n",
    "        t_es_norm = (t_edge_scores - t_es_mean)/t_es_std\n",
    "\n",
    "        t_es_renorm = t_gamma * t_es_norm + t_beta\n",
    "\n",
    "        t_edge_scores = tf.reshape(t_es_renorm, (n-1,ck_size,ck_size))\n",
    "\n",
    "        t_score_matrix, t_selection_matrix = longest_path(t_out, t_edge_scores,ck_size)\n",
    "\n",
    "        t_best_score = tf.reduce_max(t_score_matrix[-1])\n",
    "        t_last_tag = tf.argmax(t_score_matrix[-1])\n",
    "\n",
    "        t_best_path = retrieve_path(t_selection_matrix, t_last_tag)\n",
    "\n",
    "        t_correct_score = path_score(t_edge_scores, t_y_ck, n)\n",
    "\n",
    "        t_cost = -t_correct_score\n",
    "\n",
    "        # # gradiente descendente no custo do perceptron estruturado\n",
    "        t_optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        t_train = t_optimizer.minimize(t_cost)\n",
    "\n",
    "        t_outputs.extend([t_score_matrix, t_best_path])\n",
    "        \n",
    "        def t_pred(sess, x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos):\n",
    "            result = sess.run(t_best_path, feed_dict={\n",
    "                t_inputs[0]:x_word,\n",
    "                t_inputs[1]:x_ctx_p_left,\n",
    "                t_inputs[2]:x_ctx_p0,\n",
    "                t_inputs[3]:x_ctx_p_right,                \n",
    "                t_inputs[4]:x_marker,\n",
    "                t_inputs[5]:x_pos\n",
    "            })\n",
    "            return result\n",
    "\n",
    "        def my_t_train(sess, word, ctx_p_left, ctx_p0, ctx_p_right, marker, pos, y_ck):\n",
    "            _, result = sess.run([t_train, t_cost], feed_dict={\n",
    "                t_inputs[0]:x_word,\n",
    "                t_inputs[1]:x_ctx_p_left,\n",
    "                t_inputs[2]:x_ctx_p0,\n",
    "                t_inputs[3]:x_ctx_p_right,                \n",
    "                t_inputs[4]:x_marker,\n",
    "                t_inputs[5]:x_pos,\n",
    "                t_targets[0]:y_ck\n",
    "            })\n",
    "            return result\n",
    "    else: #CRF\n",
    "        t_ck_score = tf.matmul(t_out,t_W_ck)\n",
    "\n",
    "        t_ck_score_ext = tf.expand_dims(t_ck_score, 0)\n",
    "        t_y_ck_ext = tf.expand_dims(t_y_ck, 0)\n",
    "\n",
    "        t_sequence_lengths = tf.shape(t_x_words)[0]\n",
    "        t_sequence_lengths = tf.expand_dims(t_sequence_lengths,0)\n",
    "\n",
    "        t_log_likelihood, t_transition_params = tf.contrib.crf.crf_log_likelihood(\n",
    "            t_ck_score_ext, \n",
    "            t_y_ck_ext, \n",
    "            t_sequence_lengths)\n",
    "        \n",
    "        t_outputs.extend([t_ck_score, t_transition_params])\n",
    "    \n",
    "        t_cost = -t_log_likelihood\n",
    "\n",
    "        # # gradiente descendente no custo do perceptron estruturado\n",
    "        t_optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(0.003)\n",
    "        t_train = t_optimizer.minimize(t_cost)\n",
    "\n",
    "        def t_pred(sess, x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos):\n",
    "            score, tparams = sess.run([t_ck_score,t_transition_params], feed_dict={\n",
    "                t_inputs[0]:x_word,\n",
    "                t_inputs[1]:x_ctx_p_left,\n",
    "                t_inputs[2]:x_ctx_p0,\n",
    "                t_inputs[3]:x_ctx_p_right,                \n",
    "                t_inputs[4]:x_marker,\n",
    "                t_inputs[5]:x_pos\n",
    "            })\n",
    "\n",
    "            return tf.contrib.crf.viterbi_decode(score=score,transition_params=tparams)[0][:-1]\n",
    "        \n",
    "        def my_t_train(sess, word, ctx_p_left, ctx_p0, ctx_p_right, marker, pos, y_ck):\n",
    "            _, result = sess.run([t_train, t_cost], feed_dict={\n",
    "                t_inputs[0]:x_word,\n",
    "                t_inputs[1]:x_ctx_p_left,\n",
    "                t_inputs[2]:x_ctx_p0,\n",
    "                t_inputs[3]:x_ctx_p_right,                \n",
    "                t_inputs[4]:x_marker,\n",
    "                t_inputs[5]:x_pos,\n",
    "                t_targets[0]:y_ck\n",
    "            })\n",
    "            return result\n",
    "    \n",
    "    return t_inputs, t_targets, t_outputs, my_t_train, t_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 249)\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t_inputs, t_targets, t_outputs, t_train, t_pred = make_graph(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 18 34  5 34  5 17 42 27 30 26 34 40 40 40 40 40 40 40 40 40 40 40 40\n",
      " 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40]\n",
      "(44, 1)\n",
      "['B-A0', 'B-AM-PRD', 'I-AM-DIS', 'B-A5', 'I-AM-DIS', 'B-A5', 'B-AM-PNC', 'I-AM-REC', 'I-A4', 'I-AM', 'I-A3', 'I-AM-DIS', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC', 'I-AM-PNC']\n"
     ]
    }
   ],
   "source": [
    "sample = 146\n",
    "x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos = get_inputs(dbtrain, sample)\n",
    "\n",
    "y_ck = get_outputs(dbtrain, sample, n_targets)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    o_ck = t_pred(sess, x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos)\n",
    "print(o_ck)\n",
    "print(y_ck.shape)\n",
    "print([idx2lex['IOB'][ck] for ck in list(o_ck)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Overfit one proposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-32.895603]\n",
      "[-1502.0531]\n",
      "[-1928.2069]\n"
     ]
    }
   ],
   "source": [
    "sample =146\n",
    "\n",
    "x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos = get_inputs(dbtrain, sample)\n",
    "y_ck = get_outputs(dbtrain, sample, n_targets)\n",
    "y_ck = np.squeeze(y_ck, axis=1)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(200):\n",
    "    L = t_train(sess, x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos, y_ck)\n",
    "    if i % 100 == 0:\n",
    "        print(L)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Evaluate one proposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_to_conll(sess, prop_dict, propid, idx2lex):\n",
    "    gold_list = []\n",
    "    eval_list = []\n",
    "        \n",
    "    x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos = get_inputs(prop_dict, propid)\n",
    "    targets = get_outputs(prop_dict, propid, n_targets)\n",
    "    predictions = t_pred(sess, x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos)\n",
    "\n",
    "\n",
    "\n",
    "    n_words = len(x_word)\n",
    "    default_ck_list_ = [(i,i + 1, '*') for i in range(n_words)]\n",
    "    \n",
    "    pred_array = prop_dict[propid]['PRED']\n",
    "    pred_array = pred_array.flatten()\n",
    "    \n",
    "    arg_array = prop_dict[propid]['ARG']\n",
    "    arg_array = arg_array.flatten()\n",
    "    \n",
    "    pred_list = [idx2lex['PRED'][i] for i in pred_array.tolist()]\n",
    "    gold_list_ = [idx2lex['ARG'][i] for i in arg_array.tolist()]\n",
    "     \n",
    "    gold_list += list(zip(pred_list, gold_list_))\n",
    "    prop_list =  [propid for _ in range(len(gold_list))]\n",
    "    eval_list = [idx2lex['IOB'][i] for i in predictions]\n",
    "    \n",
    "    #FIXME: removed #end of sentence token\n",
    "    # now predictions are shorter then gold\n",
    "    if len(eval_list) < len(prop_list):\n",
    "        eval_list.append('O')\n",
    "\n",
    "    eval_list = propbankbr_iob2arg(prop_list, eval_list)\n",
    "    \n",
    "#     ck_list_ = []     \n",
    "#     for triple_ in sorted(chunk_ext, key= lambda x: x[0]):\n",
    "#         lb, ub, ckid = triple_\n",
    "#         # filters default value\n",
    "#         default_ck_list_ = [\n",
    "#             dck_\n",
    "#             for dck_ in default_ck_list_ if dck_[0] < lb or dck_[1] > ub\n",
    "#         ]\n",
    "#         ck_list_.append((lb, ub, idx2lex['T'][ckid]))        \n",
    "\n",
    "#     ck_list_ = default_ck_list_ + ck_list_ \n",
    "\n",
    "#     arg_list_ = []\n",
    "#     for triple_ in sorted(ck_list_, key= lambda x: x[0]):\n",
    "#         lb, ub, cktype = triple_\n",
    "#         flat_list_ = [ cktype if i == lb else '*' for i in range(lb, ub) ]\n",
    "            \n",
    "#         if cktype != '*':\n",
    "#             flat_list_[0] = '({:}*'.format(flat_list_[0])\n",
    "#             flat_list_[-1] = '{:})'.format(flat_list_[-1])\n",
    "#         arg_list_ += flat_list_\n",
    "        \n",
    "    eval_list = list(zip(pred_list, eval_list))\n",
    "#     eval_list.append(None)\n",
    "#     gold_list.append(None)\n",
    "\n",
    "    #Change to use CoNLL2004\n",
    "    if LANG == 'pt':\n",
    "        gold_list = propbankbr_arg2se(gold_list)\n",
    "        eval_list = propbankbr_arg2se(eval_list)\n",
    "\n",
    "    return gold_list, eval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(gold_list, eval_list, ds_type='train',verbose=True):\n",
    "    gold_path = '{}_gold.props'.format(ds_type)    \n",
    "    eval_path = '{}_eval.props'.format(ds_type)\n",
    "\n",
    "    with open(gold_path, mode='w') as f:        \n",
    "        for tuple_ in gold_list:\n",
    "            if tuple_ is None:\n",
    "                f.write('\\n')\n",
    "            else:\n",
    "                f.write('{:}\\t{:}\\n'.format(*tuple_))\n",
    "\n",
    "    with open(eval_path, mode='w') as f:        \n",
    "        for tuple_ in eval_list:\n",
    "            if tuple_ is None:\n",
    "                f.write('\\n')\n",
    "            else:\n",
    "                f.write('{:}\\t{:}\\n'.format(*tuple_))\n",
    "\n",
    "    pipe = Popen(['perl',PEARL_SRLEVAL_PATH, gold_path, eval_path], stdout=PIPE, stderr=PIPE)\n",
    "\n",
    "    txt, err = pipe.communicate()\n",
    "    txt = txt.decode('UTF-8')\n",
    "    err = err.decode('UTF-8')\n",
    "    \n",
    "    print(err)\n",
    "    if verbose:\n",
    "        print(txt)\n",
    "        with open('{}.conll'.format(ds_type), mode='w') as f:\n",
    "            f.write(txt)\n",
    "\n",
    "    # overall is a summary from the list\n",
    "    # is the seventh line\n",
    "    lines_list = txt.split('\\n')        \n",
    "    \n",
    "    # get the numbers from the row \n",
    "    overall_list = re.findall(r'[-+]?[0-9]*\\.?[0-9]+.', lines_list[6])\n",
    "    f1 = float(overall_list[-1])\n",
    "\n",
    "    return f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(sess, prop_dict, idx2lex, ds_type='train'):\n",
    "    gold_list = []\n",
    "    eval_list = []\n",
    "    first = True\n",
    "    for pid in prop_dict:        \n",
    "        g_list, e_list = tag_to_conll(sess, prop_dict, pid, idx2lex)\n",
    "\n",
    "        if not first:\n",
    "            gold_list.append(None)\n",
    "            eval_list.append(None)\n",
    "        else:\n",
    "            first = False\n",
    "\n",
    "        gold_list += g_list\n",
    "        eval_list += e_list\n",
    "\n",
    "    return evaluate(gold_list, eval_list, ds_type=ds_type, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Sentences    :           1\n",
      "Number of Propositions :           1\n",
      "Percentage of perfect props : 100.00\n",
      "\n",
      "              corr.  excess  missed    prec.    rec.      F1\n",
      "------------------------------------------------------------\n",
      "   Overall        5       0       0   100.00  100.00  100.00\n",
      "----------\n",
      "        A0        1       0       0   100.00  100.00  100.00\n",
      "        A1        1       0       0   100.00  100.00  100.00\n",
      "    AM-MOD        1       0       0   100.00  100.00  100.00\n",
      "    AM-TMP        2       0       0   100.00  100.00  100.00\n",
      "------------------------------------------------------------\n",
      "         V        1       0       0   100.00  100.00  100.00\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold_tags, eval_tags = tag_to_conll(sess, dbtrain, sample, idx2lex)\n",
    "f1 = evaluate(gold_tags, eval_tags, 'prop_{:}'.format(sample), verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Sentences    :        3248\n",
      "Number of Propositions :        3248\n",
      "Percentage of perfect props :   0.12\n",
      "\n",
      "              corr.  excess  missed    prec.    rec.      F1\n",
      "------------------------------------------------------------\n",
      "   Overall       49    6962    8402     0.70    0.58    0.63\n",
      "----------\n",
      "        A0       34    2630    2198     1.28    1.52    1.39\n",
      "        A1        2     214    3171     0.93    0.06    0.12\n",
      "        A2        0       0     681     0.00    0.00    0.00\n",
      "        A3        0       0     114     0.00    0.00    0.00\n",
      "        A4        0       1      65     0.00    0.00    0.00\n",
      "        A5        0       0       2     0.00    0.00    0.00\n",
      "        AA        0       0       1     0.00    0.00    0.00\n",
      "        AM        0       1       0     0.00    0.00    0.00\n",
      "    AM-ADV        0       0     279     0.00    0.00    0.00\n",
      "    AM-CAU        0       0      48     0.00    0.00    0.00\n",
      "    AM-DIR        0       0      36     0.00    0.00    0.00\n",
      "    AM-DIS        0       0     202     0.00    0.00    0.00\n",
      "    AM-EXT        0       0      29     0.00    0.00    0.00\n",
      "    AM-LOC        0       3     203     0.00    0.00    0.00\n",
      "    AM-MNR        0       0     249     0.00    0.00    0.00\n",
      "    AM-MOD        0     636     317     0.00    0.00    0.00\n",
      "    AM-NEG        0       0     104     0.00    0.00    0.00\n",
      "    AM-PNC        0       0      81     0.00    0.00    0.00\n",
      "    AM-PRD        0       0       3     0.00    0.00    0.00\n",
      "     AM-TM        0       2       0     0.00    0.00    0.00\n",
      "    AM-TMP       13    3475     619     0.37    2.06    0.63\n",
      "------------------------------------------------------------\n",
      "         V        3     128    3247     2.29    0.09    0.18\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_valid = evaluate_dataset(sess, dbvalid, idx2lex, ds_type='valid')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "train_sentences = range(*get_db_bounds('train', lang=LANG))\n",
    "dev_sentences = range(*get_db_bounds('valid', lang=LANG))\n",
    "if LANG == 'pt':\n",
    "    test_sentences = range(*get_db_bounds('test', lang=LANG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   3\n",
      "Training Model {'hidden_features': 50, 'state_size': 50, 'learning_rate': 0.0005, 'spn_layer': True}\n",
      "(?, 249)\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index -1 of dimension 0 out of bounds.\n\t [[Node: gradients/strided_slice_10_grad/StridedSliceGrad = StridedSliceGrad[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/strided_slice_10_grad/Shape, strided_slice_4/stack_1, gradients/Mean_1_grad/Const, gradients/Mean_1_grad/Reshape/shape, gradients/Neg_grad/Neg)]]\n\nCaused by op 'gradients/strided_slice_10_grad/StridedSliceGrad', defined at:\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-39af4d95bda2>\", line 41, in <module>\n    model = make_graph(model_meta)\n  File \"<ipython-input-37-2f8826b72841>\", line 138, in make_graph\n    t_train = t_optimizer.minimize(t_cost)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 399, in minimize\n    grad_loss=grad_loss)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 511, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 532, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 701, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 396, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 701, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py\", line 278, in _StridedSliceGrad\n    shrink_axis_mask=op.get_attr(\"shrink_axis_mask\")), None, None, None\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8420, in strided_slice_grad\n    shrink_axis_mask=shrink_axis_mask, name=name)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'strided_slice_10', defined at:\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 23 identical lines from previous traceback]\n  File \"<ipython-input-42-39af4d95bda2>\", line 41, in <module>\n    model = make_graph(model_meta)\n  File \"<ipython-input-37-2f8826b72841>\", line 132, in make_graph\n    t_correct_score = path_score(t_edge_scores, t_y_ck, n)\n  File \"<ipython-input-34-682be46d9e63>\", line 20, in path_score\n    return path_score[-1]\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 523, in _slice_helper\n    name=name)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 689, in strided_slice\n    shrink_axis_mask=shrink_axis_mask)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8232, in strided_slice\n    name=name)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): slice index -1 of dimension 0 out of bounds.\n\t [[Node: gradients/strided_slice_10_grad/StridedSliceGrad = StridedSliceGrad[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/strided_slice_10_grad/Shape, strided_slice_4/stack_1, gradients/Mean_1_grad/Const, gradients/Mean_1_grad/Reshape/shape, gradients/Neg_grad/Neg)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index -1 of dimension 0 out of bounds.\n\t [[Node: gradients/strided_slice_10_grad/StridedSliceGrad = StridedSliceGrad[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/strided_slice_10_grad/Shape, strided_slice_4/stack_1, gradients/Mean_1_grad/Const, gradients/Mean_1_grad/Reshape/shape, gradients/Neg_grad/Neg)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-39af4d95bda2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0my_ck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ctx_p_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ctx_p0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ctx_p_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_marker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoca \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mf1_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2lex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-2f8826b72841>\u001b[0m in \u001b[0;36mmy_t_train\u001b[0;34m(sess, word, ctx_p_left, ctx_p0, ctx_p_right, marker, pos, y_ck)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mt_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_marker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mt_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0mt_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_ck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             })\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index -1 of dimension 0 out of bounds.\n\t [[Node: gradients/strided_slice_10_grad/StridedSliceGrad = StridedSliceGrad[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/strided_slice_10_grad/Shape, strided_slice_4/stack_1, gradients/Mean_1_grad/Const, gradients/Mean_1_grad/Reshape/shape, gradients/Neg_grad/Neg)]]\n\nCaused by op 'gradients/strided_slice_10_grad/StridedSliceGrad', defined at:\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-39af4d95bda2>\", line 41, in <module>\n    model = make_graph(model_meta)\n  File \"<ipython-input-37-2f8826b72841>\", line 138, in make_graph\n    t_train = t_optimizer.minimize(t_cost)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 399, in minimize\n    grad_loss=grad_loss)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 511, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 532, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 701, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 396, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 701, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py\", line 278, in _StridedSliceGrad\n    shrink_axis_mask=op.get_attr(\"shrink_axis_mask\")), None, None, None\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8420, in strided_slice_grad\n    shrink_axis_mask=shrink_axis_mask, name=name)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'strided_slice_10', defined at:\n  File \"/Users/Varela/.pyenv/versions/3.6.5/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 23 identical lines from previous traceback]\n  File \"<ipython-input-42-39af4d95bda2>\", line 41, in <module>\n    model = make_graph(model_meta)\n  File \"<ipython-input-37-2f8826b72841>\", line 132, in make_graph\n    t_correct_score = path_score(t_edge_scores, t_y_ck, n)\n  File \"<ipython-input-34-682be46d9e63>\", line 20, in path_score\n    return path_score[-1]\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 523, in _slice_helper\n    name=name)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 689, in strided_slice\n    shrink_axis_mask=shrink_axis_mask)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8232, in strided_slice\n    name=name)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/Users/Varela/.venv/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): slice index -1 of dimension 0 out of bounds.\n\t [[Node: gradients/strided_slice_10_grad/StridedSliceGrad = StridedSliceGrad[Index=DT_INT32, T=DT_FLOAT, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/strided_slice_10_grad/Shape, strided_slice_4/stack_1, gradients/Mean_1_grad/Const, gradients/Mean_1_grad/Reshape/shape, gradients/Neg_grad/Neg)]]\n"
     ]
    }
   ],
   "source": [
    "lr_search = [0.0005]\n",
    "hidden_features_search = [50,150,250]\n",
    "\n",
    "for j in range(len(hidden_features_search)):\n",
    "    for i in range(len(lr_search)):\n",
    "        for s in range(2):\n",
    "            lr = lr_search[i]\n",
    "            hf = hidden_features_search[j]\n",
    "\n",
    "            print(j, ' ', len(hidden_features_search))\n",
    "#             model_meta = {\n",
    "#                 'vocab_size':len(id_to_word),\n",
    "#                 'capt_size':len(id_to_capt),\n",
    "#                 'pos_size':len(id_to_pos),\n",
    "#                 'char_size':len(id_to_char),\n",
    "#                 'ck_size':len(id_to_ck),\n",
    "#                 'embed_size':embedding_matrix.shape[1],\n",
    "#                 'capt_embed_size':10,\n",
    "#                 'char_embed_size':30,\n",
    "#                 'pos_embed_size':10,\n",
    "#                 'char_hidden_features':30,\n",
    "#                 'hidden_features':hf,\n",
    "#                 'state_size':hf,\n",
    "#                 'learning_rate':lr,\n",
    "#                 'spn_layer':s==0\n",
    "#             }\n",
    "            model_meta = {\n",
    "                'hidden_features':hf,\n",
    "                'state_size':hf,\n",
    "                'learning_rate':lr,\n",
    "                'spn_layer':s==0\n",
    "            }\n",
    "            print('Training Model', model_meta)\n",
    "            \n",
    "            last_layer = 'crf'\n",
    "            if s == 0:\n",
    "                last_layer = 'spn'\n",
    "\n",
    "            n_epochs = 50\n",
    "            model_name = 'bilstm_viterbi_h' + str(hf) + '_lr_' + str(lr) + '_' + last_layer\n",
    "            model = make_graph(model_meta)\n",
    "\n",
    "\n",
    "            t_inputs, t_targets, t_outputs, t_train, t_pred = model\n",
    "            \n",
    "            #NEW SESSION PER MODEL\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            sess = tf.Session(config=config)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            indices = np.arange(1, len(train_sentences))\n",
    "            n = len(indices)\n",
    "\n",
    "            best_path = None\n",
    "            best_f1 = 0\n",
    "\n",
    "            save_dir = '../outputs/1.0/notebooks/spn/models/'\n",
    "            timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H-%M-%S')\n",
    "            exp_desc_dir = '{}results/'.format(save_dir)\n",
    "            saver = tf.train.Saver(max_to_keep=n_epochs*20)\n",
    "\n",
    "            dev_f1_list = []\n",
    "            train_f1_list = []\n",
    "            consecutive_bad_dev = 0\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                start = time.time()\n",
    "                np.random.shuffle(indices)\n",
    "                it = 0\n",
    "                for sid in indices:\n",
    "                    it += 1\n",
    "                    x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos  = get_inputs(dbtrain, sid)\n",
    "                    targets = get_outputs(dbtrain, sid, n_targets)\n",
    "                    y_ck = np.squeeze(targets, axis=1)\n",
    "                    L = t_train(sess, x_word, x_ctx_p_left, x_ctx_p0, x_ctx_p_right, x_marker, x_pos, y_ck)\n",
    "                print(\"Epoca \", (epoch+1))\n",
    "                f1_valid = evaluate_dataset(sess, dbvalid, idx2lex, ds_type='valid')            \n",
    "\n",
    "                print(\"valid f1: \", f1_valid)\n",
    "\n",
    "                f1_train = evaluate_dataset(sess, dbtrain, idx2lex, ds_type='train')            \n",
    "                print(\"train f1: \", f1_train)\n",
    "                dev_f1_list.append(f1_valid)\n",
    "                train_f1_list.append(f1_train)\n",
    "                end = time.time()\n",
    "                print('Tempo por Epoca: ', (end-start), ' s')\n",
    "                if f1_valid > best_f1:\n",
    "                    best_f1 = f1_valid\n",
    "                    save_path = save_dir + model_name + '_' + timestamp\n",
    "                    saver.save(sess, save_path)\n",
    "                    print('## BEST MODEL saved at ', save_path)\n",
    "                    consecutive_bad_dev = 0\n",
    "                else:\n",
    "                    consecutive_bad_dev += 1\n",
    "                if consecutive_bad_dev == 5:\n",
    "                    break\n",
    "\n",
    "            exp_path = exp_desc_dir + model_name + timestamp + '.txt'\n",
    "            with open(exp_path,'w') as f:\n",
    "                exp_desc = {\n",
    "                    'model':model_meta,\n",
    "                    'f1_train':train_f1_list,\n",
    "                    'f1_valid':dev_f1_list\n",
    "                }\n",
    "                json.dump(exp_desc, f)\n",
    "                print('save results on ' + exp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
